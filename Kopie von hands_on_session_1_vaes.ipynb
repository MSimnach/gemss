{"cells":[{"cell_type":"markdown","metadata":{"id":"aJ_pmgxvGur9"},"source":["# Hands-on session 1 - Variational Auto-Encoders\n","## Generative Modeling Summer School 2024"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1719643388915,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"lBgoJIpdLI2Y","outputId":"64b0de8e-3a0e-4293-94b2-c54f3364012f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"mEneMITS2agU"},"source":["#### Instructions on how to use this notebook:\n","\n","This notebook is prepared to be hosted on ``Google Colab``. To be able to work on it, you have to create your own copy. In Google Drive: Go to *File* and select *Save a copy in Drive*.\n","\n","You can also avoid using ``Colab`` entirely, and download the notebook to run it on your own machine. If you choose this, go to *File* and select *Download .ipynb*.\n","\n","The advantage of using **Colab** is that you can use a GPU. You can complete this assignment with a CPU, but it will take a bit longer. Furthermore, we encourage you to train using the GPU not only for faster training, but also to get experience with this setting. This includes moving models and tensors to the GPU and back. This experience is very valuable because for various models and large datasets (like large CNNs for ImageNet, or Transformer models trained on Wikipedia), training on GPU is the only feasible way.\n","\n","The default ``Colab`` runtime does not have a GPU. To change this, go to *Runtime - Change runtime type*, and select *GPU* as the hardware accelerator. The GPU that you get changes according to what resources are available at the time, and its memory can go from a 5GB, to around 18GB if you are lucky. If you are curious, you can run the following in a code cell to check:\n","\n","```sh\n","!nvidia-smi\n","```\n","\n","Note that despite the name, ``Google Colab`` does  not support collaborative work without issues. When two or more people edit the notebook concurrently, only one version will be saved. You can choose to do group programming with one person sharing the screen with the others, or make multiple copies of the notebook to work concurrently.\n","\n","**Submission:** Please bring your (partial) solution to the hands-on session. Then you can discuss it with intructors and your colleagues."]},{"cell_type":"markdown","metadata":{"id":"tsdc7fDp40rQ"},"source":["## Introduction\n","\n","In this assignment, we are going to implement a Variational Auto-Encoder (VAE). A VAE is a likelihood-based deep generative model that consists of a stochastic encoder (a variational posterior over latent variables), a stochastic decoder, and a marginal distribution over latent variables (a.k.a. a prior). The model was originally proposed in two concurrent papers:\n","- [Kingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.](https://arxiv.org/abs/1312.6114)\n","- [Rezende, Danilo Jimenez, Shakir Mohamed, and Daan Wierstra. \"Stochastic backpropagation and approximate inference in deep generative models.\" International conference on machine learning. PMLR, 2014.](https://proceedings.mlr.press/v32/rezende14.html)\n","\n","You can read more about VAEs in Chapter 4 of the following book:\n","- [Tomczak, J.M., \"Deep Generative Modeling\", Springer, 2022](https://link.springer.com/book/10.1007/978-3-030-93158-2)\n","\n","In particular, the goals of this assignment are the following:\n","\n","- Understand how VAEs are formulated\n","- Implement components of VAEs using PyTorch\n","- Train and evaluate a model for image data"]},{"cell_type":"markdown","metadata":{"id":"RvsuVNczG6pP"},"source":["### Theory behind VAEs\n","\n","VAEs are latent variable models trained with variational inference. In general, the latent variable models define the following generative process:\n","\\begin{align}\n","1.\\ & \\mathbf{z} \\sim p_{\\lambda}(\\mathbf{z}) \\\\\n","2.\\ & \\mathbf{x} \\sim p_{\\theta}(\\mathbf{x}|\\mathbf{z})\n","\\end{align}\n","\n","In plain words, we assume that for observable data $\\mathbf{x}$, there are some latent (hidden) factors $\\mathbf{z}$. Then, the training objective is the log-likelihood function of the following form:\n","$$\n","\\log p_{\\vartheta}(\\mathbf{x})=\\log \\int p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\lambda(\\mathbf{z}) \\mathrm{d} \\mathbf{z} .\n","$$\n","\n","The problem here is the intractability of the integral if the dependencies between random variables $\\mathbf{x}$ and $\\mathbf{z}$ are non-linear and/or the distributions are non-Gaussian.\n","\n","By introducing variational posteriors $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$, we get the following lower bound (the Evidence Lower Bound, ELBO):\n","$$\n","\\log p_{\\vartheta}(\\mathbf{x}) \\geq \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}\\left[\\log p_\\theta(\\mathbf{x} \\mid \\mathbf{z})\\right]-\\mathrm{KL}\\left(q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\| p_\\lambda(\\mathbf{z})\\right) .\n","$$"]},{"cell_type":"markdown","metadata":{"id":"suzhlbWqxtD9"},"source":["## IMPORTS"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7030,"status":"ok","timestamp":1719643405132,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"BjxkigYLxpB7"},"outputs":[],"source":["# DO NOT REMOVE!\n","import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import torchvision\n","from torchvision.datasets import MNIST"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1719643405133,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"Cm23hRm6CqGh","outputId":"e8a48507-1db5-4206-8201-278e208e2e6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["The available device is cpu\n"]}],"source":["# Check if GPU is available and determine the device\n","if torch.cuda.is_available():\n","  device = 'cuda'\n","else:\n","  device = 'cpu'\n","\n","print(f'The available device is {device}')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24384,"status":"ok","timestamp":1719643429511,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"81CxONpmMulC","outputId":"b0764e49-34e8-4169-d340-64447b6da1ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["# mount drive: WE NEED IT FOR SAVING IMAGES!\n","from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1719643429512,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"OoPb92zNM4UY"},"outputs":[],"source":["# PLEASE CHANGE IT TO YOUR OWN GOOGLE DRIVE!\n","images_dir = '/content/gdrive/MyDrive/Colab Notebooks/gemss/Results/'"]},{"cell_type":"markdown","metadata":{"id":"I3zs31tOyCmq"},"source":["## Auxiliary functions"]},{"cell_type":"markdown","metadata":{"id":"DF0agzL7tDHK"},"source":["Let us define some useful log-distributions:"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1719643429512,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"LIBNVRNJtHSd"},"outputs":[],"source":["# DO NOT REMOVE\n","PI = torch.from_numpy(np.asarray(np.pi))\n","EPS = 1.e-5\n","\n","\n","def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n","    # Flatten the input x to match the shape of p\n","    x_flat = x.view(-1)\n","    # Ensure x_flat values are within the range [0, num_classes-1]\n","    #x_flat = torch.clamp(x_flat, min=0, max=num_classes-1)\n","\n","    x_one_hot = F.one_hot(x_flat.long(), num_classes=num_classes).float()\n","\n","    # Reshape p to match the shape of x_one_hot\n","    p_flat = p.view(-1, num_classes)\n","\n","    log_p = x_one_hot * torch.log(p_flat)\n","    if reduction == 'mean':\n","        return torch.mean(log_p, dim)\n","    elif reduction == 'sum':\n","        return torch.sum(log_p, dim)\n","    else:\n","        return log_p\n","\n","\n","def log_bernoulli(x, p, reduction='sum', dim=None):\n","    log_p = x * torch.log(p + 1e-8) + (1 - x) * torch.log(1 - p + 1e-8)\n","    if reduction == 'mean':\n","        return torch.mean(log_p, dim=dim)\n","    elif reduction == 'sum':\n","        return torch.sum(log_p, dim=dim)\n","    else:\n","        return log_p\n","\n","\n","def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n","    log_2pi = torch.log(torch.tensor(2.0 * torch.pi))\n","    #log_var_ = log_var + 1e-6  # Avoid too small/large log_var values\n","    log_var_ = log_var.clone()\n","    for i in range(log_var.size(0)):\n","      for j in range(log_var.size(1)):\n","        if log_var[i, j] >1:\n","          log_var_[i, j] = 1\n","        elif log_var[i, j] < -1:\n","          log_var_[i, j] = -1\n","        else:\n","         log_var_[i,j] = log_var[i,j] +1e-6\n","    # Ensure x, mu, and log_var have the correct shape\n","    if x.shape != mu.shape:\n","        raise ValueError(f'Shape mismatch: x shape {x.shape} and mu shape {mu.shape}')\n","\n","    log_p = -0.5 * (log_var_ + ((x - mu) ** 2) / torch.exp(log_var_) + log_2pi)\n","    if reduction == 'mean':\n","        return torch.mean(log_p, dim)\n","    elif reduction == 'sum':\n","        return torch.sum(log_p, dim)\n","    else:\n","        return log_p\n","\n","\n","def log_standard_normal(x, reduction=None, dim=None):\n","    D = x.shape[1]\n","    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n","    if reduction == 'avg':\n","        return torch.mean(log_p, dim)\n","    elif reduction == 'sum':\n","        return torch.sum(log_p, dim)\n","    else:\n","        return log_p\n"]},{"cell_type":"markdown","metadata":{"id":"Q2LLOs0kn7iw"},"source":["## Implementing VAEs\n","\n","The goal of this assignment is to implement four classes:\n","- `Encoder`: this class implements the encoder (variational posterior), $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$.\n","- `Decoder`: this class implements the decoded (the conditional likelihood), $p_{\\theta}(\\mathbf{x}|\\mathbf{z})$.\n","- `Prior`: this class implements the marginal over latents (the prior), $p_{\\lambda}(\\mathbf{z})$.\n","- `VAE`: this class combines all components."]},{"cell_type":"markdown","metadata":{"id":"7cXhOwKAzW6Z"},"source":["### Encoder\n","We start with `Encoder`. Please remember that we assume the Gaussian variational posterior with a diagonal covariance matrix."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":322,"status":"ok","timestamp":1719643442772,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"MrwQXSuEoFfH"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# NOTE: The class must containt the following functions:\n","# (i) reparameterization\n","# (ii) sample\n","# (iii) log_prob\n","# Moreover, forward must return the log-probability of the variational posterior for given x, i.e., log q(z|x)\n","\n","class Encoder(nn.Module):\n","    def __init__(self, encoder_net):  # ADD APPROPRIATE ATTRIBUTES\n","        super(Encoder, self).__init__()\n","\n","        self.encoder = encoder_net\n","        self.max_log_var = 1 # for numerical stability\n","\n","    @staticmethod\n","    def reparameterization(mu, log_var):\n","        std = torch.exp(0.5 * log_var) + 1e-6\n","        eps = torch.randn_like(std)\n","        print(f\"Encodeer - shape reparam mu: {mu.shape}, std: {std.shape}, eps: {eps.shape}\")\n","        return mu + eps * std\n","\n","    def encode(self, x):\n","        if torch.isnan(x).any():\n","          raise ValueError('Input contains NaNs')\n","        mu, log_var = self.encoder(x).chunk(2,dim=1)\n","        log_var_ = log_var.clone()\n","        for i in range(log_var.size(0)):\n","          for j in range(log_var.size(1)):\n","            if log_var[i, j] > self.max_log_var:\n","                log_var_[i, j] = self.max_log_var\n","            elif log_var[i, j] < -self.max_log_var:\n","                log_var_[i, j] = -self.max_log_var\n","            else:\n","              log_var_[i,j] = log_var[i,j] +1e-6\n","        print(f\"Encoder - shape encode mu: {mu.shape}, log_var: {log_var_.shape}\") # BxL, BxL\n","        return mu, log_var_\n","\n","    def sample(self, x=None, mu_e=None, log_var_e=None):\n","        if (mu_e is None) and (log_var_e is None):\n","          mu_e, log_var_e = self.encode(x)\n","        else:\n","          if (mu_e is None) or (log_var_e is None):\n","            raise ValueError('mu and log−var can‘t be None!')\n","\n","        z = Encoder.reparameterization(mu_e, log_var_e)\n","        print(f\"Encodeer - shape sample mu: {mu_e.shape}, log_var: {log_var_e.shape}, z: {z.shape}\")\n","        print(f\"Encoder sample - mu: {mu_e.sum(dim=0)}, log_var: {log_var_e.mean(dim=0)}\")\n","        return z\n","\n","    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n","        if x is not None:\n","            mu_e, log_var_e = self.encode(x)\n","            print(f\"Encoder log_prob - mu_e: {mu_e}, log_var_e: {log_var_e}\")\n","            if torch.isnan(mu_e).any() or torch.isnan(log_var_e).any():\n","                raise ValueError('Found nan in mu_e or log_var_e')\n","            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n","        else:\n","            if (z is None) or (mu_e is None) or (log_var_e is None):\n","                raise ValueError('z or mu_e or log_var_e must be given, if x is not provided')\n","        log_prob_value = log_normal_diag(z, mu_e, log_var_e)\n","        #print(f\"Log probability: {log_prob_value}\")\n","        return log_prob_value\n","\n","    def forward(self, x, type='log_prob'):\n","        assert type in ['sample', 'log_prob'], 'forward pass type should either be sample or log_prob'\n","        if type == 'sample':\n","          return self.sample(x)\n","        else:\n","          return self.log_prob(x)"]},{"cell_type":"markdown","metadata":{"id":"8XVlH5OUzdgJ"},"source":["Please answer the following questions:"]},{"cell_type":"markdown","metadata":{"id":"D1BNAH02zjjt"},"source":["#### Question 1\n","\n","Please explain the reparameterization trick and provide a mathematical formula."]},{"cell_type":"markdown","metadata":{"id":"UlxYq7-gzo_o"},"source":["ANSWER: The trick reparametrizes the latent variable $z$ through some random variable $\\epsilon$ with known simple distribution $p(\\epsilon)$ and a potentially nonlinear transformation $g(x, \\epsilon)$:\n","$$\n","z_i=g(x_i,\\epsilon)\n","$$\n","For example, in case of a Gaussian approximate posterior $\\mathcal{N}(\\mu, \\sigma^2)$, we obtain for $\\epsilon\\sim \\mathcal{N}(0,1)$\n","$$\n","z=\\mu+\\sigma\\epsilon\n","$$\n","In the Gaussian case, the trick allows for backpropagation through the latent space consisting of the parameters $\\mu, \\sigma$, by fixing them and introducing stochasticity only in $\\epsilon$. Additionally, it allows to compute the gradient of the ELBO since the gradients have large variance without reparametrization.\n"]},{"cell_type":"markdown","metadata":{"id":"HpRgXdtBzt3-"},"source":["#### Question 2\n","\n","Please write down mathematically the log-probability of the encoder (variational posterior)."]},{"cell_type":"markdown","metadata":{"id":"ET-mMAg10Ewv"},"source":["ANSWER:\n","$$\n","\\log(p(\\mathbf{z}|\\mathbf{x}))=\\prod_{i=1}^n \\log(p(z_i|x_i))\\\\\n","= \\sum_{i=1}^n -0.5\\log(2\\pi\\sigma_i^2)- \\sum_{i=1}^n\\left(\\frac{(z_i-\\mu)^2}{\\sigma^2}\\right)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"nhNTy5mn0XDT"},"source":["### Decoder\n","\n","The decoder is the conditional likelihood, i.e., $p(x|z)$. Please remember that we must decide on the form of the distribution (e.g., Bernoulli, Gaussian, Categorical)."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":330,"status":"ok","timestamp":1719643473195,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"9vTmKHwrpUVa"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# NOTE: The class must containt the following functions:\n","# (i) sample\n","# (ii) log_prob\n","# Moreover, forward must return the log-probability of the conditional likelihood function for given z, i.e., log p(x|z)\n","# Additionally, please specify the distribution class you want to use for the decode (i.e. the `distribution` attribute)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, decoder_net, distribution='categorical', num_vals=None):\n","        super(Decoder, self).__init__()\n","\n","        self.distribution = distribution\n","        self.decoder_net = decoder_net\n","        self.num_vals = num_vals\n","\n","    def decode(self, z):\n","        assert self.distribution in ['categorical', 'normal', 'bernoulli'], 'Distribution has to be categorical, normal, or bernoulli.'\n","        h_d = self.decoder_net(z)\n","        if self.distribution == 'categorical':\n","            batch_size = h_d.shape[0]\n","            num_pixels = 28 * 28  # Because we are decoding to 28x28 images\n","            assert h_d.shape[1] == num_pixels * self.num_vals, \"Decoder output size mismatch.\"\n","            h_d = h_d.view(batch_size, num_pixels, self.num_vals)\n","            p = torch.softmax(h_d, dim=2)\n","            #print(f\"Decoder decode - categorical p: {p}\")\n","            return p\n","        elif self.distribution == 'normal':\n","            batch_size = h_d.shape[0]\n","            num_pixels = 28 * 28  # Because we are decoding to 28x28 images\n","            h_d = h_d.view(batch_size, num_pixels, 2)  # For normal distribution, we expect 2 outputs per pixel (mu and log_var)\n","            mu, log_var = h_d.chunk(2, dim=2)\n","            mu = mu.view(batch_size, 1, 28, 28)  # Reshape to match the input shape\n","            log_var = log_var.view(batch_size, 1, 28, 28)  # Reshape to match the input shape\n","            #print(f\"Decoder decode - m_u: {mu}, log_var: {log_var}\")\n","            return mu, log_var\n","        else:\n","            p = torch.sigmoid(h_d)\n","            #p = p.view(-1, 1, 28, 28)  # Reshape to match the input image dimensions\n","            #print(f\"Decoder decode - bernoulli p: {p.shape}\")\n","            return p\n","\n","    def sample(self, z):\n","        params = self.decode(z)\n","        if self.distribution == 'categorical':\n","            batch_size = params.shape[0]\n","            num_pixels = params.shape[1]\n","            p = params.view(-1, self.num_vals)\n","            cat_batch_dist = torch.distributions.Categorical(p)\n","            x = cat_batch_dist.sample().view(batch_size, num_pixels)\n","        elif self.distribution == 'bernoulli':\n","            x = torch.bernoulli(params)\n","        else:\n","            mu = params[0]\n","            log_var = params[1]\n","            std = torch.exp(0.5 * log_var)\n","            eps = torch.randn_like(mu)\n","            x = mu + eps * std # Bx1ximage_widthximage_height\n","        #print(f\"Decoder - Sampled x: {x.mean().item()}\")\n","        return x\n","\n","    def log_prob(self, x, z):\n","        if self.distribution == 'categorical':\n","            p = self.decode(z)\n","            log_p = log_categorical(x, p, num_classes=self.num_vals, reduction='sum', dim=-1).sum(dim=-1) #sums first over categories and then over pixel\n","        elif self.distribution == 'normal':\n","            mu, log_var = self.decode(z)\n","            log_p = log_normal_diag(x, mu, log_var, reduction='sum', dim=1) # sums over pixel\n","        else:\n","            p = self.decode(z)\n","            log_p = log_bernoulli(x, p, reduction='sum', dim=-1) # sums over pixel\n","        print(f\"Log probability decoded x shape: {log_p.shape}\")\n","        return log_p\n","\n","    def forward(self, z):\n","        x = self.sample(z)\n","        log_p = self.log_prob(x, z)\n","        return log_p\n"]},{"cell_type":"markdown","metadata":{"id":"5xjbNkNL01DP"},"source":["Please answer the following questions:"]},{"cell_type":"markdown","metadata":{"id":"qjDvPaBj04cA"},"source":["#### Question 3\n","\n","Please explain your choice of distribution for image data used in this assignment. Additionally, please write it down mathematically (if you think that presenting it as the log-probability, then please do it)."]},{"cell_type":"markdown","metadata":{"id":"HLZEzmGI1Ok-"},"source":["ANSWER: I expect the pixel values to lie in $\\{0,\\dots, 255\\}^C$ with C=3 being the number of colour chanels (red, green, blue). Thus, the image data lies in $\\{0,\\dots,255\\}^{C\\times H\\times W}$ with $H$ and $W$ being the height and width of the images. Then, the chosen categorical distribution assigns a probabilities over the whole discrete image space through the density\n","$$\n","p(x)=\\prod_{c=1}^C\\prod_{h=1}^H\\prod_{w=1}^Wp_{chw}(x_{chw})\n","$$\n","where the pixelwise discrete density is $p_{chw}(x_{chw})=\\prod_{j=0}^{255}p_{chw,j}^{[x_{chw}=j]}$. The corresponding log-probability is thus\n","$$\n","\\log(p(x))=\\sum_{c=1}^C\\sum_{h=1}^H\\sum_{w=1}^W\\sum_{j=0}^{255}1[x_{chw}=j]\\log p_{chw,j}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"RhbWamId1eGt"},"source":["#### Question 4\n","\n","Please explain how one can sample from the distribution chosen by you. Please be specific and formal (i.e., provide mathematical formulae)."]},{"cell_type":"markdown","metadata":{"id":"JB4S8vJ96-Xv"},"source":["To sample an image from the distribution given parameters $p_{chw,j}$, we sample pixelwise from the Multinomial distributions with parameters $n=256, p=(p_{chw,j})_{j=1,\\dots,256})$ and combine all values over all chanels, height and width of the image.\n","\n","To sample in the case of a VAE from the distribution given $\\mathbf{z}$ from the latent space, we decode $z$ first to obtain $\\mathbf{p}$ and afterwards sample from as above with the parameters given in this $\\mathbf{p}$."]},{"cell_type":"markdown","metadata":{"id":"CLIEwIiw00op"},"source":["### Prior\n","\n","The prior is the marginal distribution over latent variables, i.e., $p(z)$. It plays a crucial role in the generative process and also in synthesizing images of better quality.\n","\n","In this assignment, you are asked to implement a prior that is learnable (e.g., parameterized by neural networks). If you decide to implement the standard Gaussian prior only, then please be aware that you will not get any points.\n","\n","For the learnable prior you can choose the **Mixture of Gaussians**."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":296,"status":"ok","timestamp":1719643478981,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"xQIvee5Cp69V"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# NOTES:\n","# (i) The function \"sample\" must be implemented.\n","# (ii) The function \"forward\" must return the log-probability, i.e., log p(z)\n","\n","class Prior(nn.Module):\n","    def __init__(self, L, components, device='cpu'):\n","        super(Prior, self).__init__()\n","        self.L = L\n","        self.components = components\n","\n","        self.weights = nn.Parameter(torch.ones(components) / components)\n","        self.means = nn.Parameter(torch.randn(components, L))\n","        self.log_vars = nn.Parameter(torch.randn(components, L))\n","\n","        # Initialize log_vars with small values to avoid numerical instabilities\n","        #nn.init.constant_(self.log_vars, -1.0)\n","\n","    def sample(self, batch_size):\n","        cat_dist = torch.distributions.Categorical(self.weights)\n","        component_indices = cat_dist.sample((batch_size,))\n","        samples = []\n","\n","        for i in range(batch_size):\n","            idx = component_indices[i]\n","            mean = self.means[idx]\n","            log_var = self.log_vars[idx]\n","            std = torch.exp(0.5 * log_var)\n","            std_ = std +1e-6  # Ensure std is not too small\n","            eps = torch.randn_like(mean)\n","            sample = mean + eps * std_\n","            samples.append(sample)\n","\n","        return torch.stack(samples, dim=0)\n","\n","    def log_prob(self, z):\n","        log_probs = []\n","        for i in range(self.components):\n","            mean = self.means[i]\n","            log_var = self.log_vars[i]\n","            #print(f\"Prior logprob - mean: {mean.sum(dim=0)}, log_var: {log_var.sum(dim=0)}\")\n","            std = torch.exp(0.5 * log_var)\n","            std_ = std+1e-6  # Ensure std is not too small\n","            mvn = torch.distributions.MultivariateNormal(mean, torch.diag(std_**2))\n","            log_prob = mvn.log_prob(z)\n","            log_prob = log_prob+torch.log(self.weights[i])\n","            log_probs.append(log_prob)\n","\n","        log_probs = torch.stack(log_probs, dim=1)\n","        log_prob_value = torch.logsumexp(log_probs, dim=1)\n","        #print(f\"Prior log probability: {log_prob_value.sum(dim=0)}\")\n","        return log_prob_value\n","\n","    def forward(self, z):\n","        return self.log_prob(z)"]},{"cell_type":"code","source":["class Prior(nn.Module):\n","    def __init__(self, L):\n","        super(Prior, self).__init__()\n","        self.L = L\n","\n","    def sample(self, batch_size):\n","        z = torch.randn((batch_size, self.L))\n","        return z\n","\n","    def log_prob(self, z):\n","        return log_standard_normal(z)"],"metadata":{"id":"6f01uhxJtEXq","executionInfo":{"status":"ok","timestamp":1719643499338,"user_tz":-120,"elapsed":436,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z0KH9f2O_PDg"},"source":["#### Question 5\n","\n","**Option 1:  Standard Gaussian**\n","\n","- Please explain the choice of your prior and write it down mathematically.\n","\n","**Option 2: Mixture of Gaussians**\n","\n","Please do the following:\n","- Please explain the choice of your prior and write it down mathematically.\n","- Please write down its sampling procedure (if necessary, please add a code snippet).\n","- Please write down its log-probability (a mathematical formula)."]},{"cell_type":"markdown","metadata":{"id":"DLVPs3tMbDUi"},"source":["Option 2: The MoG prior is chosen to allow for a trainable prior compared to the Standard Gaussian. The standard Gaussian can lead to holes in the high probability regions of the prior which are poorly covered by the approximate posterior and thus, poorly generated images for samples from these holes. The MoG is given by\n","$$\n","p_\\lambda(z)=\\sum_{k=1}^Kw_k\\mathcal{N}(z|\\mu_k,\\sigma_k^2)\n","$$\n","where $\\lambda=(\\{w_k\\},\\{\\mu_k\\}, \\{\\sigma^2_k\\}) are the learnable parameters. The MoG avoids holes between prior and approximate posterior compared to the standard Gaussian.\n","\n","We can sample from the MoG by sampling first the component $k$ from a Multinomial distribution with probabilities given in $w_k$ and afterwards sampling from the normal distribution of this component, i.e. $\\mathcal{N}(\\mu_k,\\sigma^2_k)$.\n","\n","The log-probability for L-dimensional Gaussian distributions with diagonal covariance matrix is given by\n","$$\n","\\log(p(z))=\\log(\\sum_{k=1}^K w_k pdf(z|\\mu_k,\\sigma_k^2))\\\\\n","pdf(z|\\mu_k, \\sigma_k^2)=\\prod_{d=1}^D\\frac{1}{\\sqrt{2\\pi\\sigma_{k,d}^2}}\\exp(-\\frac{(z_d-\\mu_{k,d})^2}{2\\sigma_{k,d}^2})\n","$$"]},{"cell_type":"markdown","metadata":{"id":"aOM4QM9I_62d"},"source":["### Complete VAE\n","\n","The last class is `VAE` tha combines all components. Please remember that this class must implement the **Negative ELBO** in `forward`, as well as `sample` (*hint*: it is a composition of `sample` functions from the prior and the decoder)."]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":310,"status":"ok","timestamp":1719650345659,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"OQpf-BeSqA6V"},"outputs":[],"source":["# YOUR CODE GOES HERE\n","# This class combines Encoder, Decoder and Prior.\n","# NOTES:\n","# (i) The function \"sample\" must be implemented.\n","# (ii) The function \"forward\" must return the negative ELBO. Please remember to add an argument \"reduction\", which is either \"mean\" or \"sum\".\n","class VAE(nn.Module):\n","    def __init__(self, encoder, decoder, prior): # ADD APPROPRIATE ATTRIBUTES IF NECESSARY\n","        super(VAE, self).__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.prior = prior\n","\n","        # FILL IN\n","\n","    def sample(self, x=None, batch_size=64):\n","        z = self.prior.sample(batch_size)\n","        x_new = self.decoder.decode(z)\n","        return x_new\n","\n","    def forward(self, x, reduction='mean'):\n","        mu_e,log_var_e = self.encoder.encode(x)\n","        z = self.encoder.sample(mu_e=mu_e,log_var_e=log_var_e)\n","        re = self.decoder.log_prob(x,z)\n","\n","        kl_prior = self.prior.log_prob(z)\n","        kl_encoder = self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)\n","        assert kl_prior.shape == kl_encoder.shape, f\"Shape mismatch: {kl_prior.shape} vs {kl_encoder.shape}\"\n","        kl = (kl_prior - kl_encoder).mean(-1)\n","\n","        elbo = -(re+kl)\n","        print(f\"current elbo {elbo.mean()}\")\n","        if reduction=='mean':\n","          return elbo.mean()\n","        else:\n","          return elbo.sum()\n"]},{"cell_type":"markdown","metadata":{"id":"U9axMlEkAYN5"},"source":["#### Question 6\n","\n","Please explain your choice of the distribution for the conditional likelihood function, and write down mathematically the log-probability of the decoder."]},{"cell_type":"markdown","metadata":{"id":"BgbEJm8FAuze"},"source":["ANSWER: This is determined by the distribution chosen in the decoder and was given in question 3."]},{"cell_type":"markdown","metadata":{"id":"eaJgXPYyAmeJ"},"source":["#### Question 7\n","\n","Please write down mathematically the **Negative ELBO**."]},{"cell_type":"markdown","metadata":{"id":"THYyO-G7AkSQ"},"source":["ANSWER:\n","$$\n","-ELBO=-\\mathbb{E}_{z\\sim q_\\phi(z|x)}[\\log (p_\\theta(x|z))]+KL(p_\\psi(z)||q_\\phi(z|x))\\\\\n","=\\int \\sum_{c=1}^C\\sum_{h=1}^H\\sum_{w=1}^W\\sum_{j=0}^{255}1[x_{chw}=j]\\log p_{chw,j}\\sum_{k=1}^K w_k \\prod_{d=1}^D\\frac{1}{\\sqrt{2\\pi\\sigma_{k,d}^2}}\\exp(-\\frac{(z_d-\\mu_{k,d})^2}{2\\sigma_{k,d}^2})d\\mathbf{z}\n","- \\mathbb{E}_{q_\\phi(z|x)}[\\log(q_\\phi(z|x))-\\log(p_\\psi(z))]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"hLhgze7DA4yx"},"source":["### Evaluation and training functions\n","\n","**Please DO NOT remove or modify them.**"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":299,"status":"ok","timestamp":1719650376878,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"I9Dr3a6lqJ0W"},"outputs":[],"source":["# ==========DO NOT REMOVE==========\n","\n","def evaluation(test_loader, name=None, model_best=None, epoch=None):\n","    # EVALUATION\n","    if model_best is None:\n","        # load best performing model\n","        model_best = torch.load(name + '.model')\n","\n","    model_best.eval()\n","    loss = 0.\n","    N = 0.\n","    for indx_batch, (test_batch, _) in enumerate(test_loader):\n","        test_batch = test_batch.to(device)\n","        loss_t = model_best.forward(test_batch, reduction='sum')\n","        loss = loss + loss_t.item()\n","        N = N + test_batch.shape[0]\n","    loss = loss / N\n","\n","    if epoch is None:\n","        print(f'FINAL LOSS: nll={loss}')\n","    else:\n","        print(f'Epoch: {epoch}, val nll={loss}')\n","\n","    return loss\n","\n","\n","def samples_real(name, test_loader, shape=(28,28)):\n","    # real images-------\n","    num_x = 4\n","    num_y = 4\n","    x, _ = next(iter(test_loader))\n","    x = x.to('cpu').detach().numpy()\n","\n","    fig, ax = plt.subplots(num_x, num_y)\n","    for i, ax in enumerate(ax.flatten()):\n","        plottable_image = np.reshape(x[i], shape)\n","        ax.imshow(plottable_image, cmap='gray')\n","        ax.axis('off')\n","\n","    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n","    plt.close()\n","\n","\n","def samples_generated(name, data_loader, shape=(28,28), extra_name=''):\n","    x, _ = next(iter(data_loader))\n","    x = x.to('cpu').detach().numpy()\n","\n","    # generations-------\n","    model_best = torch.load(name + '.model')\n","    model_best.eval()\n","\n","    num_x = 4\n","    num_y = 4\n","    x = model_best.sample(num_x * num_y)\n","    x = x.to('cpu').detach().numpy()\n","\n","    fig, ax = plt.subplots(num_x, num_y)\n","    for i, ax in enumerate(ax.flatten()):\n","        plottable_image = np.reshape(x[i], shape)\n","        ax.imshow(plottable_image, cmap='gray')\n","        ax.axis('off')\n","\n","    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n","    plt.close()\n","\n","\n","def plot_curve(name, nll_val):\n","    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n","    plt.xlabel('epochs')\n","    plt.ylabel('nll')\n","    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n","    plt.close()"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":421,"status":"ok","timestamp":1719650379863,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"9ABgMeG0qFAP"},"outputs":[],"source":["# ==========DO NOT REMOVE==========\n","\n","def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader, shape=(28,28)):\n","    nll_val = []\n","    best_nll = 1000.\n","    patience = 10\n","\n","    # Main loop\n","    for e in range(num_epochs):\n","        # TRAINING\n","        model.train()\n","        for indx_batch, (batch, _) in enumerate(training_loader):\n","            batch = batch.to(device)\n","            loss = model.forward(batch, reduction='mean')\n","\n","            optimizer.zero_grad()\n","\n","            with torch.cuda.amp.autocast():\n","                loss = model.forward(batch, reduction='mean')\n","\n","            print(f\"Epoch {e}, Batch {indx_batch} - Training loss: {loss.item()}\")\n","            scaler.scale(loss).backward()\n","            # Clip gradients\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","            scaler.step(optimizer)\n","            scaler.update()\n","            #loss.backward()\n","            optimizer.step()\n","\n","        # Validation\n","        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n","        nll_val.append(loss_val)  # save for plotting\n","        scheduler.step(loss)\n","\n","        if e == 0:\n","            print('saved!')\n","            torch.save(model, name + '.model')\n","            best_nll = loss_val\n","        else:\n","            if loss_val < best_nll:\n","                print('saved!')\n","                torch.save(model, name + '.model')\n","                best_nll = loss_val\n","                patience = 0\n","\n","                samples_generated(name, val_loader, shape=shape, extra_name=\"_epoch_\" + str(e))\n","            else:\n","                patience = patience + 1\n","\n","        if patience > max_patience:\n","            break\n","\n","    nll_val = np.asarray(nll_val)\n","\n","    return nll_val"]},{"cell_type":"markdown","metadata":{"id":"kWr8N2u2qNTu"},"source":["### Setup\n","\n","**NOTE: *Please comment your code! Especially if you introduce any new variables (e.g., hyperparameters).***\n","\n","In the following cells, we define `transforms` for the dataset. Next, we initialize the data, a directory for results and some fixed hyperparameters."]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":320,"status":"ok","timestamp":1719650382926,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"bFTE5jtYpxDV"},"outputs":[],"source":["# PLEASE DEFINE APPROPRIATE TRANFORMS FOR THE DATASET\n","# (If you don't see any need to do that, then you can skip this cell)\n","# HINT: Please prepare your data accordingly to your chosen distribution in the decoder\n","class BernoulliTransform:\n","    def __call__(self, img):\n","        # Convert to tensor if not already\n","        if not isinstance(img, torch.Tensor):\n","            img = torchvision.transforms.ToTensor()(img)\n","        # Apply a threshold to binarize the image\n","        img = (img > 0.5).float()\n","        # Flatten the image\n","        return img.view(-1)\n","\n","# Define the transformation pipeline for training and testing\n","transforms_train = torchvision.transforms.Compose([\n","    BernoulliTransform()\n","])\n","\n","transforms_test = torchvision.transforms.Compose([\n","    BernoulliTransform()\n","])"]},{"cell_type":"markdown","metadata":{"id":"8SDcOBbGCM8z"},"source":["Please do not modify the code in the next cell."]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":833,"status":"ok","timestamp":1719650409476,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"UXHitzrYqNhY"},"outputs":[],"source":["# ==========DO NOT REMOVE==========\n","#-dataset\n","dataset = MNIST('/files/', train=True, download=True,\n","                      transform=transforms_train\n","                )\n","\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [50000, 10000], generator=torch.Generator().manual_seed(14))\n","\n","test_dataset = MNIST('/files/', train=False, download=True,\n","                      transform=transforms_test\n","                     )\n","#-dataloaders\n","batch_size = 128\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","#-creating a dir for saving results\n","name = 'vae'\n","result_dir = images_dir +  name + '/'\n","if not(os.path.exists(result_dir)):\n","    os.mkdir(result_dir)\n","\n","#-hyperparams (please do not modify them!)\n","num_epochs = 100 # max. number of epochs\n","max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1719650411297,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"iJde8aLSCN_x","outputId":"e6318ff9-59ca-4c78-e4f8-ef776d7133c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Scale of values in the image tensor: Min=0.0, Max=1.0\n","Shape of the image tensor: torch.Size([784])\n"]}],"source":["# Function to get one image and output the scale of values\n","def get_image_scale(data_loader):\n","    # Get one batch from the data loader\n","    data_iter = iter(data_loader)\n","    images, labels = next(data_iter)\n","\n","    # Get the image tensor\n","    image_tensor = images[0]\n","\n","    # Find the minimum and maximum values\n","    min_value = torch.min(image_tensor).item()\n","    max_value = torch.max(image_tensor).item()\n","\n","    # Get the shape of the image\n","    image_shape = image_tensor.shape\n","\n","    return min_value, max_value, image_shape\n","\n","# Use the function to get the scale and shape of one image\n","min_value, max_value, image_shape = get_image_scale(train_loader)\n","print(f\"Scale of values in the image tensor: Min={min_value}, Max={max_value}\")\n","print(f\"Shape of the image tensor: {image_shape}\")"]},{"cell_type":"markdown","metadata":{"id":"kmKDXMI0B231"},"source":["In the next cell, please initialize the model. Please remember about commenting your code!"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":294,"status":"ok","timestamp":1719650413945,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"b73aaBDxqSYb"},"outputs":[],"source":["# BASIC HYPERPARAMETERS\n","D = 784   # input dimension\n","L = 16  # number of latents\n","\n","# model definition\n","likelihood_type = 'bernoulli'\n","num_vals = 128\n","\n","# YOUR CODE COMES HERE:\n","# FILL IN ANY OTHER HYPERPARAMS YOU WANT TO USE\n","encoder_net = nn.Sequential(\n","    nn.Linear(D, 128),\n","    nn.BatchNorm1d(128),\n","    nn.LeakyReLU(negative_slope=0.01),\n","    nn.Linear(128, L * 2)\n",")\n","\n","decoder_net = nn.Sequential(\n","    nn.Linear(L, 128),\n","    nn.BatchNorm1d(128),\n","    nn.LeakyReLU(negative_slope=0.01),\n","    nn.Linear(128, D)\n",")\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.kaiming_normal_(m.weight, nonlinearity='leaky_relu')\n","        if m.bias is not None:\n","            nn.init.constant_(m.bias, 0)\n","\n","encoder_net.apply(weights_init)\n","decoder_net.apply(weights_init)\n","\n","encoder = Encoder(encoder_net)\n","decoder = Decoder(decoder_net, distribution=likelihood_type, num_vals=num_vals)\n","prior = Prior(L)#, components = 10)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1300,"status":"ok","timestamp":1719650417397,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"EcWTKcZmDp_w","outputId":"be1c6ec0-46df-4e00-bc8f-684c7b8332fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encoded mu: tensor([  72.0912,  -92.5759,  -35.5726,   43.4661,  -25.9087,  -56.8831,\n","          36.4583,  -36.9240,   79.2244,   48.4998,  -42.0737,  -71.3282,\n","        -114.8711,  -61.9158,  -91.1359,  -10.1994], grad_fn=<SumBackward1>)\n","Encoded log_var: tensor([1.0784e-10, 3.5608e+10, 1.4991e-08, 9.5088e-01, 3.9873e+00, 2.4372e-07,\n","               inf, 2.8232e+09, 6.1082e-21, 5.7335e-08, 5.8833e-16, 6.7619e+15,\n","        6.0667e-06, 3.6472e-25, 1.5389e+03, 2.8256e-40],\n","       grad_fn=<ExpBackward0>)\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  69.0373,  -94.7525,  -36.0233,   44.8070,  -23.0412,  -57.8658,\n","          40.3227,  -37.0646,   76.6539,   47.0504,  -40.6911,  -70.5299,\n","        -116.9537,  -63.5888,  -87.4190,   -4.9541], grad_fn=<SumBackward1>), log_var: tensor([-0.1556,  0.1737, -0.1261, -0.0170,  0.0380, -0.1039,  0.7976,  0.1732,\n","        -0.3410, -0.1250, -0.2874,  0.2517, -0.1287, -0.4022,  0.0447, -0.7105],\n","       grad_fn=<MeanBackward1>)\n","Sampled z: tensor([[-0.4170,  1.9200,  0.2630,  ..., -1.1227, -0.0837,  0.6991],\n","        [ 0.7491,  1.0467, -0.2390,  ..., -1.4511, -1.0844,  0.7520],\n","        [-0.6954,  2.5240, -0.6195,  ...,  0.4557,  0.0050, -0.5055],\n","        ...,\n","        [ 0.8831, -0.6630,  0.0972,  ..., -0.7703,  1.5053, -0.4095],\n","        [ 2.9715, -1.5275, -0.1939,  ...,  1.8971,  0.0034, -0.0698],\n","        [ 3.4351,  0.4321,  1.3971,  ..., -1.3043,  0.2528,  0.4821]],\n","       grad_fn=<AddBackward0>)\n"]}],"source":["# Function to take one image from the training data loader and encode it\n","def encode_one_image(data_loader, encoder):\n","    data_iter = iter(data_loader)\n","    images, labels = next(data_iter)\n","\n","    # Flatten the image\n","    images = images.view(images.size(0), -1)\n","\n","    # Encode the image\n","    mu, log_var = encoder.encode(images)\n","    return mu, log_var\n","\n","# Get one image from the training data loader and encode it\n","mu, log_var = encode_one_image(train_loader, encoder)\n","print(f\"Encoded mu: {mu.sum(dim=0)}\")\n","print(f\"Encoded log_var: {torch.exp(log_var.sum(dim=0))}\")\n","\n","# Function to take one image from the training data loader and pass it through the sample function\n","def sample_one_image(data_loader, encoder):\n","    data_iter = iter(data_loader)\n","    images, labels = next(data_iter)\n","\n","    # Flatten the image\n","    images = images.view(images.size(0), -1)\n","\n","    # Pass the image through the sample function\n","    z = encoder.sample(x=images)\n","    return z\n","\n","# Get one image from the training data loader and pass it through the sample function\n","z = sample_one_image(train_loader, encoder)\n","print(f\"Sampled z: {z}\")"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1719650420096,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"SGSaa3MKGksp","outputId":"efae8859-9e73-40da-b104-9a14dd2e18cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of sampled images from bernoulli decoder: torch.Size([64, 784])\n"]}],"source":["# Initialize the decoders for each distribution type\n","### Change also last layer of decoder net before checking\n","decoder_categorical = Decoder(decoder_net, distribution='categorical', num_vals=10)\n","decoder_normal = Decoder(decoder_net, distribution='normal')\n","decoder_bernoulli = Decoder(decoder_net, distribution='bernoulli')\n","\n","# Function to sample from the decoder and return the shape of the sampled images\n","def sample_from_decoder(decoder, latent_dim):\n","    # Generate random latent vectors\n","    z = torch.randn((64, 16))  # Change (1, latent_dim) to match your batch size and latent dimension\n","    sampled_images = decoder.sample(z)\n","    return sampled_images.shape\n","\n","# Sample from each decoder and print the shape of the sampled images\n","#shape_categorical = sample_from_decoder(decoder_categorical, L)\n","#shape_normal = sample_from_decoder(decoder_normal, L)\n","shape_bernoulli = sample_from_decoder(decoder_bernoulli, L)\n","#print(f\"Shape of sampled images from normal decoder: {shape_normal}\")\n","#print(f\"Shape of sampled images from categorical decoder: {shape_categorical}\")\n","print(f\"Shape of sampled images from bernoulli decoder: {shape_bernoulli}\")"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1719650431062,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"N5kdnqbiSDmq","outputId":"bead6840-ba34-43dd-af29-9518454b3bfa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["VAE(\n","  (encoder): Encoder(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=784, out_features=128, bias=True)\n","      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Linear(in_features=128, out_features=32, bias=True)\n","    )\n","  )\n","  (decoder): Decoder(\n","    (decoder_net): Sequential(\n","      (0): Linear(in_features=16, out_features=128, bias=True)\n","      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Linear(in_features=128, out_features=784, bias=True)\n","    )\n","  )\n","  (prior): Prior()\n",")"]},"metadata":{},"execution_count":46}],"source":["# INIT YOUR VAE (PLEASE CALL IT model)\n","# AN EXAMPLE: model = VAE(encoder, decoder, likelihood_type=likelihood_type, ...)\n","\n","model = VAE(encoder, decoder, prior)\n","\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"iC8AkWt4CURT"},"source":["Please initialize the optimizer"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":636,"status":"ok","timestamp":1719650434249,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"},"user_tz":-120},"id":"a3nTSDe7ql08","outputId":"b436d39c-dba1-4583-bc6d-9bea26fcc027"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n","  warnings.warn(\n"]}],"source":["# PLEASE DEFINE YOUR OPTIMIZER\n","lr = 1e-4 # learning rate (PLEASE CHANGE IT AS YOU WISH!)\n","optimizer = torch.optim.Adamax(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n","\n","# Free up unused GPU memory\n","torch.cuda.empty_cache()\n","\n","# Initialize mixed precision scaler\n","scaler = torch.cuda.amp.GradScaler()\n"]},{"cell_type":"markdown","metadata":{"id":"79odxtRjCaix"},"source":["#### Question 8\n","\n","Please explain the choice of the optimizer, and comment on the choice of the hyperparameters (e.g., the learing reate value)."]},{"cell_type":"markdown","metadata":{"id":"cEjOlYN9Ft_B"},"source":["ANSWER: [Please fill in]"]},{"cell_type":"markdown","metadata":{"id":"P5GrzUcHFweG"},"source":["### Training and final evaluation\n","\n","In the following two cells, we run the training and the final evaluation."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD7WuY6bqnBK","executionInfo":{"status":"error","timestamp":1719655794415,"user_tz":-120,"elapsed":3086303,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"}},"outputId":"85675913-576d-4f3c-afd8-8b0e3d233c28"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  70.1159,  -93.7433,  -35.2272,   42.0663,  -23.3392,  -56.0929,\n","          40.4631,  -40.5474,   78.8917,   47.3549,  -39.9378,  -70.3841,\n","        -116.9075,  -62.1597,  -87.8629,   -6.1137], grad_fn=<SumBackward1>), log_var: tensor([-2.0035e-01,  2.1343e-01, -7.9942e-02, -1.9516e-02, -5.6038e-04,\n","        -7.2885e-02,  8.1129e-01,  1.4743e-01, -3.8203e-01, -1.0644e-01,\n","        -3.0491e-01,  2.7606e-01, -7.6015e-02, -3.7994e-01,  4.6540e-02,\n","        -6.9909e-01], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 645.93505859375\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.9879,   1.5125,  -1.0437,   4.2025,  -1.5532,  -5.6065,  -3.5680,\n","          2.6841, -10.9007,   8.9949,   5.9231,   4.1927,  -1.2016,   6.3027,\n","         -1.6027,   3.6302], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.0560302734375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.9879,   1.5125,  -1.0437,   4.2025,  -1.5532,  -5.6065,  -3.5680,\n","          2.6841, -10.9007,   8.9949,   5.9231,   4.1927,  -1.2016,   6.3027,\n","         -1.6027,   3.6302], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.76360321044922\n","Epoch 13, Batch 75 - Training loss: 113.76360321044922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1311,  1.6962, -0.0357,  1.4330,  3.7255, -3.3742,  2.9672,  0.6683,\n","        -9.7904,  4.3568,  4.3697,  1.6675, -1.1489,  3.2728, -1.4896,  1.1329],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.15707397460938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1311,  1.6962, -0.0357,  1.4330,  3.7255, -3.3742,  2.9672,  0.6683,\n","        -9.7904,  4.3568,  4.3697,  1.6675, -1.1489,  3.2728, -1.4896,  1.1329],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.83330535888672\n","Epoch 13, Batch 76 - Training loss: 115.83330535888672\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.0210,  0.4497,  1.3450,  4.4439,  2.2635,  0.2493, -3.1179,  3.0126,\n","        -8.2981,  4.8386,  6.8242,  4.8673,  3.6178,  8.0503, -2.4538,  6.2804],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9970, -0.9976,\n","        -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -0.9995, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.84151458740234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.0210,  0.4497,  1.3450,  4.4439,  2.2635,  0.2493, -3.1179,  3.0126,\n","        -8.2981,  4.8386,  6.8242,  4.8673,  3.6178,  8.0503, -2.4538,  6.2804],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9970, -0.9976,\n","        -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -0.9995, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.68003845214844\n","Epoch 13, Batch 77 - Training loss: 112.68003845214844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.6147,  -0.9527,   0.8665,   3.2808,   1.9225,  -1.2999,  -0.7782,\n","         -0.0378, -10.4622,   0.9539,   4.1625,   1.3686,  -1.1021,  -3.6174,\n","         -5.0909,   1.2372], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.7945556640625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.6147,  -0.9527,   0.8665,   3.2808,   1.9225,  -1.2999,  -0.7782,\n","         -0.0378, -10.4622,   0.9539,   4.1625,   1.3686,  -1.1021,  -3.6174,\n","         -5.0909,   1.2372], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.81822204589844\n","Epoch 13, Batch 78 - Training loss: 118.81822204589844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.2357,  1.0875, -0.6947,  6.1831,  4.8557, -1.0431, -1.1085, -0.2346,\n","        -7.2978,  5.6433,  6.1951,  4.3634, -1.4182,  3.1112, -7.2050,  9.2530],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9985, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.4388198852539\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.2357,  1.0875, -0.6947,  6.1831,  4.8557, -1.0431, -1.1085, -0.2346,\n","        -7.2978,  5.6433,  6.1951,  4.3634, -1.4182,  3.1112, -7.2050,  9.2530],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9985, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.27153778076172\n","Epoch 13, Batch 79 - Training loss: 115.27153778076172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.8976,  -0.1339,  -1.9650,   4.5856,   6.1402,  -0.9581,  -3.2718,\n","          1.5216, -10.9874,   4.6507,   6.5315,   1.3274,  -0.7416,   4.7871,\n","         -2.2835,   9.8583], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9954,\n","        -1.0000, -1.0000, -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.37816619873047\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.8976,  -0.1339,  -1.9650,   4.5856,   6.1402,  -0.9581,  -3.2718,\n","          1.5216, -10.9874,   4.6507,   6.5315,   1.3274,  -0.7416,   4.7871,\n","         -2.2835,   9.8583], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9954,\n","        -1.0000, -1.0000, -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.64862060546875\n","Epoch 13, Batch 80 - Training loss: 118.64862060546875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.8328,   4.7320,  -1.4185,   3.4314,   5.5188,  -4.3297,  -0.0150,\n","          0.2551, -12.5728,   6.6859,   0.1237,   4.3181,   0.6102,   2.3215,\n","         -5.8450,   5.2596], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.81864929199219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.8328,   4.7320,  -1.4185,   3.4314,   5.5188,  -4.3297,  -0.0150,\n","          0.2551, -12.5728,   6.6859,   0.1237,   4.3181,   0.6102,   2.3215,\n","         -5.8450,   5.2596], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.29325103759766\n","Epoch 13, Batch 81 - Training loss: 119.29325103759766\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.7869,   5.2469,   3.8261,   5.3239,   6.7231,  -4.4747,  -2.1875,\n","          5.9447, -11.7797,   7.0124,   3.1451,   4.4909,  -0.6877,   2.4912,\n","         -3.2663,   6.3778], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.39360809326172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.7869,   5.2469,   3.8261,   5.3239,   6.7231,  -4.4747,  -2.1875,\n","          5.9447, -11.7797,   7.0124,   3.1451,   4.4909,  -0.6877,   2.4912,\n","         -3.2663,   6.3778], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.94144439697266\n","Epoch 13, Batch 82 - Training loss: 119.94144439697266\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.9841,  0.3566,  1.6817,  5.8593,  7.8503,  1.3548, -2.1464,  2.9580,\n","        -8.1083,  8.9066,  0.2005,  1.7452, -1.6888,  4.8948, -0.9116,  8.6470],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.42159271240234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.9841,  0.3566,  1.6817,  5.8593,  7.8503,  1.3548, -2.1464,  2.9580,\n","        -8.1083,  8.9066,  0.2005,  1.7452, -1.6888,  4.8948, -0.9116,  8.6470],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.11956787109375\n","Epoch 13, Batch 83 - Training loss: 115.11956787109375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.3233,   1.5972,  -1.1011,   6.0859,   1.9923,  -1.9236,  -2.3108,\n","          3.6524, -13.4489,   3.3433,   2.7455,   3.6377,  -3.0878,   1.0989,\n","         -3.8596,   5.4251], grad_fn=<SumBackward1>), log_var: tensor([-0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9986,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.19486999511719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.3233,   1.5972,  -1.1011,   6.0859,   1.9923,  -1.9236,  -2.3108,\n","          3.6524, -13.4489,   3.3433,   2.7455,   3.6377,  -3.0878,   1.0989,\n","         -3.8596,   5.4251], grad_fn=<SumBackward1>), log_var: tensor([-0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9986,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.54722595214844\n","Epoch 13, Batch 84 - Training loss: 114.54722595214844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.2718,   1.1642,  -1.4869,   3.4860,   6.0330,   0.4273,  -2.5564,\n","          2.3814, -10.0945,   0.6139,   2.1498,   3.0858,   0.0317,   8.2223,\n","         -0.3679,   6.2104], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.16404724121094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.2718,   1.1642,  -1.4869,   3.4860,   6.0330,   0.4273,  -2.5564,\n","          2.3814, -10.0945,   0.6139,   2.1498,   3.0858,   0.0317,   8.2223,\n","         -0.3679,   6.2104], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.79029083251953\n","Epoch 13, Batch 85 - Training loss: 118.79029083251953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.3462,  2.4345, -3.3142,  0.5861, -0.1306, -0.6957,  3.0475,  4.1727,\n","        -6.6074,  5.7524,  5.9374,  6.3171, -0.7406,  1.5090, -2.4677,  5.8726],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.12688446044922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.3462,  2.4345, -3.3142,  0.5861, -0.1306, -0.6957,  3.0475,  4.1727,\n","        -6.6074,  5.7524,  5.9374,  6.3171, -0.7406,  1.5090, -2.4677,  5.8726],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.091552734375\n","Epoch 13, Batch 86 - Training loss: 118.091552734375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.4586,   0.7098,   4.6743,   9.2990,   7.0073,  -3.3919,  -1.2392,\n","          4.7602, -11.3750,   1.8237,   8.0385,   4.1239,  -1.9101,   0.4975,\n","         -1.8821,  12.3533], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -0.9980, -1.0000,\n","        -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.19384765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.4586,   0.7098,   4.6743,   9.2990,   7.0073,  -3.3919,  -1.2392,\n","          4.7602, -11.3750,   1.8237,   8.0385,   4.1239,  -1.9101,   0.4975,\n","         -1.8821,  12.3533], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -0.9980, -1.0000,\n","        -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.51431274414062\n","Epoch 13, Batch 87 - Training loss: 114.51431274414062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.7674,  0.7855, -0.0521,  7.1385,  6.0008, -5.8489,  1.1439,  1.7881,\n","        -9.9235,  7.5982,  6.6777,  4.5679, -5.3056,  4.3854, -1.8549,  6.7107],\n","       grad_fn=<SumBackward1>), log_var: tensor([-0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.26624298095703\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.7674,  0.7855, -0.0521,  7.1385,  6.0008, -5.8489,  1.1439,  1.7881,\n","        -9.9235,  7.5982,  6.6777,  4.5679, -5.3056,  4.3854, -1.8549,  6.7107],\n","       grad_fn=<SumBackward1>), log_var: tensor([-0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.94286346435547\n","Epoch 13, Batch 88 - Training loss: 115.94286346435547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.7296,  1.0792, -0.4316,  3.8137,  5.9796, -7.0078, -0.4861, -0.5599,\n","        -9.4459,  2.2933,  7.3694,  2.0313, -6.1292, -1.9603, -2.7344,  9.0087],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9994, -0.9956, -0.9977],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.57022094726562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.7296,  1.0792, -0.4316,  3.8137,  5.9796, -7.0078, -0.4861, -0.5599,\n","        -9.4459,  2.2933,  7.3694,  2.0313, -6.1292, -1.9603, -2.7344,  9.0087],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9994, -0.9956, -0.9977],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.26849365234375\n","Epoch 13, Batch 89 - Training loss: 117.26849365234375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.3717, -0.3520, -5.0350,  6.4137,  4.4111,  1.7371, -1.6478,  4.2046,\n","        -7.8308,  7.3766,  1.7295,  3.5195,  0.3470,  4.4601, -1.1241, 10.3553],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.12810516357422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.3717, -0.3520, -5.0350,  6.4137,  4.4111,  1.7371, -1.6478,  4.2046,\n","        -7.8308,  7.3766,  1.7295,  3.5195,  0.3470,  4.4601, -1.1241, 10.3553],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.71366882324219\n","Epoch 13, Batch 90 - Training loss: 115.71366882324219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6356,   2.8811,  -4.3216,   4.1072,   5.7861,   0.4179,  -6.3485,\n","          4.7822, -11.5667,   7.2443,   6.8081,   0.1080,  -0.0192,  -4.9533,\n","          2.1089,   8.6316], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.7640609741211\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6356,   2.8811,  -4.3216,   4.1072,   5.7861,   0.4179,  -6.3485,\n","          4.7822, -11.5667,   7.2443,   6.8081,   0.1080,  -0.0192,  -4.9533,\n","          2.1089,   8.6316], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.25916290283203\n","Epoch 13, Batch 91 - Training loss: 108.25916290283203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.4136,  3.1384, -2.4291,  7.5274,  3.0115, -1.4954, -2.3934, -0.8346,\n","        -7.8118,  7.7579,  6.5435,  1.8460, -0.5863,  3.4871, -1.4405,  6.6827],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9996, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.22588348388672\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.4136,  3.1384, -2.4291,  7.5274,  3.0115, -1.4954, -2.3934, -0.8346,\n","        -7.8118,  7.7579,  6.5435,  1.8460, -0.5863,  3.4871, -1.4405,  6.6827],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9996, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.30561065673828\n","Epoch 13, Batch 92 - Training loss: 113.30561065673828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-12.9282,   3.6826,   2.4258,   8.2087,   4.6370,  -3.7532,  -2.7626,\n","          2.7857,  -9.3932,   4.4386,   6.5811,   7.0422,  -0.9263,   2.0650,\n","          2.0479,   5.4581], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.77342987060547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-12.9282,   3.6826,   2.4258,   8.2087,   4.6370,  -3.7532,  -2.7626,\n","          2.7857,  -9.3932,   4.4386,   6.5811,   7.0422,  -0.9263,   2.0650,\n","          2.0479,   5.4581], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.12776184082031\n","Epoch 13, Batch 93 - Training loss: 115.12776184082031\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5730,  -3.9318,  -0.1955,   5.6444,   4.6189,  -5.8136,   1.9083,\n","          4.1994, -11.0643,   6.2853,   9.1536,  -0.4921,  -1.3322,   3.2792,\n","         -5.1510,   5.4320], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.44340515136719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5730,  -3.9318,  -0.1955,   5.6444,   4.6189,  -5.8136,   1.9083,\n","          4.1994, -11.0643,   6.2853,   9.1536,  -0.4921,  -1.3322,   3.2792,\n","         -5.1510,   5.4320], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.1477279663086\n","Epoch 13, Batch 94 - Training loss: 113.1477279663086\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1119,  -1.3101,   2.1722,   4.2536,   2.4485,  -2.3478,  -2.6808,\n","          1.5777, -10.7182,   6.7236,   8.7789,   1.9190,   3.7017,   2.1657,\n","         -2.6965,   8.6727], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.7367935180664\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1119,  -1.3101,   2.1722,   4.2536,   2.4485,  -2.3478,  -2.6808,\n","          1.5777, -10.7182,   6.7236,   8.7789,   1.9190,   3.7017,   2.1657,\n","         -2.6965,   8.6727], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.4346923828125\n","Epoch 13, Batch 95 - Training loss: 116.4346923828125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.7914,   1.5194,  -3.2249,   9.0743,   5.0162,  -3.5227,  -2.3137,\n","          3.0812, -13.7028,   7.4700,  10.5082,   3.3841,   1.1650,   7.9490,\n","         -0.5090,   9.9748], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.43788146972656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.7914,   1.5194,  -3.2249,   9.0743,   5.0162,  -3.5227,  -2.3137,\n","          3.0812, -13.7028,   7.4700,  10.5082,   3.3841,   1.1650,   7.9490,\n","         -0.5090,   9.9748], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.25988006591797\n","Epoch 13, Batch 96 - Training loss: 117.25988006591797\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.3741,  0.9213,  1.0182,  4.3923,  3.7219, -0.9613,  0.4310,  4.6224,\n","        -9.2852, -2.5549,  5.3930,  3.9064,  3.0115,  3.5253, -0.8098,  8.9011],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.79127502441406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.3741,  0.9213,  1.0182,  4.3923,  3.7219, -0.9613,  0.4310,  4.6224,\n","        -9.2852, -2.5549,  5.3930,  3.9064,  3.0115,  3.5253, -0.8098,  8.9011],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.59220123291016\n","Epoch 13, Batch 97 - Training loss: 114.59220123291016\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.4605,  2.5798, -1.7968,  1.8423,  4.4669, -6.7093, -7.9200,  0.5621,\n","        -8.3451,  2.2135, 11.4034,  4.3269,  1.3092,  1.6769, -4.4639,  6.5439],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.18949127197266\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.4605,  2.5798, -1.7968,  1.8423,  4.4669, -6.7093, -7.9200,  0.5621,\n","        -8.3451,  2.2135, 11.4034,  4.3269,  1.3092,  1.6769, -4.4639,  6.5439],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.70939636230469\n","Epoch 13, Batch 98 - Training loss: 116.70939636230469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.8608,  -2.3122,  -0.4281,   0.9502,   2.4218,   3.5302,  -5.8033,\n","          2.4930, -12.4913,   5.5987,   2.1337,  -0.4340,   0.7594,   4.0430,\n","         -1.0172,   5.8168], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.947509765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.8608,  -2.3122,  -0.4281,   0.9502,   2.4218,   3.5302,  -5.8033,\n","          2.4930, -12.4913,   5.5987,   2.1337,  -0.4340,   0.7594,   4.0430,\n","         -1.0172,   5.8168], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.814208984375\n","Epoch 13, Batch 99 - Training loss: 115.814208984375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.1780, -0.5731,  0.5018,  2.2766,  5.5717, -3.1502,  0.4705, -1.3412,\n","        -8.7312, 10.8836,  2.8531,  5.0274, -1.0236,  8.7902,  1.3648,  6.2689],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -0.9990],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.84640502929688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.1780, -0.5731,  0.5018,  2.2766,  5.5717, -3.1502,  0.4705, -1.3412,\n","        -8.7312, 10.8836,  2.8531,  5.0274, -1.0236,  8.7902,  1.3648,  6.2689],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -0.9990],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.70845794677734\n","Epoch 13, Batch 100 - Training loss: 116.70845794677734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6432,   3.1726,  -1.4242,   6.1479,   5.6169,  -9.4517,  -0.6171,\n","          4.4214, -10.1997,   4.7327,   4.3140,   2.1750,   0.5887,   4.8617,\n","         -4.1878,   7.0334], grad_fn=<SumBackward1>), log_var: tensor([-0.9995, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.00614929199219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6432,   3.1726,  -1.4242,   6.1479,   5.6169,  -9.4517,  -0.6171,\n","          4.4214, -10.1997,   4.7327,   4.3140,   2.1750,   0.5887,   4.8617,\n","         -4.1878,   7.0334], grad_fn=<SumBackward1>), log_var: tensor([-0.9995, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.43842315673828\n","Epoch 13, Batch 101 - Training loss: 114.43842315673828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.3229,   2.3342,  -0.4347,   7.9659,   5.0957,  -2.3717,  -3.4415,\n","          2.0111, -11.4948,   4.7621,   6.6604,   2.2736,  -0.6971,   2.5129,\n","         -0.8651,   9.6747], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.09032440185547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.3229,   2.3342,  -0.4347,   7.9659,   5.0957,  -2.3717,  -3.4415,\n","          2.0111, -11.4948,   4.7621,   6.6604,   2.2736,  -0.6971,   2.5129,\n","         -0.8651,   9.6747], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.16764831542969\n","Epoch 13, Batch 102 - Training loss: 114.16764831542969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.5776,  -1.0713,  -0.8798,   5.7302,   4.8540,  -7.4870,   0.0225,\n","          5.1468, -11.0387,   3.6350,   2.9351,   4.9127,  -0.5594,   1.6795,\n","         -4.0475,   8.9445], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.9035415649414\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.5776,  -1.0713,  -0.8798,   5.7302,   4.8540,  -7.4870,   0.0225,\n","          5.1468, -11.0387,   3.6350,   2.9351,   4.9127,  -0.5594,   1.6795,\n","         -4.0475,   8.9445], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.08229064941406\n","Epoch 13, Batch 103 - Training loss: 111.08229064941406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.4888,  3.5670,  3.8995,  8.1062,  2.7265, -0.9871, -3.4132,  2.2741,\n","        -9.0327,  5.6383,  6.0813,  4.2290,  1.1400,  6.4986,  0.5170,  4.1486],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.80245208740234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.4888,  3.5670,  3.8995,  8.1062,  2.7265, -0.9871, -3.4132,  2.2741,\n","        -9.0327,  5.6383,  6.0813,  4.2290,  1.1400,  6.4986,  0.5170,  4.1486],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.78749084472656\n","Epoch 13, Batch 104 - Training loss: 117.78749084472656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.4485,  0.6673,  3.1958,  7.8150,  2.9371, -1.2609,  2.2921,  2.0593,\n","        -8.4853,  5.4487,  8.4266,  3.5891, -0.6316,  6.6064, -2.0157,  2.3057],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.99290466308594\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.4485,  0.6673,  3.1958,  7.8150,  2.9371, -1.2609,  2.2921,  2.0593,\n","        -8.4853,  5.4487,  8.4266,  3.5891, -0.6316,  6.6064, -2.0157,  2.3057],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.25804901123047\n","Epoch 13, Batch 105 - Training loss: 120.25804901123047\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.4303,  0.4599,  2.9279,  4.9752,  1.5040, -4.0010, -0.4496,  3.8081,\n","        -9.9031,  9.8318,  1.4875,  1.8441, -3.8095,  5.9588, -2.1473,  6.2267],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989, -0.9981,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.70243835449219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.4303,  0.4599,  2.9279,  4.9752,  1.5040, -4.0010, -0.4496,  3.8081,\n","        -9.9031,  9.8318,  1.4875,  1.8441, -3.8095,  5.9588, -2.1473,  6.2267],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989, -0.9981,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.97205352783203\n","Epoch 13, Batch 106 - Training loss: 114.97205352783203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.4502,  -1.2794,   0.9391,   4.4392,   5.5347,  -1.6265,  -6.1569,\n","          5.3742, -12.7182,   3.3138,   2.9373,   4.8638,  -2.7181,   5.9989,\n","         -4.7539,   4.8595], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9977, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.39945220947266\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.4502,  -1.2794,   0.9391,   4.4392,   5.5347,  -1.6265,  -6.1569,\n","          5.3742, -12.7182,   3.3138,   2.9373,   4.8638,  -2.7181,   5.9989,\n","         -4.7539,   4.8595], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9977, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.9312515258789\n","Epoch 13, Batch 107 - Training loss: 113.9312515258789\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.3163,  1.4928,  0.1729,  3.0790,  6.4794, -1.5822, -0.3103,  1.3915,\n","        -6.7628,  8.2322,  4.9370,  3.1768,  0.1850,  2.2523,  0.5728,  5.9170],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.15265655517578\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.3163,  1.4928,  0.1729,  3.0790,  6.4794, -1.5822, -0.3103,  1.3915,\n","        -6.7628,  8.2322,  4.9370,  3.1768,  0.1850,  2.2523,  0.5728,  5.9170],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.61054992675781\n","Epoch 13, Batch 108 - Training loss: 113.61054992675781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.9077,   0.9449,  -2.3767,   7.2474,   3.2499,  -5.6918,   0.4148,\n","          1.5042, -10.6168,   9.3139,   5.7028,   3.8097,   0.5249,   3.9079,\n","          4.5793,   4.5976], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.6176986694336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.9077,   0.9449,  -2.3767,   7.2474,   3.2499,  -5.6918,   0.4148,\n","          1.5042, -10.6168,   9.3139,   5.7028,   3.8097,   0.5249,   3.9079,\n","          4.5793,   4.5976], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.71617126464844\n","Epoch 13, Batch 109 - Training loss: 111.71617126464844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.8148,   0.4009,  -0.3167,  -0.4118,  -0.6224,  -1.8973,  -2.8992,\n","         -1.4312, -10.7406,   2.1759,   5.1195,   0.1604,  -0.7927,   2.3220,\n","         -3.2676,   5.5086], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.00517272949219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.8148,   0.4009,  -0.3167,  -0.4118,  -0.6224,  -1.8973,  -2.8992,\n","         -1.4312, -10.7406,   2.1759,   5.1195,   0.1604,  -0.7927,   2.3220,\n","         -3.2676,   5.5086], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.13417053222656\n","Epoch 13, Batch 110 - Training loss: 116.13417053222656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.5389, -1.9250,  2.0009,  1.2167,  4.9999, -6.2805,  2.7702,  3.5300,\n","        -9.9677,  3.6181,  6.1333,  7.1438, -4.2116,  2.3060,  1.7314,  4.7857],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.35197448730469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.5389, -1.9250,  2.0009,  1.2167,  4.9999, -6.2805,  2.7702,  3.5300,\n","        -9.9677,  3.6181,  6.1333,  7.1438, -4.2116,  2.3060,  1.7314,  4.7857],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.38573455810547\n","Epoch 13, Batch 111 - Training loss: 117.38573455810547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-12.2892,   1.3911,   0.6667,   9.8120,   4.1123,  -0.4424,  -7.5223,\n","          2.3427,  -9.7484,   5.6953,   4.1355,   4.0400,   0.4367,   2.9623,\n","         -2.0433,  11.0030], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9958, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.43302917480469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-12.2892,   1.3911,   0.6667,   9.8120,   4.1123,  -0.4424,  -7.5223,\n","          2.3427,  -9.7484,   5.6953,   4.1355,   4.0400,   0.4367,   2.9623,\n","         -2.0433,  11.0030], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9958, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.81450653076172\n","Epoch 13, Batch 112 - Training loss: 119.81450653076172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.2305,  -1.9331,  -4.4736,  12.0321,   3.7980,  -3.5917,  -7.0233,\n","          4.0876, -11.2257,   2.9838,   1.6677,   3.3768,  -0.1814,   5.4623,\n","         -1.6055,   7.7175], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.79039001464844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.2305,  -1.9331,  -4.4736,  12.0321,   3.7980,  -3.5917,  -7.0233,\n","          4.0876, -11.2257,   2.9838,   1.6677,   3.3768,  -0.1814,   5.4623,\n","         -1.6055,   7.7175], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.88887023925781\n","Epoch 13, Batch 113 - Training loss: 109.88887023925781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-11.5663,   1.7517,  -0.3755,   7.8833,   2.6908,  -2.6972,  -2.9720,\n","          0.0867, -10.5150,   3.9914,   3.0715,   3.1124,   1.0935,   3.0806,\n","         -0.8777,   8.3938], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.49418640136719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-11.5663,   1.7517,  -0.3755,   7.8833,   2.6908,  -2.6972,  -2.9720,\n","          0.0867, -10.5150,   3.9914,   3.0715,   3.1124,   1.0935,   3.0806,\n","         -0.8777,   8.3938], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.50167846679688\n","Epoch 13, Batch 114 - Training loss: 116.50167846679688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.0600,   3.6005,   2.4015,   3.0937,   4.4719,  -2.3871,  -4.8833,\n","          7.2477, -14.6559,   9.3828,   3.4789,   6.6755,   2.0482,   4.4291,\n","          1.3446,   9.8777], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.46640014648438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.0600,   3.6005,   2.4015,   3.0937,   4.4719,  -2.3871,  -4.8833,\n","          7.2477, -14.6559,   9.3828,   3.4789,   6.6755,   2.0482,   4.4291,\n","          1.3446,   9.8777], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.46695709228516\n","Epoch 13, Batch 115 - Training loss: 115.46695709228516\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5261,   4.3445,   4.1188,   6.1074,   6.9082,  -2.0288,  -4.3292,\n","          4.1948, -11.3489,   7.0937,   7.1664,   7.2914,   1.1250,   3.7118,\n","         -3.3653,   9.4160], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9995, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9984],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.941650390625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5261,   4.3445,   4.1188,   6.1074,   6.9082,  -2.0288,  -4.3292,\n","          4.1948, -11.3489,   7.0937,   7.1664,   7.2914,   1.1250,   3.7118,\n","         -3.3653,   9.4160], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9995, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9984],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.20821380615234\n","Epoch 13, Batch 116 - Training loss: 116.20821380615234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.3490,   1.7539,  -3.9714,   5.9878,   3.5807,  -3.9183,  -3.6329,\n","          0.7492, -10.6972,  -0.1108,   6.5299,   5.5924,  -2.4973,   6.9597,\n","         -3.6571,   7.6292], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9987, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.40521240234375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.3490,   1.7539,  -3.9714,   5.9878,   3.5807,  -3.9183,  -3.6329,\n","          0.7492, -10.6972,  -0.1108,   6.5299,   5.5924,  -2.4973,   6.9597,\n","         -3.6571,   7.6292], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9987, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.52139282226562\n","Epoch 13, Batch 117 - Training loss: 119.52139282226562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0741,  2.0129,  2.1650,  6.4910,  4.0330, -0.8561, -0.7179,  2.3032,\n","        -8.6431,  9.0469,  2.6616,  3.0885, -3.5937,  5.6101,  2.1094,  8.2643],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.36931610107422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0741,  2.0129,  2.1650,  6.4910,  4.0330, -0.8561, -0.7179,  2.3032,\n","        -8.6431,  9.0469,  2.6616,  3.0885, -3.5937,  5.6101,  2.1094,  8.2643],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.4926986694336\n","Epoch 13, Batch 118 - Training loss: 117.4926986694336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.0522,  -1.1545,   2.9216,   5.7286,   6.2708,  -4.4658,  -2.8892,\n","          4.4327, -11.4790,   5.2984,   4.7929,   0.2995,  -1.6459,   4.1814,\n","         -2.4796,   7.6036], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.81847381591797\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.0522,  -1.1545,   2.9216,   5.7286,   6.2708,  -4.4658,  -2.8892,\n","          4.4327, -11.4790,   5.2984,   4.7929,   0.2995,  -1.6459,   4.1814,\n","         -2.4796,   7.6036], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.12361145019531\n","Epoch 13, Batch 119 - Training loss: 116.12361145019531\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.6350,   0.6262,  -1.7695,  10.3679,   6.3281,  -0.0445,  -1.7376,\n","          8.5292, -11.9720,   6.2281,   3.4846,   6.4898,  -2.1970,   0.1173,\n","         -5.7752,   6.2603], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.14585876464844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.6350,   0.6262,  -1.7695,  10.3679,   6.3281,  -0.0445,  -1.7376,\n","          8.5292, -11.9720,   6.2281,   3.4846,   6.4898,  -2.1970,   0.1173,\n","         -5.7752,   6.2603], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.52565002441406\n","Epoch 13, Batch 120 - Training loss: 113.52565002441406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6587,   0.7646,  -0.8503,  -0.0947,   3.6323,  -2.7838,  -2.1803,\n","         -0.4509, -14.5482,   9.9325,   3.7064,  -0.2363,  -0.3801,   1.4222,\n","          0.3472,   8.4397], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9985, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9985],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.25341796875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6587,   0.7646,  -0.8503,  -0.0947,   3.6323,  -2.7838,  -2.1803,\n","         -0.4509, -14.5482,   9.9325,   3.7064,  -0.2363,  -0.3801,   1.4222,\n","          0.3472,   8.4397], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9985, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9985],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.76028442382812\n","Epoch 13, Batch 121 - Training loss: 113.76028442382812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.7388,  1.0775,  1.9704,  8.4820,  6.7583, -2.8895, -3.2517,  4.9917,\n","        -9.3850, -1.6982,  6.6453,  2.6090,  3.5180,  2.4067, -2.9861,  8.6209],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.80384063720703\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.7388,  1.0775,  1.9704,  8.4820,  6.7583, -2.8895, -3.2517,  4.9917,\n","        -9.3850, -1.6982,  6.6453,  2.6090,  3.5180,  2.4067, -2.9861,  8.6209],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.75819396972656\n","Epoch 13, Batch 122 - Training loss: 109.75819396972656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.4982,   4.6512,  -1.1202,   6.3924,   6.3799,  -2.6456,  -1.5589,\n","          0.8010, -13.9351,   4.9774,   0.7827,   1.9409,  -1.4822,   1.8422,\n","          0.9263,   7.9593], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.89830780029297\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.4982,   4.6512,  -1.1202,   6.3924,   6.3799,  -2.6456,  -1.5589,\n","          0.8010, -13.9351,   4.9774,   0.7827,   1.9409,  -1.4822,   1.8422,\n","          0.9263,   7.9593], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.3193588256836\n","Epoch 13, Batch 123 - Training loss: 111.3193588256836\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.6147,  -1.5398,  -0.2488,   1.9660,   1.5738,  -0.1305,  -1.9096,\n","         -0.7020, -11.7911,   2.0420,   8.9785,   2.4629,  -5.0889,   4.4719,\n","         -2.8441,  15.2067], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9997, -1.0000, -0.9978, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.83390045166016\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.6147,  -1.5398,  -0.2488,   1.9660,   1.5738,  -0.1305,  -1.9096,\n","         -0.7020, -11.7911,   2.0420,   8.9785,   2.4629,  -5.0889,   4.4719,\n","         -2.8441,  15.2067], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9997, -1.0000, -0.9978, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.05020141601562\n","Epoch 13, Batch 124 - Training loss: 117.05020141601562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.9698,  4.5991,  5.3447,  6.2460,  7.8412,  0.8533,  0.8038,  1.1029,\n","        -6.8332,  2.4561,  4.0113,  5.2524, -5.4091,  7.5060, -3.2870,  4.5468],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.25496673583984\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.9698,  4.5991,  5.3447,  6.2460,  7.8412,  0.8533,  0.8038,  1.1029,\n","        -6.8332,  2.4561,  4.0113,  5.2524, -5.4091,  7.5060, -3.2870,  4.5468],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.36961364746094\n","Epoch 13, Batch 125 - Training loss: 115.36961364746094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.8484,  -1.1252,   0.4815,   2.1913,   1.8620,  -7.9790,  -0.5950,\n","         -0.2447, -10.6312,   2.1061,   5.5432,   4.8441,  -3.5945,   2.9760,\n","         -4.2020,   7.8468], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9997, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.28581237792969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.8484,  -1.1252,   0.4815,   2.1913,   1.8620,  -7.9790,  -0.5950,\n","         -0.2447, -10.6312,   2.1061,   5.5432,   4.8441,  -3.5945,   2.9760,\n","         -4.2020,   7.8468], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9997, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.63386535644531\n","Epoch 13, Batch 126 - Training loss: 120.63386535644531\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.8894,  1.4770, -1.8486,  4.0735,  7.7016, -0.1457, -1.8100,  4.0832,\n","        -8.4601,  7.8680,  8.1135,  2.6242,  1.6662,  5.4888, -1.0091, 10.5087],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.93272399902344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.8894,  1.4770, -1.8486,  4.0735,  7.7016, -0.1457, -1.8100,  4.0832,\n","        -8.4601,  7.8680,  8.1135,  2.6242,  1.6662,  5.4888, -1.0091, 10.5087],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.69661712646484\n","Epoch 13, Batch 127 - Training loss: 112.69661712646484\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.5115,   0.6901,  -3.1279,  -0.7264,   3.3477,  -3.6704,  -6.4498,\n","          2.9854, -13.0250,   6.6285,   7.4246,   3.4118,  -4.0712,  -1.7799,\n","          2.7203,   5.2658], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.1435317993164\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.5115,   0.6901,  -3.1279,  -0.7264,   3.3477,  -3.6704,  -6.4498,\n","          2.9854, -13.0250,   6.6285,   7.4246,   3.4118,  -4.0712,  -1.7799,\n","          2.7203,   5.2658], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.47724914550781\n","Epoch 13, Batch 128 - Training loss: 116.47724914550781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  1.2912,  -3.3572,  -0.0764,   3.4507,   3.2266,  -3.2052,  -1.0422,\n","          4.1242, -12.1798,  -1.5392,   8.4176,   3.8254,  -3.1769,   0.9749,\n","          3.5230,   8.5014], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.06146240234375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  1.2912,  -3.3572,  -0.0764,   3.4507,   3.2266,  -3.2052,  -1.0422,\n","          4.1242, -12.1798,  -1.5392,   8.4176,   3.8254,  -3.1769,   0.9749,\n","          3.5230,   8.5014], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.00810241699219\n","Epoch 13, Batch 129 - Training loss: 114.00810241699219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.3645, -0.9881, -1.0537,  4.6172,  3.7925, -2.0515, -1.5529,  3.0749,\n","        -4.7964,  7.2772, 11.4475,  0.6289, -0.3716,  6.6519, -8.6423,  7.7386],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.5701904296875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.3645, -0.9881, -1.0537,  4.6172,  3.7925, -2.0515, -1.5529,  3.0749,\n","        -4.7964,  7.2772, 11.4475,  0.6289, -0.3716,  6.6519, -8.6423,  7.7386],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.93158721923828\n","Epoch 13, Batch 130 - Training loss: 113.93158721923828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.7486,  -2.4036,  -2.0762,   4.4565,   3.8609,   1.4487,  -0.6657,\n","          5.2993, -11.9299,   4.4210,   4.1412,   0.1123,  -0.2480,  -0.4405,\n","         -1.9355,   5.7548], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.31980895996094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.7486,  -2.4036,  -2.0762,   4.4565,   3.8609,   1.4487,  -0.6657,\n","          5.2993, -11.9299,   4.4210,   4.1412,   0.1123,  -0.2480,  -0.4405,\n","         -1.9355,   5.7548], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.89700317382812\n","Epoch 13, Batch 131 - Training loss: 112.89700317382812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-0.8521, -2.1818, -0.0569,  5.5292, -0.3868,  3.2014,  0.6702,  3.4664,\n","        -9.2809,  5.7301,  8.9211,  5.1669,  0.1728,  4.6785,  4.5421,  8.2372],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9980, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.43598937988281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-0.8521, -2.1818, -0.0569,  5.5292, -0.3868,  3.2014,  0.6702,  3.4664,\n","        -9.2809,  5.7301,  8.9211,  5.1669,  0.1728,  4.6785,  4.5421,  8.2372],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9980, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.29656219482422\n","Epoch 13, Batch 132 - Training loss: 112.29656219482422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4317,   1.9176,   4.7277,   5.4863,   5.9949,  -3.5760,   1.3557,\n","          1.5495, -10.2729,   5.6512,   6.8049,   5.9195,  -1.7198,   5.5204,\n","         -2.2449,   2.7543], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.76889038085938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4317,   1.9176,   4.7277,   5.4863,   5.9949,  -3.5760,   1.3557,\n","          1.5495, -10.2729,   5.6512,   6.8049,   5.9195,  -1.7198,   5.5204,\n","         -2.2449,   2.7543], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.10824584960938\n","Epoch 13, Batch 133 - Training loss: 113.10824584960938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.0627e+00, -2.1694e+00, -1.2452e+00,  3.8007e+00,  6.5815e+00,\n","        -3.2752e-01, -4.8132e+00,  2.0319e+00, -1.1722e+01,  3.1239e+00,\n","         9.7388e+00,  1.5736e+00, -2.5293e+00,  1.5161e+00,  9.1572e-03,\n","         7.6541e+00], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9962, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.62091827392578\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.0627e+00, -2.1694e+00, -1.2452e+00,  3.8007e+00,  6.5815e+00,\n","        -3.2752e-01, -4.8132e+00,  2.0319e+00, -1.1722e+01,  3.1239e+00,\n","         9.7388e+00,  1.5736e+00, -2.5293e+00,  1.5161e+00,  9.1572e-03,\n","         7.6541e+00], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9962, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.74455261230469\n","Epoch 13, Batch 134 - Training loss: 116.74455261230469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.2758,  -0.6661,  -1.2932,   2.6193,   6.2641,   0.7838,  -5.6957,\n","         -0.1925, -10.6914,   3.9083,   7.3139,   0.6446,  -1.5669,   1.7383,\n","          0.8922,   5.3297], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.03659057617188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.2758,  -0.6661,  -1.2932,   2.6193,   6.2641,   0.7838,  -5.6957,\n","         -0.1925, -10.6914,   3.9083,   7.3139,   0.6446,  -1.5669,   1.7383,\n","          0.8922,   5.3297], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.27740478515625\n","Epoch 13, Batch 135 - Training loss: 111.27740478515625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.4365,   1.4509,  -1.0562,   1.6947,   4.7792,  -5.2246,  -9.1389,\n","         -1.3686, -11.0391,   3.4076,   6.5409,   8.1809,   0.5129,  -1.4699,\n","          1.4915,   7.5133], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.6885757446289\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.4365,   1.4509,  -1.0562,   1.6947,   4.7792,  -5.2246,  -9.1389,\n","         -1.3686, -11.0391,   3.4076,   6.5409,   8.1809,   0.5129,  -1.4699,\n","          1.4915,   7.5133], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.1619873046875\n","Epoch 13, Batch 136 - Training loss: 115.1619873046875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.6357,  -0.9568,  -0.5593,   5.4227,   4.8790,  -2.8204,   0.7456,\n","         -2.7853, -10.3172,   4.5195,   4.4499,   5.5224,   0.1297,   3.4192,\n","         -4.4839,   2.0859], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.26799774169922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.6357,  -0.9568,  -0.5593,   5.4227,   4.8790,  -2.8204,   0.7456,\n","         -2.7853, -10.3172,   4.5195,   4.4499,   5.5224,   0.1297,   3.4192,\n","         -4.4839,   2.0859], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.7755126953125\n","Epoch 13, Batch 137 - Training loss: 111.7755126953125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.5536,  -2.2711,   2.9412,   3.5826,   3.0257,  -0.0438,  -3.6016,\n","          2.2753, -12.8447,   2.7119,   6.9772,   2.5699,   0.9079,   3.1979,\n","         -0.0485,   6.1234], grad_fn=<SumBackward1>), log_var: tensor([-0.9982, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.80441284179688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.5536,  -2.2711,   2.9412,   3.5826,   3.0257,  -0.0438,  -3.6016,\n","          2.2753, -12.8447,   2.7119,   6.9772,   2.5699,   0.9079,   3.1979,\n","         -0.0485,   6.1234], grad_fn=<SumBackward1>), log_var: tensor([-0.9982, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.855224609375\n","Epoch 13, Batch 138 - Training loss: 117.855224609375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1151,   0.3306,  -0.3638,   7.9007,   2.5768,  -0.0207,  -4.5457,\n","          1.1940, -12.7890,   6.0465,   3.0552,  -0.8039,  -3.7702,   6.6547,\n","          2.1632,   7.0407], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.12364196777344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1151,   0.3306,  -0.3638,   7.9007,   2.5768,  -0.0207,  -4.5457,\n","          1.1940, -12.7890,   6.0465,   3.0552,  -0.8039,  -3.7702,   6.6547,\n","          2.1632,   7.0407], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.27140808105469\n","Epoch 13, Batch 139 - Training loss: 115.27140808105469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.0544e+00,  3.1082e+00,  3.7339e+00,  6.3964e+00,  5.7224e+00,\n","         4.9599e-01, -7.0570e+00, -3.9330e-03, -7.2910e+00, -2.2920e-01,\n","         8.7078e+00,  3.0635e+00, -4.6140e+00,  1.1672e+00, -2.5618e-02,\n","         6.3334e+00], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9997, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.44943237304688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.0544e+00,  3.1082e+00,  3.7339e+00,  6.3964e+00,  5.7224e+00,\n","         4.9599e-01, -7.0570e+00, -3.9330e-03, -7.2910e+00, -2.2920e-01,\n","         8.7078e+00,  3.0635e+00, -4.6140e+00,  1.1672e+00, -2.5618e-02,\n","         6.3334e+00], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9997, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.62151336669922\n","Epoch 13, Batch 140 - Training loss: 120.62151336669922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.7559,  -0.8148,   1.3867,   8.5590,   0.8013,  -3.5996,  -4.6069,\n","          0.6689, -12.2696,   2.8424,   7.5885,   5.7931,  -2.1979,   1.6013,\n","         -4.2467,   2.4559], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.32682800292969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.7559,  -0.8148,   1.3867,   8.5590,   0.8013,  -3.5996,  -4.6069,\n","          0.6689, -12.2696,   2.8424,   7.5885,   5.7931,  -2.1979,   1.6013,\n","         -4.2467,   2.4559], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.97149658203125\n","Epoch 13, Batch 141 - Training loss: 112.97149658203125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.2246,   1.5040,  -0.2387,   6.5227,   5.3155,  -4.4290,  -2.8481,\n","          5.3905, -14.0582,   2.3914,   9.3707,   1.7827,   1.8134,   5.9354,\n","          1.1291,   7.8163], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.40279388427734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.2246,   1.5040,  -0.2387,   6.5227,   5.3155,  -4.4290,  -2.8481,\n","          5.3905, -14.0582,   2.3914,   9.3707,   1.7827,   1.8134,   5.9354,\n","          1.1291,   7.8163], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.85184478759766\n","Epoch 13, Batch 142 - Training loss: 114.85184478759766\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.2057e+00, -2.4031e+00,  3.0999e+00,  3.6713e+00,  2.1528e+00,\n","        -2.1838e+00,  2.3889e+00,  8.0694e-01, -9.3314e+00,  4.0012e+00,\n","         4.1301e+00,  4.6299e+00, -7.8437e-03, -2.1614e-01, -3.3430e+00,\n","         5.0082e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.225341796875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.2057e+00, -2.4031e+00,  3.0999e+00,  3.6713e+00,  2.1528e+00,\n","        -2.1838e+00,  2.3889e+00,  8.0694e-01, -9.3314e+00,  4.0012e+00,\n","         4.1301e+00,  4.6299e+00, -7.8437e-03, -2.1614e-01, -3.3430e+00,\n","         5.0082e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.70449829101562\n","Epoch 13, Batch 143 - Training loss: 117.70449829101562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.1749,  -0.9804,  -0.4519,   6.3758,   7.7486,  -2.8696,  -6.0601,\n","          0.2021, -11.5384,   5.3454,   8.4522,   4.7328,  -1.8738,   1.7721,\n","         -1.6389,   4.6833], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 121.6191177368164\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.1749,  -0.9804,  -0.4519,   6.3758,   7.7486,  -2.8696,  -6.0601,\n","          0.2021, -11.5384,   5.3454,   8.4522,   4.7328,  -1.8738,   1.7721,\n","         -1.6389,   4.6833], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 121.4663314819336\n","Epoch 13, Batch 144 - Training loss: 121.4663314819336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.0373,   1.7540,   2.7243,   6.1625,   4.3394,  -1.2785,  -2.8629,\n","          4.9963, -10.0145,   3.0600,   5.1513,   4.9507,  -2.4425,   1.3252,\n","          0.2453,   7.5910], grad_fn=<SumBackward1>), log_var: tensor([-0.9980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9963, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.46652221679688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.0373,   1.7540,   2.7243,   6.1625,   4.3394,  -1.2785,  -2.8629,\n","          4.9963, -10.0145,   3.0600,   5.1513,   4.9507,  -2.4425,   1.3252,\n","          0.2453,   7.5910], grad_fn=<SumBackward1>), log_var: tensor([-0.9980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9963, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.82847595214844\n","Epoch 13, Batch 145 - Training loss: 118.82847595214844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.9510,   1.3407,   2.3903,   5.6146,   6.0474,   0.6628,  -2.4121,\n","          2.4219, -10.3170,  -0.2728,   2.1158,   1.1874,  -2.0086,   3.5513,\n","          4.4638,   3.1946], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.70282745361328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.9510,   1.3407,   2.3903,   5.6146,   6.0474,   0.6628,  -2.4121,\n","          2.4219, -10.3170,  -0.2728,   2.1158,   1.1874,  -2.0086,   3.5513,\n","          4.4638,   3.1946], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.90904998779297\n","Epoch 13, Batch 146 - Training loss: 111.90904998779297\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.4040,   1.7960,  -3.0033,   5.3822,   3.5240,   3.2995,  -6.9443,\n","          1.9627, -14.7640,   8.8779,   3.3805,   3.8812,  -1.4049,   4.9572,\n","          2.6270,  11.8134], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9972, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.92674255371094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.4040,   1.7960,  -3.0033,   5.3822,   3.5240,   3.2995,  -6.9443,\n","          1.9627, -14.7640,   8.8779,   3.3805,   3.8812,  -1.4049,   4.9572,\n","          2.6270,  11.8134], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9972, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.98319244384766\n","Epoch 13, Batch 147 - Training loss: 115.98319244384766\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.6732, -4.0066, -3.0153,  3.0476,  4.1324, -0.9259,  0.1107,  3.4618,\n","        -6.7784,  3.2829,  7.2322,  5.4313,  4.0520,  4.4913,  1.3814,  7.6996],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9980],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.13748931884766\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.6732, -4.0066, -3.0153,  3.0476,  4.1324, -0.9259,  0.1107,  3.4618,\n","        -6.7784,  3.2829,  7.2322,  5.4313,  4.0520,  4.4913,  1.3814,  7.6996],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9980],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.67274475097656\n","Epoch 13, Batch 148 - Training loss: 113.67274475097656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.9734,   0.0498,   0.8792,   1.1918,   4.4199,  -4.9997,  -3.4513,\n","          3.0489, -10.6835,   7.8141,   6.7876,   0.5393,  -0.6050,   2.7935,\n","         -0.3499,   9.4338], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9988, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.75291442871094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.9734,   0.0498,   0.8792,   1.1918,   4.4199,  -4.9997,  -3.4513,\n","          3.0489, -10.6835,   7.8141,   6.7876,   0.5393,  -0.6050,   2.7935,\n","         -0.3499,   9.4338], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9988, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.34227752685547\n","Epoch 13, Batch 149 - Training loss: 113.34227752685547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.6521,   4.0282,   3.8811,  -0.4557,   6.1273,   0.2740,  -0.3782,\n","         -0.3731, -10.7521,   3.1916,   8.4170,   0.7980,  -0.2746,  -0.5514,\n","          2.6903,   5.0210], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9986, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.7266845703125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.6521,   4.0282,   3.8811,  -0.4557,   6.1273,   0.2740,  -0.3782,\n","         -0.3731, -10.7521,   3.1916,   8.4170,   0.7980,  -0.2746,  -0.5514,\n","          2.6903,   5.0210], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9986, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.85769653320312\n","Epoch 13, Batch 150 - Training loss: 115.85769653320312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-13.6338,   3.7082,  -3.2724,   2.3535,   2.1612,  -3.3889,  -2.6806,\n","         -1.4978, -13.5075,   2.3493,   5.4278,   2.4633,  -0.5915,   2.0367,\n","         -0.3293,   9.0358], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.5577392578125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-13.6338,   3.7082,  -3.2724,   2.3535,   2.1612,  -3.3889,  -2.6806,\n","         -1.4978, -13.5075,   2.3493,   5.4278,   2.4633,  -0.5915,   2.0367,\n","         -0.3293,   9.0358], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.25336456298828\n","Epoch 13, Batch 151 - Training loss: 114.25336456298828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.4959,   4.3235,  -0.3388,   3.5601,   4.9384,   1.0432,  -7.1887,\n","          0.1416, -13.4324,   2.8327,   8.4153,   2.5339,  -1.2595,   6.7691,\n","         -0.9316,   6.5999], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9965, -0.9956],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.36210632324219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.4959,   4.3235,  -0.3388,   3.5601,   4.9384,   1.0432,  -7.1887,\n","          0.1416, -13.4324,   2.8327,   8.4153,   2.5339,  -1.2595,   6.7691,\n","         -0.9316,   6.5999], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9965, -0.9956],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.18038177490234\n","Epoch 13, Batch 152 - Training loss: 117.18038177490234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.2082, -0.6582, -0.7309,  1.8053,  3.9324,  3.8698, -1.3544,  1.4496,\n","        -8.8746,  5.7861,  3.6634,  5.5609,  1.4172,  8.5734, -1.8360, 10.7633],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.36614990234375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.2082, -0.6582, -0.7309,  1.8053,  3.9324,  3.8698, -1.3544,  1.4496,\n","        -8.8746,  5.7861,  3.6634,  5.5609,  1.4172,  8.5734, -1.8360, 10.7633],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.51042175292969\n","Epoch 13, Batch 153 - Training loss: 115.51042175292969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.6276,  0.8990, -1.6432,  5.9762,  3.4158, -3.0485, -1.3004,  4.2946,\n","        -5.7504,  6.1466,  5.0962,  5.5053, -4.0908,  6.2008,  0.1713,  5.2833],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9981, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.595703125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.6276,  0.8990, -1.6432,  5.9762,  3.4158, -3.0485, -1.3004,  4.2946,\n","        -5.7504,  6.1466,  5.0962,  5.5053, -4.0908,  6.2008,  0.1713,  5.2833],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9981, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.82623291015625\n","Epoch 13, Batch 154 - Training loss: 114.82623291015625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.0268,  -0.5006,  -0.5939,   2.1379,   2.4196,  -8.0946,  -3.0423,\n","          1.1663, -15.5211,   7.2669,   6.2669,  -2.8698,  -1.4918,  -0.1233,\n","         -2.7872,   7.3501], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.98538970947266\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.0268,  -0.5006,  -0.5939,   2.1379,   2.4196,  -8.0946,  -3.0423,\n","          1.1663, -15.5211,   7.2669,   6.2669,  -2.8698,  -1.4918,  -0.1233,\n","         -2.7872,   7.3501], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.86217498779297\n","Epoch 13, Batch 155 - Training loss: 110.86217498779297\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.9925,  8.3154,  2.2704,  7.5202,  7.2302, -1.7053,  3.1146,  1.8383,\n","        -9.0924,  6.9034,  6.7063,  4.3168,  5.3017, -0.1479,  0.5454,  5.3725],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.85060119628906\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.9925,  8.3154,  2.2704,  7.5202,  7.2302, -1.7053,  3.1146,  1.8383,\n","        -9.0924,  6.9034,  6.7063,  4.3168,  5.3017, -0.1479,  0.5454,  5.3725],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.2509765625\n","Epoch 13, Batch 156 - Training loss: 111.2509765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-0.4943,  3.8550, -3.3706, 10.2116,  3.5985, -3.1514, -2.2959,  6.8676,\n","        -7.9262,  5.4135,  6.9289, -0.0107,  0.1094,  9.4226, -0.7597,  5.8408],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9983, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.42036437988281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-0.4943,  3.8550, -3.3706, 10.2116,  3.5985, -3.1514, -2.2959,  6.8676,\n","        -7.9262,  5.4135,  6.9289, -0.0107,  0.1094,  9.4226, -0.7597,  5.8408],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9983, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.29243469238281\n","Epoch 13, Batch 157 - Training loss: 114.29243469238281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7914,   0.4230,   1.6302,   3.1811,   6.2033,  -1.6104,  -4.3993,\n","          0.5833, -14.7957,   6.4547,   5.2345,   2.7483,  -6.6289,  10.2252,\n","         -1.5560,   7.1060], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.75918579101562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7914,   0.4230,   1.6302,   3.1811,   6.2033,  -1.6104,  -4.3993,\n","          0.5833, -14.7957,   6.4547,   5.2345,   2.7483,  -6.6289,  10.2252,\n","         -1.5560,   7.1060], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.46809387207031\n","Epoch 13, Batch 158 - Training loss: 120.46809387207031\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.3450,  1.3386,  1.5349,  3.1181,  5.2630, -3.2454, -1.0938,  1.4796,\n","        -6.4117,  4.2743,  8.4798,  5.6797, -3.8066,  3.9350,  1.8705,  7.2904],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.84565734863281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.3450,  1.3386,  1.5349,  3.1181,  5.2630, -3.2454, -1.0938,  1.4796,\n","        -6.4117,  4.2743,  8.4798,  5.6797, -3.8066,  3.9350,  1.8705,  7.2904],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.51729583740234\n","Epoch 13, Batch 159 - Training loss: 119.51729583740234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.7117,  2.1699,  0.5723,  1.9166,  5.0399,  0.5035, -4.3792,  7.5259,\n","        -8.6785,  4.1841, 10.2012,  0.0713,  2.0353,  2.9452, -3.4520,  8.8321],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.12747192382812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.7117,  2.1699,  0.5723,  1.9166,  5.0399,  0.5035, -4.3792,  7.5259,\n","        -8.6785,  4.1841, 10.2012,  0.0713,  2.0353,  2.9452, -3.4520,  8.8321],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.04913330078125\n","Epoch 13, Batch 160 - Training loss: 116.04913330078125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.7670,  -0.0740,   2.0845,   1.3439,  10.2462,  -0.6758,  -3.0401,\n","          1.4942, -10.7074,   1.1661,   5.1763,   3.6153,   1.0014,   4.0677,\n","         -4.1891,   2.7831], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.6610336303711\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.7670,  -0.0740,   2.0845,   1.3439,  10.2462,  -0.6758,  -3.0401,\n","          1.4942, -10.7074,   1.1661,   5.1763,   3.6153,   1.0014,   4.0677,\n","         -4.1891,   2.7831], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.8578109741211\n","Epoch 13, Batch 161 - Training loss: 115.8578109741211\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.8493,   4.0039,   0.7059,   3.2493,   3.1402,  -0.3932,  -0.5942,\n","          0.5470, -11.5251,   7.6379,   1.5617,   1.5509,   1.5498,   1.0282,\n","          2.5657,   5.0077], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.45783233642578\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.8493,   4.0039,   0.7059,   3.2493,   3.1402,  -0.3932,  -0.5942,\n","          0.5470, -11.5251,   7.6379,   1.5617,   1.5509,   1.5498,   1.0282,\n","          2.5657,   5.0077], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.8400650024414\n","Epoch 13, Batch 162 - Training loss: 111.8400650024414\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.6372,  -2.5324,   5.1037,   7.2832,   4.6919,  -3.0859,  -2.4781,\n","          0.0125, -10.4379,   3.3896,  -0.4289,   9.3721,  -0.3750,   4.9935,\n","         -6.7603,   5.0089], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.20072937011719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.6372,  -2.5324,   5.1037,   7.2832,   4.6919,  -3.0859,  -2.4781,\n","          0.0125, -10.4379,   3.3896,  -0.4289,   9.3721,  -0.3750,   4.9935,\n","         -6.7603,   5.0089], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.4867172241211\n","Epoch 13, Batch 163 - Training loss: 116.4867172241211\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.3681,  2.1414, -2.7023,  4.8940,  4.3353,  1.6372, -6.6382,  1.6104,\n","        -8.9431,  6.9221,  5.2071,  4.1085, -5.5792,  4.1799,  0.2091,  5.2561],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.66289520263672\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.3681,  2.1414, -2.7023,  4.8940,  4.3353,  1.6372, -6.6382,  1.6104,\n","        -8.9431,  6.9221,  5.2071,  4.1085, -5.5792,  4.1799,  0.2091,  5.2561],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.78022766113281\n","Epoch 13, Batch 164 - Training loss: 111.78022766113281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.3208,   2.7087,   4.3270,   1.6977,   7.3236,  -5.0894,   2.7517,\n","          1.7087, -13.9171,   5.5596,   8.1647,   5.0670,  -3.5955,   8.2353,\n","         -1.4373,   2.4080], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.54898834228516\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.3208,   2.7087,   4.3270,   1.6977,   7.3236,  -5.0894,   2.7517,\n","          1.7087, -13.9171,   5.5596,   8.1647,   5.0670,  -3.5955,   8.2353,\n","         -1.4373,   2.4080], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.84468078613281\n","Epoch 13, Batch 165 - Training loss: 116.84468078613281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.5848,   2.8663,   1.2615,   4.3660,   4.1778,   1.1603,  -4.4272,\n","          1.0350, -14.8763,   1.1506,   2.2462,   7.0647,  -0.9604,   6.4918,\n","         -4.2853,   8.3562], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.69184112548828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.5848,   2.8663,   1.2615,   4.3660,   4.1778,   1.1603,  -4.4272,\n","          1.0350, -14.8763,   1.1506,   2.2462,   7.0647,  -0.9604,   6.4918,\n","         -4.2853,   8.3562], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.07174682617188\n","Epoch 13, Batch 166 - Training loss: 114.07174682617188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.0212,   1.8410,  -0.5734,   6.7501,   5.1337,  -1.6040,  -3.0996,\n","          3.1986, -10.5949,   2.8305,   4.3729,   2.4650,   0.9161,   3.4255,\n","         -1.8885,   8.4950], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9994,\n","        -1.0000, -1.0000, -1.0000, -0.9991, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.84589385986328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.0212,   1.8410,  -0.5734,   6.7501,   5.1337,  -1.6040,  -3.0996,\n","          3.1986, -10.5949,   2.8305,   4.3729,   2.4650,   0.9161,   3.4255,\n","         -1.8885,   8.4950], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9994,\n","        -1.0000, -1.0000, -1.0000, -0.9991, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.79309844970703\n","Epoch 13, Batch 167 - Training loss: 114.79309844970703\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.5002,  -1.9959,   1.7824,  -0.8749,   0.9913,  -0.3919,   1.4298,\n","         -1.2255, -16.7875,   3.2562,   4.1375,   0.3345,   0.9458,  -0.2712,\n","          1.4995,   2.4452], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9975,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.09113311767578\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.5002,  -1.9959,   1.7824,  -0.8749,   0.9913,  -0.3919,   1.4298,\n","         -1.2255, -16.7875,   3.2562,   4.1375,   0.3345,   0.9458,  -0.2712,\n","          1.4995,   2.4452], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9975,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.96441650390625\n","Epoch 13, Batch 168 - Training loss: 119.96441650390625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.0412,   0.2674,  -0.6927,   2.1998,   6.2484,  -0.6064,  -1.5709,\n","          2.9089, -11.5582,   2.4862,   4.8819,   1.7214,  -1.9703,   3.7525,\n","         -1.0916,   4.4031], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.77339935302734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.0412,   0.2674,  -0.6927,   2.1998,   6.2484,  -0.6064,  -1.5709,\n","          2.9089, -11.5582,   2.4862,   4.8819,   1.7214,  -1.9703,   3.7525,\n","         -1.0916,   4.4031], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.07459259033203\n","Epoch 13, Batch 169 - Training loss: 117.07459259033203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.3331,  -4.1407,   5.4981,   4.1884,   6.2119,  -1.7443,  -0.0893,\n","          2.7553, -14.0944,   2.0465,   1.2960,   3.7743,   0.7052,  -1.0300,\n","         -0.6962,   7.5375], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.17179870605469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.3331,  -4.1407,   5.4981,   4.1884,   6.2119,  -1.7443,  -0.0893,\n","          2.7553, -14.0944,   2.0465,   1.2960,   3.7743,   0.7052,  -1.0300,\n","         -0.6962,   7.5375], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.61414337158203\n","Epoch 13, Batch 170 - Training loss: 115.61414337158203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.5888, -0.6588, -1.0577,  1.7026,  3.4267, -3.1106, -5.7938,  0.8432,\n","        -5.4604,  5.4547,  4.6494, -4.5180,  0.1940, -0.3695,  0.2696,  3.5353],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9981, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.2690658569336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.5888, -0.6588, -1.0577,  1.7026,  3.4267, -3.1106, -5.7938,  0.8432,\n","        -5.4604,  5.4547,  4.6494, -4.5180,  0.1940, -0.3695,  0.2696,  3.5353],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9981, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.39009857177734\n","Epoch 13, Batch 171 - Training loss: 110.39009857177734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6794,   3.4118,   1.8669,   6.6064,   5.2074,  -4.4052,  -1.7618,\n","          0.5206, -12.5800,   4.8453,   3.3149,   3.0917,  -1.0175,   5.9045,\n","          2.2670,   5.1471], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.0383529663086\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6794,   3.4118,   1.8669,   6.6064,   5.2074,  -4.4052,  -1.7618,\n","          0.5206, -12.5800,   4.8453,   3.3149,   3.0917,  -1.0175,   5.9045,\n","          2.2670,   5.1471], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.05220794677734\n","Epoch 13, Batch 172 - Training loss: 115.05220794677734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.2027,  -0.0370,   4.6679,   3.3708,   2.6656,  -5.3716,  -0.9704,\n","          3.4883, -15.5831,   5.6509,   1.6938,   5.9462,  -0.7705,   2.3201,\n","          0.7724,   4.5165], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 122.5267105102539\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.2027,  -0.0370,   4.6679,   3.3708,   2.6656,  -5.3716,  -0.9704,\n","          3.4883, -15.5831,   5.6509,   1.6938,   5.9462,  -0.7705,   2.3201,\n","          0.7724,   4.5165], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 122.29907989501953\n","Epoch 13, Batch 173 - Training loss: 122.29907989501953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.8675,   0.1400,   3.0129,   4.4333,  -1.4112,  -3.2531,   1.7474,\n","          3.3245, -10.3701,   2.6617,   5.5965,   2.9098,   0.0957,   2.5326,\n","         -1.1816,   8.0255], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.10003662109375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.8675,   0.1400,   3.0129,   4.4333,  -1.4112,  -3.2531,   1.7474,\n","          3.3245, -10.3701,   2.6617,   5.5965,   2.9098,   0.0957,   2.5326,\n","         -1.1816,   8.0255], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.39749145507812\n","Epoch 13, Batch 174 - Training loss: 120.39749145507812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.9990, -3.1952,  1.3734,  0.9187,  1.6644,  1.5927, -2.9724, -3.0017,\n","        -8.1703,  4.0482,  7.8638,  2.2601, -6.6311,  4.7905, -4.8460,  6.5266],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.5566177368164\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.9990, -3.1952,  1.3734,  0.9187,  1.6644,  1.5927, -2.9724, -3.0017,\n","        -8.1703,  4.0482,  7.8638,  2.2601, -6.6311,  4.7905, -4.8460,  6.5266],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.65217590332031\n","Epoch 13, Batch 175 - Training loss: 116.65217590332031\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.4678, -1.4440,  2.2174,  4.8700,  2.9891, -2.2743, -0.8649,  7.9057,\n","        -9.7916,  3.1029,  7.3518,  1.1580, -3.2432, -0.8087, -3.2480,  9.0751],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9978, -1.0000, -0.9987, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9984, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.56240844726562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.4678, -1.4440,  2.2174,  4.8700,  2.9891, -2.2743, -0.8649,  7.9057,\n","        -9.7916,  3.1029,  7.3518,  1.1580, -3.2432, -0.8087, -3.2480,  9.0751],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9978, -1.0000, -0.9987, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9984, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.75407409667969\n","Epoch 13, Batch 176 - Training loss: 112.75407409667969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.4512e+00,  2.8873e+00, -3.7063e+00,  1.1499e+00,  3.0609e+00,\n","        -1.6614e-01, -9.9621e-03,  3.1699e+00, -1.3122e+01,  5.3265e+00,\n","         2.5240e+00,  2.4163e+00,  8.3961e-01,  5.7193e+00, -2.4328e+00,\n","         8.6197e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.79783630371094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.4512e+00,  2.8873e+00, -3.7063e+00,  1.1499e+00,  3.0609e+00,\n","        -1.6614e-01, -9.9621e-03,  3.1699e+00, -1.3122e+01,  5.3265e+00,\n","         2.5240e+00,  2.4163e+00,  8.3961e-01,  5.7193e+00, -2.4328e+00,\n","         8.6197e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.96566772460938\n","Epoch 13, Batch 177 - Training loss: 117.96566772460938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.3640,  -0.2346,  -0.4684,   3.6875,   6.1757,  -2.9318,  -2.6143,\n","          4.2007, -13.5108,   3.1009,   5.3696,   6.5764,   4.7919,   2.2839,\n","          0.0142,   4.7830], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.03367614746094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.3640,  -0.2346,  -0.4684,   3.6875,   6.1757,  -2.9318,  -2.6143,\n","          4.2007, -13.5108,   3.1009,   5.3696,   6.5764,   4.7919,   2.2839,\n","          0.0142,   4.7830], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.75204467773438\n","Epoch 13, Batch 178 - Training loss: 117.75204467773438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1531,   3.3196,   1.5015,  -2.9528,   7.8391,  -3.4227,  -1.9631,\n","          1.0097, -13.0663,   6.3383,   7.5131,   1.6853,  -4.4225,   2.6393,\n","         -1.0131,   7.7558], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.68392944335938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1531,   3.3196,   1.5015,  -2.9528,   7.8391,  -3.4227,  -1.9631,\n","          1.0097, -13.0663,   6.3383,   7.5131,   1.6853,  -4.4225,   2.6393,\n","         -1.0131,   7.7558], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.3592529296875\n","Epoch 13, Batch 179 - Training loss: 117.3592529296875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.9883,  -0.3611,   2.3606,   4.2300,   5.5269,   0.0310,  -1.4223,\n","          3.1850, -10.7713,   1.1122,   5.4599,   1.9719,  -4.1941,   7.1913,\n","          1.8683,   6.1538], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.50856018066406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.9883,  -0.3611,   2.3606,   4.2300,   5.5269,   0.0310,  -1.4223,\n","          3.1850, -10.7713,   1.1122,   5.4599,   1.9719,  -4.1941,   7.1913,\n","          1.8683,   6.1538], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.69261932373047\n","Epoch 13, Batch 180 - Training loss: 115.69261932373047\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.9590, -0.0318, -0.9476,  5.4553,  5.5537,  1.0138, -1.3010, -0.8002,\n","        -8.2235,  5.1586,  4.1215,  2.0650, -1.2695,  3.8094, -1.4267,  4.2908],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.8541030883789\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.9590, -0.0318, -0.9476,  5.4553,  5.5537,  1.0138, -1.3010, -0.8002,\n","        -8.2235,  5.1586,  4.1215,  2.0650, -1.2695,  3.8094, -1.4267,  4.2908],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.20984649658203\n","Epoch 13, Batch 181 - Training loss: 114.20984649658203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.6550,  1.8656,  3.5122,  7.6907,  5.1591, -1.4523,  2.7331,  0.6623,\n","        -9.0996,  5.5663,  5.2261,  0.8053, -1.4812,  8.0421, -0.3168,  7.6518],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.04459381103516\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.6550,  1.8656,  3.5122,  7.6907,  5.1591, -1.4523,  2.7331,  0.6623,\n","        -9.0996,  5.5663,  5.2261,  0.8053, -1.4812,  8.0421, -0.3168,  7.6518],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.21570587158203\n","Epoch 13, Batch 182 - Training loss: 116.21570587158203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.6188, -1.4506,  1.3811,  1.3908, -0.7715, -5.3021, -0.1148,  2.8639,\n","        -8.6824, -1.9122,  7.0191,  4.4280, -1.1646,  1.3938,  2.6071,  4.1130],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.77987670898438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.6188, -1.4506,  1.3811,  1.3908, -0.7715, -5.3021, -0.1148,  2.8639,\n","        -8.6824, -1.9122,  7.0191,  4.4280, -1.1646,  1.3938,  2.6071,  4.1130],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.5379867553711\n","Epoch 13, Batch 183 - Training loss: 119.5379867553711\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.1715,   4.9159,   1.4232,   4.9685,   5.1872,  -6.1839,  -3.7353,\n","          5.1868, -10.8854,   5.1285,   0.5549,   6.7425,   3.0657,   1.7481,\n","         -0.9668,   6.3535], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.39283752441406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.1715,   4.9159,   1.4232,   4.9685,   5.1872,  -6.1839,  -3.7353,\n","          5.1868, -10.8854,   5.1285,   0.5549,   6.7425,   3.0657,   1.7481,\n","         -0.9668,   6.3535], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.56950378417969\n","Epoch 13, Batch 184 - Training loss: 112.56950378417969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.1407e+00, -8.7770e-03,  5.5935e-01,  8.3436e+00,  5.5609e+00,\n","        -1.5354e+00, -1.9142e-01,  3.9850e+00, -1.4140e+01,  1.9037e+00,\n","         6.5232e+00,  4.9696e+00, -5.8709e+00,  7.2606e+00, -6.2388e+00,\n","         9.2392e+00], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 123.59727478027344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.1407e+00, -8.7770e-03,  5.5935e-01,  8.3436e+00,  5.5609e+00,\n","        -1.5354e+00, -1.9142e-01,  3.9850e+00, -1.4140e+01,  1.9037e+00,\n","         6.5232e+00,  4.9696e+00, -5.8709e+00,  7.2606e+00, -6.2388e+00,\n","         9.2392e+00], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 123.50914764404297\n","Epoch 13, Batch 185 - Training loss: 123.50914764404297\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.6633,   3.5134,  -1.4539,   1.5240,   9.2939,  -5.5751,  -2.0216,\n","          4.1661, -13.2279,   1.4555,   8.8651,   2.9640,  -1.3387,  -0.3379,\n","         -4.4848,   9.4839], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9983, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.18399810791016\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.6633,   3.5134,  -1.4539,   1.5240,   9.2939,  -5.5751,  -2.0216,\n","          4.1661, -13.2279,   1.4555,   8.8651,   2.9640,  -1.3387,  -0.3379,\n","         -4.4848,   9.4839], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9983, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.09950256347656\n","Epoch 13, Batch 186 - Training loss: 117.09950256347656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.4585,  1.2446,  2.9295,  2.4698,  2.0695, -0.4363, -4.4825,  2.4954,\n","        -9.1642,  4.3124,  7.5286,  6.4159, -4.3818,  1.8243, -3.3448,  2.2211],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.47916412353516\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.4585,  1.2446,  2.9295,  2.4698,  2.0695, -0.4363, -4.4825,  2.4954,\n","        -9.1642,  4.3124,  7.5286,  6.4159, -4.3818,  1.8243, -3.3448,  2.2211],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.7484359741211\n","Epoch 13, Batch 187 - Training loss: 112.7484359741211\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.1022,  -0.9969,  -0.7496,  -0.9403,   6.7985,   0.9674,  -7.8973,\n","          0.0966, -14.5062,   2.5724,   9.9367,  -1.2757,   1.5552,  -1.8067,\n","         -1.9282,   9.5769], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.04469299316406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.1022,  -0.9969,  -0.7496,  -0.9403,   6.7985,   0.9674,  -7.8973,\n","          0.0966, -14.5062,   2.5724,   9.9367,  -1.2757,   1.5552,  -1.8067,\n","         -1.9282,   9.5769], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.64653015136719\n","Epoch 13, Batch 188 - Training loss: 110.64653015136719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6563,   2.9270,   1.0141,   4.5042,   8.0644,  -4.3602,  -3.1099,\n","          0.5807, -10.0863,   3.6282,   7.3199,   5.8692,  -0.8485,   2.2822,\n","          0.0745,   9.5149], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.2094955444336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6563,   2.9270,   1.0141,   4.5042,   8.0644,  -4.3602,  -3.1099,\n","          0.5807, -10.0863,   3.6282,   7.3199,   5.8692,  -0.8485,   2.2822,\n","          0.0745,   9.5149], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.52302551269531\n","Epoch 13, Batch 189 - Training loss: 109.52302551269531\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-11.7261,   0.1074,  -2.6442,   5.1502,   5.4594,  -3.2561,   1.2753,\n","         -1.3187, -11.0881,   7.0873,   6.0192,   1.1953,  -2.8700,   4.1794,\n","         -7.8240,  12.6866], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.6380844116211\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-11.7261,   0.1074,  -2.6442,   5.1502,   5.4594,  -3.2561,   1.2753,\n","         -1.3187, -11.0881,   7.0873,   6.0192,   1.1953,  -2.8700,   4.1794,\n","         -7.8240,  12.6866], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.41650390625\n","Epoch 13, Batch 190 - Training loss: 116.41650390625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1635,  2.1886,  0.9976,  5.9442,  4.2020,  1.3704, -1.8421,  6.7237,\n","        -9.7354,  5.1096,  4.3478,  3.0184, -1.1600,  1.7946, -2.8461,  7.2167],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9953, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.67603302001953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1635,  2.1886,  0.9976,  5.9442,  4.2020,  1.3704, -1.8421,  6.7237,\n","        -9.7354,  5.1096,  4.3478,  3.0184, -1.1600,  1.7946, -2.8461,  7.2167],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9953, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.76587677001953\n","Epoch 13, Batch 191 - Training loss: 116.76587677001953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  0.3808,  -1.3246,   2.0671,   6.5886,   1.7709,  -0.4144,   0.4067,\n","          2.8563, -11.6245,   7.0205,   4.5184,   0.8702,   6.6715,   2.6075,\n","          2.4199,   0.9071], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.67615509033203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  0.3808,  -1.3246,   2.0671,   6.5886,   1.7709,  -0.4144,   0.4067,\n","          2.8563, -11.6245,   7.0205,   4.5184,   0.8702,   6.6715,   2.6075,\n","          2.4199,   0.9071], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.9206771850586\n","Epoch 13, Batch 192 - Training loss: 108.9206771850586\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.2029,   4.1269,   2.5542,   5.6685,   5.9867,  -1.4030,  -2.6996,\n","          0.3913, -13.1585,   0.3960,   9.5597,   6.2750,  -0.3293,   2.8745,\n","         -2.2163,  11.1989], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9972, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.44706726074219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.2029,   4.1269,   2.5542,   5.6685,   5.9867,  -1.4030,  -2.6996,\n","          0.3913, -13.1585,   0.3960,   9.5597,   6.2750,  -0.3293,   2.8745,\n","         -2.2163,  11.1989], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9972, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.00182342529297\n","Epoch 13, Batch 193 - Training loss: 115.00182342529297\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.1906,   2.4360,   3.8686,   6.7588,   2.9666,  -0.5168,  -2.7453,\n","          3.9894, -13.9447,   6.1975,   2.1588,   7.0758,   0.2711,   6.5115,\n","          1.9499,   5.4503], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.25570678710938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.1906,   2.4360,   3.8686,   6.7588,   2.9666,  -0.5168,  -2.7453,\n","          3.9894, -13.9447,   6.1975,   2.1588,   7.0758,   0.2711,   6.5115,\n","          1.9499,   5.4503], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.60948181152344\n","Epoch 13, Batch 194 - Training loss: 117.60948181152344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 0.9418, -0.0495,  0.0991,  3.8005,  7.3212, -1.7397, -2.9082,  2.9216,\n","        -8.6328,  4.8643,  4.8348,  3.1014, -1.2060,  3.4260,  0.2882,  5.5207],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.40675354003906\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 0.9418, -0.0495,  0.0991,  3.8005,  7.3212, -1.7397, -2.9082,  2.9216,\n","        -8.6328,  4.8643,  4.8348,  3.1014, -1.2060,  3.4260,  0.2882,  5.5207],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.14768981933594\n","Epoch 13, Batch 195 - Training loss: 112.14768981933594\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.7588,  -0.0604,  -1.1120,   2.2593,   4.7025,   1.6055,   0.0322,\n","          3.8474, -11.5895,   5.1775,   3.9869,   2.6690,  -0.6156,   0.7265,\n","          1.6131,   4.4694], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.94999694824219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.7588,  -0.0604,  -1.1120,   2.2593,   4.7025,   1.6055,   0.0322,\n","          3.8474, -11.5895,   5.1775,   3.9869,   2.6690,  -0.6156,   0.7265,\n","          1.6131,   4.4694], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9989, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.74342346191406\n","Epoch 13, Batch 196 - Training loss: 116.74342346191406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.2555e+00,  3.3678e+00,  2.3379e+00,  2.6184e-01,  4.1423e+00,\n","         4.0451e-01, -3.6337e+00, -1.8888e+00, -1.3278e+01,  9.7260e+00,\n","         5.7434e+00, -4.0312e+00,  3.2571e+00,  6.7282e-03, -2.2000e+00,\n","         9.6492e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.95714569091797\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.2555e+00,  3.3678e+00,  2.3379e+00,  2.6184e-01,  4.1423e+00,\n","         4.0451e-01, -3.6337e+00, -1.8888e+00, -1.3278e+01,  9.7260e+00,\n","         5.7434e+00, -4.0312e+00,  3.2571e+00,  6.7282e-03, -2.2000e+00,\n","         9.6492e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.8515853881836\n","Epoch 13, Batch 197 - Training loss: 111.8515853881836\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.8820, -4.0610,  5.4282, -5.4893,  2.8763, -2.6001,  1.0540,  1.6089,\n","        -7.0463, -0.6561, 10.4820,  3.5862, -3.6185,  1.3497,  0.6085,  7.1554],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.99089813232422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.8820, -4.0610,  5.4282, -5.4893,  2.8763, -2.6001,  1.0540,  1.6089,\n","        -7.0463, -0.6561, 10.4820,  3.5862, -3.6185,  1.3497,  0.6085,  7.1554],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.8837661743164\n","Epoch 13, Batch 198 - Training loss: 114.8837661743164\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.9177,   1.5914,   2.5543,   2.3645,   4.9992,  -2.9136,  -3.4126,\n","          6.6541, -12.7716,   3.9769,   3.6535,   7.0712,   3.3378,   5.8024,\n","         -0.7454,   7.7784], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.54525756835938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.9177,   1.5914,   2.5543,   2.3645,   4.9992,  -2.9136,  -3.4126,\n","          6.6541, -12.7716,   3.9769,   3.6535,   7.0712,   3.3378,   5.8024,\n","         -0.7454,   7.7784], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.2926254272461\n","Epoch 13, Batch 199 - Training loss: 117.2926254272461\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.4963,  -1.3982,  -0.7603,   2.2950,   2.8378,  -2.3975,  -0.1249,\n","          0.8206, -10.0142,   0.8439,   5.6468,   2.7046,  -2.3542,   2.0513,\n","          2.2648,   6.7700], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9983, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9991, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.08390045166016\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.4963,  -1.3982,  -0.7603,   2.2950,   2.8378,  -2.3975,  -0.1249,\n","          0.8206, -10.0142,   0.8439,   5.6468,   2.7046,  -2.3542,   2.0513,\n","          2.2648,   6.7700], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9983, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9991, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.5505142211914\n","Epoch 13, Batch 200 - Training loss: 117.5505142211914\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.8618,   1.0902,  -0.0333,   4.0623,   5.5334,   0.5846,  -4.0680,\n","         -0.1533, -11.2407,   2.7799,   4.1898,   1.3065,  -2.1742,   4.3259,\n","         -2.5878,   2.2493], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9978, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.03530883789062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -2.8618,   1.0902,  -0.0333,   4.0623,   5.5334,   0.5846,  -4.0680,\n","         -0.1533, -11.2407,   2.7799,   4.1898,   1.3065,  -2.1742,   4.3259,\n","         -2.5878,   2.2493], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9978, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.02243041992188\n","Epoch 13, Batch 201 - Training loss: 113.02243041992188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5230,  -0.7858,   0.7083,   4.1045,   8.4614,  -2.2929,  -1.4536,\n","         -2.1352, -11.6182,   5.5597,   5.1155,   6.3137,   1.2102,   3.5958,\n","         -1.7088,   7.2991], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9985, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.57084655761719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5230,  -0.7858,   0.7083,   4.1045,   8.4614,  -2.2929,  -1.4536,\n","         -2.1352, -11.6182,   5.5597,   5.1155,   6.3137,   1.2102,   3.5958,\n","         -1.7088,   7.2991], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9985, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.43030548095703\n","Epoch 13, Batch 202 - Training loss: 112.43030548095703\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.4146,  -1.4630,  -0.7489,   2.8587,   4.5270,  -3.6941,   0.7122,\n","          2.8299, -13.6879,  -0.2484,   4.0541,   0.1916,  -0.8561,   7.9886,\n","         -0.2808,   5.6044], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.54346466064453\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.4146,  -1.4630,  -0.7489,   2.8587,   4.5270,  -3.6941,   0.7122,\n","          2.8299, -13.6879,  -0.2484,   4.0541,   0.1916,  -0.8561,   7.9886,\n","         -0.2808,   5.6044], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.59356689453125\n","Epoch 13, Batch 203 - Training loss: 116.59356689453125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.7016, -0.9922,  3.5011,  0.7247, -0.7256,  0.6557,  2.0416,  1.1810,\n","        -9.9029,  6.5963, -0.1585,  4.5270,  2.2017,  3.6003, -4.4433,  9.1756],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.59185028076172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.7016, -0.9922,  3.5011,  0.7247, -0.7256,  0.6557,  2.0416,  1.1810,\n","        -9.9029,  6.5963, -0.1585,  4.5270,  2.2017,  3.6003, -4.4433,  9.1756],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.01286315917969\n","Epoch 13, Batch 204 - Training loss: 113.01286315917969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.8862,   2.0499,   2.9625,   3.3544,   4.2592,   1.4412,  -2.0579,\n","          3.9349, -13.1871,   2.6823,   6.4114,   1.5410,  -3.0672,   5.1076,\n","          1.3728,   5.1405], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9978, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.45034790039062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.8862,   2.0499,   2.9625,   3.3544,   4.2592,   1.4412,  -2.0579,\n","          3.9349, -13.1871,   2.6823,   6.4114,   1.5410,  -3.0672,   5.1076,\n","          1.3728,   5.1405], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9978, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.53192138671875\n","Epoch 13, Batch 205 - Training loss: 119.53192138671875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.2822,  -2.2276,   1.9675,  -3.4343,   0.8837,   0.9623,  -2.3444,\n","         -2.0271, -10.4858,   0.3543,   5.0011,   8.7668,  -0.4692,   1.3447,\n","          2.2750,  10.4606], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.5054702758789\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.2822,  -2.2276,   1.9675,  -3.4343,   0.8837,   0.9623,  -2.3444,\n","         -2.0271, -10.4858,   0.3543,   5.0011,   8.7668,  -0.4692,   1.3447,\n","          2.2750,  10.4606], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.32301330566406\n","Epoch 13, Batch 206 - Training loss: 111.32301330566406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.5110,  -3.9883,  -1.3900,   1.3436,   1.9535,  -2.6479,   0.0255,\n","         -0.2709, -11.3789,   1.3240,   6.9108,   3.6880,   0.4684,   5.1197,\n","         -1.2679,  12.0553], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.8043212890625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.5110,  -3.9883,  -1.3900,   1.3436,   1.9535,  -2.6479,   0.0255,\n","         -0.2709, -11.3789,   1.3240,   6.9108,   3.6880,   0.4684,   5.1197,\n","         -1.2679,  12.0553], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.0570068359375\n","Epoch 13, Batch 207 - Training loss: 113.0570068359375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.2005,   0.8869,  -0.1793,   3.0220,   5.8201,  -0.4660,  -0.4302,\n","         -1.0553, -11.6152,   4.5974,   6.4377,   6.2983,  -1.6862,   5.1961,\n","         -2.7304,  10.8562], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9984, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.16368103027344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.2005,   0.8869,  -0.1793,   3.0220,   5.8201,  -0.4660,  -0.4302,\n","         -1.0553, -11.6152,   4.5974,   6.4377,   6.2983,  -1.6862,   5.1961,\n","         -2.7304,  10.8562], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9984, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.1765365600586\n","Epoch 13, Batch 208 - Training loss: 113.1765365600586\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5619,  -0.8984,   1.6131,   4.0830,  -0.1659,   1.8273,  -3.1750,\n","          6.1150, -11.1520,   1.2605,   4.0561,   6.3021,  -1.0430,   4.4956,\n","          0.3960,   4.5355], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.7208023071289\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.5619,  -0.8984,   1.6131,   4.0830,  -0.1659,   1.8273,  -3.1750,\n","          6.1150, -11.1520,   1.2605,   4.0561,   6.3021,  -1.0430,   4.4956,\n","          0.3960,   4.5355], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.0369644165039\n","Epoch 13, Batch 209 - Training loss: 111.0369644165039\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.3037,  -2.0289,   2.8944,   2.2413,   2.8615,  -5.2101,  -3.6545,\n","          0.6392, -11.2727,  -1.3895,   6.0021,   6.2622,  -0.5333,   2.3643,\n","         -0.0915,   8.9206], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.182861328125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.3037,  -2.0289,   2.8944,   2.2413,   2.8615,  -5.2101,  -3.6545,\n","          0.6392, -11.2727,  -1.3895,   6.0021,   6.2622,  -0.5333,   2.3643,\n","         -0.0915,   8.9206], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.04167175292969\n","Epoch 13, Batch 210 - Training loss: 114.04167175292969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.1969,  -3.6321,  -0.6391,   3.1157,   5.8448,  -2.8663,  -0.9881,\n","          2.2991, -12.7375,  -1.6541,   3.4723,   7.8374,  -5.3222,   4.7043,\n","          2.3694,   5.1083], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9994, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.08145904541016\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.1969,  -3.6321,  -0.6391,   3.1157,   5.8448,  -2.8663,  -0.9881,\n","          2.2991, -12.7375,  -1.6541,   3.4723,   7.8374,  -5.3222,   4.7043,\n","          2.3694,   5.1083], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9985, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9994, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.77911376953125\n","Epoch 13, Batch 211 - Training loss: 116.77911376953125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.6514,   2.3672,  -4.6557,   5.4037,   1.4969,  -3.4334,  -3.3071,\n","          1.8129, -13.4858,   6.9672,   3.1434,   4.1784,   3.1892,   7.1794,\n","         -4.8796,   7.6620], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.93793487548828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.6514,   2.3672,  -4.6557,   5.4037,   1.4969,  -3.4334,  -3.3071,\n","          1.8129, -13.4858,   6.9672,   3.1434,   4.1784,   3.1892,   7.1794,\n","         -4.8796,   7.6620], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.18777465820312\n","Epoch 13, Batch 212 - Training loss: 111.18777465820312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  0.8739,   1.4552,  -4.0807,   3.4765,   4.3192,  -0.1899,  -2.0687,\n","         11.2538, -10.8823,   6.1632,   6.2863,   3.1480,   5.9225,   5.0269,\n","          1.6947,   4.0937], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 107.03193664550781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  0.8739,   1.4552,  -4.0807,   3.4765,   4.3192,  -0.1899,  -2.0687,\n","         11.2538, -10.8823,   6.1632,   6.2863,   3.1480,   5.9225,   5.0269,\n","          1.6947,   4.0937], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 107.14641571044922\n","Epoch 13, Batch 213 - Training loss: 107.14641571044922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7453,  -1.7061,   2.5520,  -3.2690,   6.8007,  -0.9042,  -1.4376,\n","          0.9794, -11.3168,   5.3592,   7.5874,  -0.8809,  -1.5252,   3.2770,\n","          1.7695,   5.7813], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9989, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.15555572509766\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7453,  -1.7061,   2.5520,  -3.2690,   6.8007,  -0.9042,  -1.4376,\n","          0.9794, -11.3168,   5.3592,   7.5874,  -0.8809,  -1.5252,   3.2770,\n","          1.7695,   5.7813], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9989, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.88772583007812\n","Epoch 13, Batch 214 - Training loss: 112.88772583007812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.3681,   4.3208,   4.5726,   1.5389,   8.5560,   0.8953,   4.5322,\n","         -2.0798, -10.1325,   1.5003,   7.2116,   4.1591,  -4.6854,   2.7456,\n","          3.8085,   8.7675], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.51007080078125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.3681,   4.3208,   4.5726,   1.5389,   8.5560,   0.8953,   4.5322,\n","         -2.0798, -10.1325,   1.5003,   7.2116,   4.1591,  -4.6854,   2.7456,\n","          3.8085,   8.7675], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.93280029296875\n","Epoch 13, Batch 215 - Training loss: 113.93280029296875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.8945,  -0.3849,  -0.2513,  -2.1434,   3.1814,  -0.0203,  -2.6048,\n","          2.0683, -16.2766,   1.5867,   5.1492,   0.8469,  -0.6488,   3.1326,\n","          1.9697,   7.3078], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.94203186035156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.8945,  -0.3849,  -0.2513,  -2.1434,   3.1814,  -0.0203,  -2.6048,\n","          2.0683, -16.2766,   1.5867,   5.1492,   0.8469,  -0.6488,   3.1326,\n","          1.9697,   7.3078], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.67982482910156\n","Epoch 13, Batch 216 - Training loss: 119.67982482910156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.9289,   2.3577,   2.4972,   0.5462,   9.0279,  -3.6870,  -1.3802,\n","          3.3611, -13.2461,  -0.2690,   2.2447,   3.8070,  -5.2116,   8.3430,\n","          2.6519,   4.7263], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.03968811035156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.9289,   2.3577,   2.4972,   0.5462,   9.0279,  -3.6870,  -1.3802,\n","          3.3611, -13.2461,  -0.2690,   2.2447,   3.8070,  -5.2116,   8.3430,\n","          2.6519,   4.7263], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.43124389648438\n","Epoch 13, Batch 217 - Training loss: 117.43124389648438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.0739,  -3.4063,  -0.0326,   3.4030,   3.3205,  -0.3632,  -1.2077,\n","          1.5796, -10.1893,   5.3940,   8.7031,   0.2394,  -2.0944,   4.7668,\n","         -2.1163,   4.9204], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.4759750366211\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.0739,  -3.4063,  -0.0326,   3.4030,   3.3205,  -0.3632,  -1.2077,\n","          1.5796, -10.1893,   5.3940,   8.7031,   0.2394,  -2.0944,   4.7668,\n","         -2.1163,   4.9204], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.81636810302734\n","Epoch 13, Batch 218 - Training loss: 111.81636810302734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.7190,  0.9920, -1.2750, -0.0168,  3.2731,  0.1742,  0.3241,  1.2033,\n","        -8.8921,  1.7045,  3.7882,  5.6274, -1.0011,  4.6744, -3.1019,  4.4906],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.04976654052734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.7190,  0.9920, -1.2750, -0.0168,  3.2731,  0.1742,  0.3241,  1.2033,\n","        -8.8921,  1.7045,  3.7882,  5.6274, -1.0011,  4.6744, -3.1019,  4.4906],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.23177337646484\n","Epoch 13, Batch 219 - Training loss: 115.23177337646484\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0111, -1.9232, -2.6153, -0.1721,  1.6071, -1.3723, -1.4968,  4.1718,\n","        -9.2723,  1.1985, 12.6791,  0.1341, -5.7846,  5.7466,  0.4239,  8.9267],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.5269546508789\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0111, -1.9232, -2.6153, -0.1721,  1.6071, -1.3723, -1.4968,  4.1718,\n","        -9.2723,  1.1985, 12.6791,  0.1341, -5.7846,  5.7466,  0.4239,  8.9267],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.0474624633789\n","Epoch 13, Batch 220 - Training loss: 113.0474624633789\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1462, -0.6506,  3.8186,  3.4881,  4.9397,  2.4826, -0.4350,  2.4439,\n","        -8.1144,  4.9688,  6.3541,  5.7954, -0.2314,  4.4608, -0.6229,  4.8635],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.19915771484375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1462, -0.6506,  3.8186,  3.4881,  4.9397,  2.4826, -0.4350,  2.4439,\n","        -8.1144,  4.9688,  6.3541,  5.7954, -0.2314,  4.4608, -0.6229,  4.8635],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.28152465820312\n","Epoch 13, Batch 221 - Training loss: 117.28152465820312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0296, -0.9452,  1.2684,  7.7519,  2.8865, -3.9217, -1.4956,  1.7761,\n","        -6.8151,  0.0842,  4.3321,  3.7323, -0.7330, -0.1212, -4.5404,  6.0361],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.42984008789062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0296, -0.9452,  1.2684,  7.7519,  2.8865, -3.9217, -1.4956,  1.7761,\n","        -6.8151,  0.0842,  4.3321,  3.7323, -0.7330, -0.1212, -4.5404,  6.0361],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.651611328125\n","Epoch 13, Batch 222 - Training loss: 116.651611328125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6916,  -2.6200,   2.7472,   0.2467,   2.2157,   5.3049,   0.5556,\n","          3.7636, -12.3210,   2.4038,   1.8872,  -1.3447,  -1.4159,  -0.6299,\n","          1.1270,   6.4291], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.22946166992188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6916,  -2.6200,   2.7472,   0.2467,   2.2157,   5.3049,   0.5556,\n","          3.7636, -12.3210,   2.4038,   1.8872,  -1.3447,  -1.4159,  -0.6299,\n","          1.1270,   6.4291], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.12468719482422\n","Epoch 13, Batch 223 - Training loss: 108.12468719482422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4517,   0.8954,   0.3629,   3.7013,   5.6962,  -4.1301,  -1.0536,\n","          2.1375, -10.1252,   2.1966,   3.1713,   4.4597,   0.9003,   3.9134,\n","         -3.6122,   5.0085], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.8045883178711\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4517,   0.8954,   0.3629,   3.7013,   5.6962,  -4.1301,  -1.0536,\n","          2.1375, -10.1252,   2.1966,   3.1713,   4.4597,   0.9003,   3.9134,\n","         -3.6122,   5.0085], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.7173080444336\n","Epoch 13, Batch 224 - Training loss: 115.7173080444336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-0.9850,  2.2248,  0.8784,  5.9503,  6.4319, -0.7189, -4.1942,  7.3332,\n","        -6.7597, -1.5808,  7.2289,  0.1854, -0.0506,  1.1243,  1.7897, 13.2175],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.99423217773438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-0.9850,  2.2248,  0.8784,  5.9503,  6.4319, -0.7189, -4.1942,  7.3332,\n","        -6.7597, -1.5808,  7.2289,  0.1854, -0.0506,  1.1243,  1.7897, 13.2175],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.16255950927734\n","Epoch 13, Batch 225 - Training loss: 115.16255950927734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.3294, -2.1709,  2.0247,  2.0224,  7.5732,  1.4508, -7.3270,  0.8304,\n","        -7.8309,  3.8327,  9.3228,  3.8042, -1.8708,  1.0770, -0.3064,  9.0786],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9983, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.63884735107422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.3294, -2.1709,  2.0247,  2.0224,  7.5732,  1.4508, -7.3270,  0.8304,\n","        -7.8309,  3.8327,  9.3228,  3.8042, -1.8708,  1.0770, -0.3064,  9.0786],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9983, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.97456359863281\n","Epoch 13, Batch 226 - Training loss: 116.97456359863281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.1704,   1.7633,   0.2998,  -1.9767,   3.2425,   0.4049,  -1.4502,\n","          2.6765, -12.4307,   4.7370,   5.9548,  -0.7875,   0.9953,   4.6021,\n","         -5.3253,   9.0825], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.42156982421875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.1704,   1.7633,   0.2998,  -1.9767,   3.2425,   0.4049,  -1.4502,\n","          2.6765, -12.4307,   4.7370,   5.9548,  -0.7875,   0.9953,   4.6021,\n","         -5.3253,   9.0825], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.1026382446289\n","Epoch 13, Batch 227 - Training loss: 117.1026382446289\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.3842,   1.7590,  -0.7760,   4.6149,   2.1257,   0.3666,  -2.6805,\n","          1.1952, -12.5157,   9.5385,   7.2235,   6.9619,  -1.8728,   7.8734,\n","          2.6291,   9.1807], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.7548599243164\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.3842,   1.7590,  -0.7760,   4.6149,   2.1257,   0.3666,  -2.6805,\n","          1.1952, -12.5157,   9.5385,   7.2235,   6.9619,  -1.8728,   7.8734,\n","          2.6291,   9.1807], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.66140747070312\n","Epoch 13, Batch 228 - Training loss: 113.66140747070312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.3951,  -1.0421,   3.3840,   7.3049,   1.4712,  -0.8822,  -1.2869,\n","          3.3702, -12.6945,  -0.3352,   4.2930,   1.8758,   0.4547,   4.2373,\n","          1.4465,   6.9553], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.016845703125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.3951,  -1.0421,   3.3840,   7.3049,   1.4712,  -0.8822,  -1.2869,\n","          3.3702, -12.6945,  -0.3352,   4.2930,   1.8758,   0.4547,   4.2373,\n","          1.4465,   6.9553], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.3281478881836\n","Epoch 13, Batch 229 - Training loss: 118.3281478881836\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.0271,   2.3726,   1.6320,   5.3768,   0.6640,   3.8759,  -7.5513,\n","          4.0186, -15.9853,   5.4406,   6.2069,   2.3449,   2.1247,   4.4620,\n","         -0.3662,   6.8450], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.14313507080078\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.0271,   2.3726,   1.6320,   5.3768,   0.6640,   3.8759,  -7.5513,\n","          4.0186, -15.9853,   5.4406,   6.2069,   2.3449,   2.1247,   4.4620,\n","         -0.3662,   6.8450], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.82992553710938\n","Epoch 13, Batch 230 - Training loss: 114.82992553710938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.3703e+00, -2.8458e-01,  8.8776e-02,  3.5827e+00,  4.8171e+00,\n","        -7.3481e-03,  6.2384e-01,  4.9798e+00, -9.0122e+00,  1.2536e+00,\n","         5.2868e+00,  1.0486e+00, -5.9503e+00,  2.0579e+00, -3.4546e+00,\n","         7.5593e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.29423522949219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.3703e+00, -2.8458e-01,  8.8776e-02,  3.5827e+00,  4.8171e+00,\n","        -7.3481e-03,  6.2384e-01,  4.9798e+00, -9.0122e+00,  1.2536e+00,\n","         5.2868e+00,  1.0486e+00, -5.9503e+00,  2.0579e+00, -3.4546e+00,\n","         7.5593e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.1307601928711\n","Epoch 13, Batch 231 - Training loss: 115.1307601928711\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.8833,  2.3872,  1.4967,  3.1014,  4.5452, -2.9577, -1.7647,  4.2631,\n","        -9.9666,  4.3704, 10.8143,  2.1419, -2.0393,  3.1355, -1.4962,  7.0710],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.4516830444336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.8833,  2.3872,  1.4967,  3.1014,  4.5452, -2.9577, -1.7647,  4.2631,\n","        -9.9666,  4.3704, 10.8143,  2.1419, -2.0393,  3.1355, -1.4962,  7.0710],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9976, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.77516174316406\n","Epoch 13, Batch 232 - Training loss: 112.77516174316406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.0936,  -1.5265,   2.8445,  -0.0536,  -0.0161,   1.2860,  -2.6377,\n","          2.6456, -11.6999,   3.5775,   0.1496,   8.0172,  -4.0331,   0.3690,\n","         -1.7560,   4.1504], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.13082885742188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.0936,  -1.5265,   2.8445,  -0.0536,  -0.0161,   1.2860,  -2.6377,\n","          2.6456, -11.6999,   3.5775,   0.1496,   8.0172,  -4.0331,   0.3690,\n","         -1.7560,   4.1504], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.52703857421875\n","Epoch 13, Batch 233 - Training loss: 114.52703857421875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.1962, -1.1119, -1.5750,  3.4476, -0.5855, -1.1091, -2.6029,  4.6845,\n","        -6.7363,  6.5701,  4.9248,  8.6837, -1.0042,  4.1262, -0.3932,  4.8890],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.75808715820312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.1962, -1.1119, -1.5750,  3.4476, -0.5855, -1.1091, -2.6029,  4.6845,\n","        -6.7363,  6.5701,  4.9248,  8.6837, -1.0042,  4.1262, -0.3932,  4.8890],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.99041748046875\n","Epoch 13, Batch 234 - Training loss: 112.99041748046875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.5756,  -1.6134,  -0.6712,   3.6872,   1.9535,  -0.6366,  -4.6011,\n","         -0.0665, -14.2823,   3.4432,   7.7434,   7.1639,  -0.4058,   6.2165,\n","         -4.1752,   9.1216], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000, -1.0000, -0.9987],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.94452667236328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.5756,  -1.6134,  -0.6712,   3.6872,   1.9535,  -0.6366,  -4.6011,\n","         -0.0665, -14.2823,   3.4432,   7.7434,   7.1639,  -0.4058,   6.2165,\n","         -4.1752,   9.1216], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9990, -1.0000, -1.0000, -1.0000, -1.0000, -0.9987],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.80648803710938\n","Epoch 13, Batch 235 - Training loss: 115.80648803710938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.6481,  0.2716,  3.3400,  3.2025,  2.4267, -0.1378,  1.9863,  3.5459,\n","        -9.1359,  5.4859,  7.8621,  5.2704, -3.1698,  0.4760, -1.4401,  6.2363],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.33419036865234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.6481,  0.2716,  3.3400,  3.2025,  2.4267, -0.1378,  1.9863,  3.5459,\n","        -9.1359,  5.4859,  7.8621,  5.2704, -3.1698,  0.4760, -1.4401,  6.2363],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.26039123535156\n","Epoch 13, Batch 236 - Training loss: 111.26039123535156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.6085,  0.9420,  2.3045,  1.3100,  5.6245, -3.4691,  0.4423, -0.4153,\n","        -9.4939,  6.5172,  6.2732, -1.4794, -2.0136,  7.5116, -2.3762,  7.6856],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9977, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.13832092285156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.6085,  0.9420,  2.3045,  1.3100,  5.6245, -3.4691,  0.4423, -0.4153,\n","        -9.4939,  6.5172,  6.2732, -1.4794, -2.0136,  7.5116, -2.3762,  7.6856],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9977, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.50497436523438\n","Epoch 13, Batch 237 - Training loss: 115.50497436523438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6552,  -1.5051,  -1.6970,   7.0943,  -2.2714,  -2.4521,  -2.1806,\n","          6.6018, -14.4084,   4.1022,   5.2916,   0.0811,   1.4122,   3.9901,\n","          0.7048,   9.1878], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.11669921875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.6552,  -1.5051,  -1.6970,   7.0943,  -2.2714,  -2.4521,  -2.1806,\n","          6.6018, -14.4084,   4.1022,   5.2916,   0.0811,   1.4122,   3.9901,\n","          0.7048,   9.1878], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9993, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.43412780761719\n","Epoch 13, Batch 238 - Training loss: 112.43412780761719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.7180,   2.0921,  -2.1825,   6.4856,   5.2532,  -0.9421,  -2.1960,\n","         -1.2430, -11.8337,   2.8632,   1.9537,   2.6285,  -1.3355,   1.8585,\n","         -3.1379,   3.0623], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.10688018798828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.7180,   2.0921,  -2.1825,   6.4856,   5.2532,  -0.9421,  -2.1960,\n","         -1.2430, -11.8337,   2.8632,   1.9537,   2.6285,  -1.3355,   1.8585,\n","         -3.1379,   3.0623], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.44535827636719\n","Epoch 13, Batch 239 - Training loss: 116.44535827636719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.7580, -1.3426,  2.4132,  8.7349,  5.0369, -3.4321, -2.2541,  1.2429,\n","        -6.7315,  5.2568,  8.1720,  3.4993, -7.0020,  1.7603, -2.6684,  5.7253],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.43904876708984\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.7580, -1.3426,  2.4132,  8.7349,  5.0369, -3.4321, -2.2541,  1.2429,\n","        -6.7315,  5.2568,  8.1720,  3.4993, -7.0020,  1.7603, -2.6684,  5.7253],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.5604476928711\n","Epoch 13, Batch 240 - Training loss: 111.5604476928711\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.1148, -1.6068,  0.2565, -0.2462,  4.0037,  1.3368, -3.2953,  4.7831,\n","        -9.1224,  4.9833,  0.2439,  5.6517, -1.5296,  2.7370,  2.4483,  5.2491],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.68221282958984\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.1148, -1.6068,  0.2565, -0.2462,  4.0037,  1.3368, -3.2953,  4.7831,\n","        -9.1224,  4.9833,  0.2439,  5.6517, -1.5296,  2.7370,  2.4483,  5.2491],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.89366912841797\n","Epoch 13, Batch 241 - Training loss: 115.89366912841797\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.8192,  5.1821,  2.2425,  3.4160,  4.0148, -0.1075,  1.1630,  3.4298,\n","        -9.8024,  5.7275,  5.0798,  3.0315, -1.4226,  1.7959,  2.0930,  8.0735],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.77824401855469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.8192,  5.1821,  2.2425,  3.4160,  4.0148, -0.1075,  1.1630,  3.4298,\n","        -9.8024,  5.7275,  5.0798,  3.0315, -1.4226,  1.7959,  2.0930,  8.0735],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.5992431640625\n","Epoch 13, Batch 242 - Training loss: 118.5992431640625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.9048,   1.1238,   5.5165,   5.6398,   4.9498,  -2.4278,  -1.4690,\n","          4.2178, -11.5441,   3.4429,  10.2729,   5.7050,  -3.4571,  11.2936,\n","         -1.4959,   6.8879], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.24430847167969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -1.9048,   1.1238,   5.5165,   5.6398,   4.9498,  -2.4278,  -1.4690,\n","          4.2178, -11.5441,   3.4429,  10.2729,   5.7050,  -3.4571,  11.2936,\n","         -1.4959,   6.8879], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.34793090820312\n","Epoch 13, Batch 243 - Training loss: 117.34793090820312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.9311,   2.9235,   2.1820,   3.8769,  -0.8956,   0.3321,  -4.5909,\n","          3.1919, -13.6468,   4.7188,   5.6576,  -0.4340,  -4.1681,   5.1751,\n","         -0.8092,   6.6974], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.32905578613281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.9311,   2.9235,   2.1820,   3.8769,  -0.8956,   0.3321,  -4.5909,\n","          3.1919, -13.6468,   4.7188,   5.6576,  -0.4340,  -4.1681,   5.1751,\n","         -0.8092,   6.6974], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.36491394042969\n","Epoch 13, Batch 244 - Training loss: 112.36491394042969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.8630,  1.9663, -3.7052,  3.3369,  5.3167,  2.8871,  2.8675,  5.0226,\n","        -7.3363,  1.7675,  5.3159,  6.3903, -0.4467,  3.7627, -0.3591,  5.3367],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.82711791992188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.8630,  1.9663, -3.7052,  3.3369,  5.3167,  2.8871,  2.8675,  5.0226,\n","        -7.3363,  1.7675,  5.3159,  6.3903, -0.4467,  3.7627, -0.3591,  5.3367],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.3313980102539\n","Epoch 13, Batch 245 - Training loss: 117.3313980102539\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1138,   2.3052,   0.1504,   3.0617,   1.7651,  -1.4215,  -0.9849,\n","          3.5137, -13.8382,   0.9009,   1.0856,   3.4229,  -3.1820,   5.2142,\n","         -3.2204,   7.7953], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9991, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.69246673583984\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1138,   2.3052,   0.1504,   3.0617,   1.7651,  -1.4215,  -0.9849,\n","          3.5137, -13.8382,   0.9009,   1.0856,   3.4229,  -3.1820,   5.2142,\n","         -3.2204,   7.7953], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9991, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.66503143310547\n","Epoch 13, Batch 246 - Training loss: 117.66503143310547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.0695, -0.6332,  0.9226, -2.1286,  2.2638,  3.2301,  1.9616,  0.8809,\n","        -5.1393,  6.1407,  4.6136, -2.8841, -0.1192, -1.5283, -0.6035,  7.2283],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.60552978515625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-1.0695, -0.6332,  0.9226, -2.1286,  2.2638,  3.2301,  1.9616,  0.8809,\n","        -5.1393,  6.1407,  4.6136, -2.8841, -0.1192, -1.5283, -0.6035,  7.2283],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.5253677368164\n","Epoch 13, Batch 247 - Training loss: 109.5253677368164\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.7148,   0.3686,   1.8398,   0.1176,   2.7273,   0.1667,  -0.0542,\n","         -0.0265, -10.6901,   1.2490,   3.5612,   2.9878,  -2.3048,   4.5346,\n","         -1.2061,   4.1576], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.90895080566406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.7148,   0.3686,   1.8398,   0.1176,   2.7273,   0.1667,  -0.0542,\n","         -0.0265, -10.6901,   1.2490,   3.5612,   2.9878,  -2.3048,   4.5346,\n","         -1.2061,   4.1576], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.65870666503906\n","Epoch 13, Batch 248 - Training loss: 116.65870666503906\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.6421,  2.9639,  2.2520,  0.1196,  2.9536, -1.3986, -1.5960,  5.1473,\n","        -9.9505,  8.2422,  3.8437,  5.6362,  1.3498,  4.6961, -2.3901,  8.3234],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.69486999511719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.6421,  2.9639,  2.2520,  0.1196,  2.9536, -1.3986, -1.5960,  5.1473,\n","        -9.9505,  8.2422,  3.8437,  5.6362,  1.3498,  4.6961, -2.3901,  8.3234],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.28279113769531\n","Epoch 13, Batch 249 - Training loss: 116.28279113769531\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.1745, -1.2961,  1.0645,  5.1063,  3.0612, -0.6080, -0.2692,  3.0655,\n","        -9.7103,  5.1130,  3.7349,  3.6334, -0.0777,  7.4943, -4.3351,  7.7235],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.60660552978516\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.1745, -1.2961,  1.0645,  5.1063,  3.0612, -0.6080, -0.2692,  3.0655,\n","        -9.7103,  5.1130,  3.7349,  3.6334, -0.0777,  7.4943, -4.3351,  7.7235],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.6739273071289\n","Epoch 13, Batch 250 - Training loss: 112.6739273071289\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.2822,  -1.3378,   4.6170,  -1.3322,   2.4782,   1.2746,  -2.2855,\n","         -1.7698, -10.9425,  -2.1370,  11.1097,   2.9399,   0.7706,  -0.3100,\n","         -1.8157,  -0.3900], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.97509765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.2822,  -1.3378,   4.6170,  -1.3322,   2.4782,   1.2746,  -2.2855,\n","         -1.7698, -10.9425,  -2.1370,  11.1097,   2.9399,   0.7706,  -0.3100,\n","         -1.8157,  -0.3900], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.06791687011719\n","Epoch 13, Batch 251 - Training loss: 111.06791687011719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7382,  -3.5447,  -1.9581,  -1.3764,   3.8196,   2.7105,  -0.8297,\n","          2.0737, -12.9195,   2.2044,  -0.1541,   2.6767,  -1.0957,   1.3881,\n","         -3.9438,   7.8424], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.84080505371094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7382,  -3.5447,  -1.9581,  -1.3764,   3.8196,   2.7105,  -0.8297,\n","          2.0737, -12.9195,   2.2044,  -0.1541,   2.6767,  -1.0957,   1.3881,\n","         -3.9438,   7.8424], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.12232208251953\n","Epoch 13, Batch 252 - Training loss: 114.12232208251953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.7939, -4.2284,  1.2827,  4.5886,  5.9605,  0.1809, -0.2841,  4.4739,\n","        -8.0218,  1.5948,  1.9413,  4.6548, -1.6575,  3.4748, -1.4501,  8.6395],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.59465026855469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.7939, -4.2284,  1.2827,  4.5886,  5.9605,  0.1809, -0.2841,  4.4739,\n","        -8.0218,  1.5948,  1.9413,  4.6548, -1.6575,  3.4748, -1.4501,  8.6395],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9993, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.93283081054688\n","Epoch 13, Batch 253 - Training loss: 117.93283081054688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -0.9906,  -0.4781,  -0.1071,   2.7302,   3.4739,  -3.6055,  -0.2430,\n","          5.7586, -11.7839,   4.1290,   1.0605,   3.4615,   0.7763,   5.4180,\n","          2.2590,   5.4884], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.82557678222656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -0.9906,  -0.4781,  -0.1071,   2.7302,   3.4739,  -3.6055,  -0.2430,\n","          5.7586, -11.7839,   4.1290,   1.0605,   3.4615,   0.7763,   5.4180,\n","          2.2590,   5.4884], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.85488891601562\n","Epoch 13, Batch 254 - Training loss: 113.85488891601562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.9794, -2.7998,  0.3615,  0.5908,  1.8668,  6.2276, -2.6852,  3.7158,\n","        -8.2214, -0.1863,  8.2845,  3.3010,  2.7794,  1.4209,  0.8619,  9.9160],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.48643493652344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.9794, -2.7998,  0.3615,  0.5908,  1.8668,  6.2276, -2.6852,  3.7158,\n","        -8.2214, -0.1863,  8.2845,  3.3010,  2.7794,  1.4209,  0.8619,  9.9160],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.75413513183594\n","Epoch 13, Batch 255 - Training loss: 112.75413513183594\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -0.9794,   4.5959,   1.5691,   4.0032,   0.1562,  -0.7841,   1.8790,\n","          3.0025, -15.3070,   7.7206,  -0.4223,  -0.9534,   4.3961,  -0.4362,\n","         -2.1280,   6.7225], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 107.94327545166016\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -0.9794,   4.5959,   1.5691,   4.0032,   0.1562,  -0.7841,   1.8790,\n","          3.0025, -15.3070,   7.7206,  -0.4223,  -0.9534,   4.3961,  -0.4362,\n","         -2.1280,   6.7225], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.10363006591797\n","Epoch 13, Batch 256 - Training loss: 108.10363006591797\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.8486,  -2.1314,  -0.3634,   0.2901,   7.9789,  -0.2706,  -0.3624,\n","          5.5108, -12.6463,   0.5445,  -0.4716,   0.7646,  -2.5450,   7.3030,\n","         -0.9247,   4.3720], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.98738861083984\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.8486,  -2.1314,  -0.3634,   0.2901,   7.9789,  -0.2706,  -0.3624,\n","          5.5108, -12.6463,   0.5445,  -0.4716,   0.7646,  -2.5450,   7.3030,\n","         -0.9247,   4.3720], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.85975646972656\n","Epoch 13, Batch 257 - Training loss: 118.85975646972656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.2765,   2.5278,   3.1260,   4.6894,   3.3112,  -2.6797,  -3.5160,\n","          1.4396, -14.6680,   3.6111,   0.3010,   4.5023,   0.0568,   0.1753,\n","          0.8104,   5.2263], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.36822509765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.2765,   2.5278,   3.1260,   4.6894,   3.3112,  -2.6797,  -3.5160,\n","          1.4396, -14.6680,   3.6111,   0.3010,   4.5023,   0.0568,   0.1753,\n","          0.8104,   5.2263], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.3419189453125\n","Epoch 13, Batch 258 - Training loss: 112.3419189453125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.6398,  3.9678, -1.0549,  3.8569,  4.5104, -0.1215,  1.0977,  1.9382,\n","        -7.8150,  4.7094,  5.5849,  6.0056, -0.9085,  4.6932, -1.1953, 10.0154],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.90728759765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.6398,  3.9678, -1.0549,  3.8569,  4.5104, -0.1215,  1.0977,  1.9382,\n","        -7.8150,  4.7094,  5.5849,  6.0056, -0.9085,  4.6932, -1.1953, 10.0154],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.97138214111328\n","Epoch 13, Batch 259 - Training loss: 118.97138214111328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1524, -0.3503,  3.2074, -1.4305,  4.1038, -1.5825,  0.3897,  1.4947,\n","        -8.7675,  2.8561,  4.3152,  0.9299,  2.0576,  2.8514,  1.9035,  7.1970],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.4349365234375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.1524, -0.3503,  3.2074, -1.4305,  4.1038, -1.5825,  0.3897,  1.4947,\n","        -8.7675,  2.8561,  4.3152,  0.9299,  2.0576,  2.8514,  1.9035,  7.1970],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.3062515258789\n","Epoch 13, Batch 260 - Training loss: 117.3062515258789\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.3300,   1.2361,   2.3401,   5.9372,   4.2965,  -1.1368,   1.5349,\n","          2.9140, -10.2338,   1.6002,   5.2238,   1.8810,  -5.0221,   3.0257,\n","         -2.9913,   4.0989], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.62305450439453\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.3300,   1.2361,   2.3401,   5.9372,   4.2965,  -1.1368,   1.5349,\n","          2.9140, -10.2338,   1.6002,   5.2238,   1.8810,  -5.0221,   3.0257,\n","         -2.9913,   4.0989], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.84255981445312\n","Epoch 13, Batch 261 - Training loss: 116.84255981445312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.8727,   3.7698,  -2.1336,   1.7042,   2.3833,   2.7685,  -1.7969,\n","         -0.8341, -12.5238,  -0.1256,   4.2877,   3.1288,  -2.5220,   4.0786,\n","          0.7678,   5.3651], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.29859924316406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.8727,   3.7698,  -2.1336,   1.7042,   2.3833,   2.7685,  -1.7969,\n","         -0.8341, -12.5238,  -0.1256,   4.2877,   3.1288,  -2.5220,   4.0786,\n","          0.7678,   5.3651], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.00602722167969\n","Epoch 13, Batch 262 - Training loss: 116.00602722167969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4425,   1.5911,   7.9377,  -5.1809,   1.6783,   5.8029,   0.9179,\n","          0.8407, -13.7021,   0.0630,   1.1510,   3.0992,  -4.3731,  -0.9507,\n","          0.5730,   3.7291], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.597412109375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4425,   1.5911,   7.9377,  -5.1809,   1.6783,   5.8029,   0.9179,\n","          0.8407, -13.7021,   0.0630,   1.1510,   3.0992,  -4.3731,  -0.9507,\n","          0.5730,   3.7291], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.01390838623047\n","Epoch 13, Batch 263 - Training loss: 113.01390838623047\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.8203,  -2.5043,  -1.6374,  -1.4202,   1.4327,  -1.5996,  -1.2407,\n","          0.4754, -13.1179,  -1.1347,   5.4133,   3.4684,  -2.9570,   4.2090,\n","          2.4551,   5.7344], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.8757553100586\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.8203,  -2.5043,  -1.6374,  -1.4202,   1.4327,  -1.5996,  -1.2407,\n","          0.4754, -13.1179,  -1.1347,   5.4133,   3.4684,  -2.9570,   4.2090,\n","          2.4551,   5.7344], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.23359680175781\n","Epoch 13, Batch 264 - Training loss: 116.23359680175781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.4157e+00, -2.3265e+00,  4.8227e+00, -4.5776e-03,  2.5010e+00,\n","        -1.5029e+00,  3.2451e-01,  8.9293e-01, -1.5358e+01,  1.7380e+00,\n","         5.5780e+00,  3.8574e+00, -4.4096e+00,  1.7821e+00, -5.6862e-01,\n","         3.9594e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.12612915039062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.4157e+00, -2.3265e+00,  4.8227e+00, -4.5776e-03,  2.5010e+00,\n","        -1.5029e+00,  3.2451e-01,  8.9293e-01, -1.5358e+01,  1.7380e+00,\n","         5.5780e+00,  3.8574e+00, -4.4096e+00,  1.7821e+00, -5.6862e-01,\n","         3.9594e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.00064849853516\n","Epoch 13, Batch 265 - Training loss: 117.00064849853516\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.7418,  0.4336,  2.2583,  3.2731,  4.1346,  3.3247, -0.1294, -0.2649,\n","        -9.7116,  4.7256,  6.1033, -1.2914, -0.5994, -0.0847, -5.2643,  6.8811],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.32073211669922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.7418,  0.4336,  2.2583,  3.2731,  4.1346,  3.3247, -0.1294, -0.2649,\n","        -9.7116,  4.7256,  6.1033, -1.2914, -0.5994, -0.0847, -5.2643,  6.8811],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.57249450683594\n","Epoch 13, Batch 266 - Training loss: 117.57249450683594\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.8311, -0.6818,  2.5786,  3.9997,  3.7672,  1.1822, -1.0235,  3.3195,\n","        -9.6651,  2.1967,  7.9570,  6.6852,  1.4840,  7.0217, -2.0815,  5.8560],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.78495025634766\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.8311, -0.6818,  2.5786,  3.9997,  3.7672,  1.1822, -1.0235,  3.3195,\n","        -9.6651,  2.1967,  7.9570,  6.6852,  1.4840,  7.0217, -2.0815,  5.8560],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.07740020751953\n","Epoch 13, Batch 267 - Training loss: 109.07740020751953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7698,   0.6479,   2.7838,  -0.0178,   3.5394,   1.2635,   3.4943,\n","          1.9159, -10.1106,   2.3697,   3.1931,   2.9847,  -2.1276,   2.0923,\n","          1.8081,   7.8533], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.93866729736328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.7698,   0.6479,   2.7838,  -0.0178,   3.5394,   1.2635,   3.4943,\n","          1.9159, -10.1106,   2.3697,   3.1931,   2.9847,  -2.1276,   2.0923,\n","          1.8081,   7.8533], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.606201171875\n","Epoch 13, Batch 268 - Training loss: 120.606201171875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.6076,  -2.6388,  -0.3031,   0.6920,   5.4392,  -1.7569,  -0.6032,\n","          3.5036, -13.2843,   2.1215,   6.6705,   2.1369,  -2.3786,   1.5784,\n","          2.6449,  11.8620], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.39366149902344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.6076,  -2.6388,  -0.3031,   0.6920,   5.4392,  -1.7569,  -0.6032,\n","          3.5036, -13.2843,   2.1215,   6.6705,   2.1369,  -2.3786,   1.5784,\n","          2.6449,  11.8620], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.9803466796875\n","Epoch 13, Batch 269 - Training loss: 115.9803466796875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.0722,   1.5509,  -0.4407,   0.4236,   3.1629,  -1.0333,  -2.7769,\n","          8.1312, -13.0349,   4.5349,   4.5924,   0.2810,  -2.7874,   5.4444,\n","          0.7144,   9.4725], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.62045288085938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.0722,   1.5509,  -0.4407,   0.4236,   3.1629,  -1.0333,  -2.7769,\n","          8.1312, -13.0349,   4.5349,   4.5924,   0.2810,  -2.7874,   5.4444,\n","          0.7144,   9.4725], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.62603759765625\n","Epoch 13, Batch 270 - Training loss: 113.62603759765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.2751e+00, -2.5303e+00,  4.1588e+00,  1.4083e+00,  3.5126e+00,\n","         4.4870e-01, -1.8721e-03,  7.6325e-01, -1.2559e+01, -7.3575e-01,\n","         2.3423e+00,  7.5139e+00, -5.5806e+00,  3.2257e+00, -1.2114e+00,\n","         7.4085e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.79594421386719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.2751e+00, -2.5303e+00,  4.1588e+00,  1.4083e+00,  3.5126e+00,\n","         4.4870e-01, -1.8721e-03,  7.6325e-01, -1.2559e+01, -7.3575e-01,\n","         2.3423e+00,  7.5139e+00, -5.5806e+00,  3.2257e+00, -1.2114e+00,\n","         7.4085e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.53175354003906\n","Epoch 13, Batch 271 - Training loss: 113.53175354003906\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.5562,  1.4999, -0.0653,  3.0696,  5.2838,  2.1692, -2.4235,  1.1647,\n","        -9.4836,  9.2641,  4.4043, -0.2161,  4.1214,  0.4550, -3.2866, 11.7244],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.90174102783203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.5562,  1.4999, -0.0653,  3.0696,  5.2838,  2.1692, -2.4235,  1.1647,\n","        -9.4836,  9.2641,  4.4043, -0.2161,  4.1214,  0.4550, -3.2866, 11.7244],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.49790954589844\n","Epoch 13, Batch 272 - Training loss: 114.49790954589844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.1943,  -1.3206,   2.1734,   2.7014,   5.0577,  -3.2252,  -1.1993,\n","          3.3953, -12.4767,   2.1073,  -0.0819,   3.6401,  -4.7617,   1.3411,\n","         -1.3843,   8.0543], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.15719604492188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.1943,  -1.3206,   2.1734,   2.7014,   5.0577,  -3.2252,  -1.1993,\n","          3.3953, -12.4767,   2.1073,  -0.0819,   3.6401,  -4.7617,   1.3411,\n","         -1.3843,   8.0543], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.24161529541016\n","Epoch 13, Batch 273 - Training loss: 115.24161529541016\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.9640,  -1.1052,   5.6999,   0.9975,   6.6046,   0.1838,  -1.9494,\n","          1.7486, -13.3133,   1.4148,   5.1944,   3.4874,  -0.3926,   5.9312,\n","          0.5716,   6.8628], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 123.37205505371094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.9640,  -1.1052,   5.6999,   0.9975,   6.6046,   0.1838,  -1.9494,\n","          1.7486, -13.3133,   1.4148,   5.1944,   3.4874,  -0.3926,   5.9312,\n","          0.5716,   6.8628], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 122.88216400146484\n","Epoch 13, Batch 274 - Training loss: 122.88216400146484\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.9476,  -0.4523,   5.0172,   3.7665,   5.9683,   1.8057,  -0.5657,\n","          3.5405, -13.6763,   1.7877,   3.2358,   4.2847,  -1.7272,   3.0141,\n","         -1.6467,   6.5322], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000, -0.9971, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.85693359375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.9476,  -0.4523,   5.0172,   3.7665,   5.9683,   1.8057,  -0.5657,\n","          3.5405, -13.6763,   1.7877,   3.2358,   4.2847,  -1.7272,   3.0141,\n","         -1.6467,   6.5322], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9997, -1.0000, -0.9971, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.1761474609375\n","Epoch 13, Batch 275 - Training loss: 115.1761474609375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.3825,  -0.6856,  -0.4542,   0.9459,   2.9320,  -2.2764,   3.3932,\n","          2.6381, -10.6134,   4.0844,   7.1141,   2.9066,  -1.9560,   3.5432,\n","         -4.7999,   6.4446], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.25736999511719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.3825,  -0.6856,  -0.4542,   0.9459,   2.9320,  -2.2764,   3.3932,\n","          2.6381, -10.6134,   4.0844,   7.1141,   2.9066,  -1.9560,   3.5432,\n","         -4.7999,   6.4446], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.23456573486328\n","Epoch 13, Batch 276 - Training loss: 116.23456573486328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.1376,  0.9838, -1.1376,  1.1314,  0.5670, -1.4065, -2.4012, -2.4548,\n","        -7.7432, -0.6723,  2.1389,  3.9918, -5.5354,  1.4877, -6.1387,  8.7361],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 121.58414459228516\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.1376,  0.9838, -1.1376,  1.1314,  0.5670, -1.4065, -2.4012, -2.4548,\n","        -7.7432, -0.6723,  2.1389,  3.9918, -5.5354,  1.4877, -6.1387,  8.7361],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 121.2404556274414\n","Epoch 13, Batch 277 - Training loss: 121.2404556274414\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.5380,  0.9969,  0.9468,  4.1767,  5.4249, -1.4560,  0.7584,  2.7055,\n","        -8.8679, -0.2899,  5.5266,  4.3757,  0.5979,  0.3069, -1.4782,  4.1942],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.4913558959961\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.5380,  0.9969,  0.9468,  4.1767,  5.4249, -1.4560,  0.7584,  2.7055,\n","        -8.8679, -0.2899,  5.5266,  4.3757,  0.5979,  0.3069, -1.4782,  4.1942],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.68232727050781\n","Epoch 13, Batch 278 - Training loss: 115.68232727050781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.7691,  2.2913, -1.4596, -0.5427,  4.2684,  1.9290, -0.0173,  1.6245,\n","        -8.3507, -0.9859,  7.2815,  5.6512,  2.6628,  3.2806,  3.3788,  6.5920],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9945, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.98383331298828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.7691,  2.2913, -1.4596, -0.5427,  4.2684,  1.9290, -0.0173,  1.6245,\n","        -8.3507, -0.9859,  7.2815,  5.6512,  2.6628,  3.2806,  3.3788,  6.5920],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9945, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.75780487060547\n","Epoch 13, Batch 279 - Training loss: 114.75780487060547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.6393,  -0.5985,   2.7265,   3.8038,   2.0499,  -0.4534,  -2.0153,\n","          1.4448, -10.2474,   2.2995,   5.2319,   5.3362,  -0.4318,   5.1767,\n","         -3.3147,   6.3012], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.41756439208984\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.6393,  -0.5985,   2.7265,   3.8038,   2.0499,  -0.4534,  -2.0153,\n","          1.4448, -10.2474,   2.2995,   5.2319,   5.3362,  -0.4318,   5.1767,\n","         -3.3147,   6.3012], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.9796371459961\n","Epoch 13, Batch 280 - Training loss: 113.9796371459961\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.4393,   0.0829,   2.1745,   0.7830,   6.3543,   2.1217,  -1.9224,\n","          0.8978, -12.2010,  -0.9320,   3.0428,   1.9891,  -3.5515,   2.6527,\n","         -1.0651,   7.1087], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.99849700927734\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -9.4393,   0.0829,   2.1745,   0.7830,   6.3543,   2.1217,  -1.9224,\n","          0.8978, -12.2010,  -0.9320,   3.0428,   1.9891,  -3.5515,   2.6527,\n","         -1.0651,   7.1087], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.43923950195312\n","Epoch 13, Batch 281 - Training loss: 119.43923950195312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.6968,  -2.9075,   0.9137,   4.0018,   5.9829,   0.2329,  -2.0775,\n","          2.8565, -10.9475,   5.0153,   1.9959,   3.3605,  -3.6483,   0.3838,\n","         -1.2677,  11.1743], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.88761901855469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.6968,  -2.9075,   0.9137,   4.0018,   5.9829,   0.2329,  -2.0775,\n","          2.8565, -10.9475,   5.0153,   1.9959,   3.3605,  -3.6483,   0.3838,\n","         -1.2677,  11.1743], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.46502685546875\n","Epoch 13, Batch 282 - Training loss: 116.46502685546875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.9804,   0.8264,  -0.2116,   4.0948,   6.5896,  -1.5766,  -1.4864,\n","          2.4164, -11.7040,   3.9566,   6.1182,   5.9033,  -3.7650,   1.8084,\n","         -2.3541,   4.8310], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 108.91885375976562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.9804,   0.8264,  -0.2116,   4.0948,   6.5896,  -1.5766,  -1.4864,\n","          2.4164, -11.7040,   3.9566,   6.1182,   5.9033,  -3.7650,   1.8084,\n","         -2.3541,   4.8310], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.45979309082031\n","Epoch 13, Batch 283 - Training loss: 109.45979309082031\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.8738,  -2.0219,   2.0517,   1.2742,   6.8912,  -2.0360,  -0.8265,\n","          6.2966, -15.1333,   5.2963,   2.4193,   3.7213,   1.4054,   4.6482,\n","          3.6733,   8.2777], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.35794067382812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.8738,  -2.0219,   2.0517,   1.2742,   6.8912,  -2.0360,  -0.8265,\n","          6.2966, -15.1333,   5.2963,   2.4193,   3.7213,   1.4054,   4.6482,\n","          3.6733,   8.2777], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.60816955566406\n","Epoch 13, Batch 284 - Training loss: 112.60816955566406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.3431, -3.2031,  0.5845,  1.3210,  2.0784, -2.5913,  2.1528, -3.9626,\n","        -7.5543, -2.2158,  2.6633,  6.1844, -2.9818,  0.3612, -0.9040,  6.6406],\n","       grad_fn=<SumBackward1>), log_var: tensor([-0.9975, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.32881927490234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.3431, -3.2031,  0.5845,  1.3210,  2.0784, -2.5913,  2.1528, -3.9626,\n","        -7.5543, -2.2158,  2.6633,  6.1844, -2.9818,  0.3612, -0.9040,  6.6406],\n","       grad_fn=<SumBackward1>), log_var: tensor([-0.9975, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.57959747314453\n","Epoch 13, Batch 285 - Training loss: 113.57959747314453\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.7439,  5.5155,  3.3280,  2.0316,  2.6006, -1.2859,  0.4505,  1.3285,\n","        -9.7710,  1.0049,  8.5412,  4.1271,  1.2433, -0.8105,  1.5881,  7.8348],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.06085968017578\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.7439,  5.5155,  3.3280,  2.0316,  2.6006, -1.2859,  0.4505,  1.3285,\n","        -9.7710,  1.0049,  8.5412,  4.1271,  1.2433, -0.8105,  1.5881,  7.8348],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.1749496459961\n","Epoch 13, Batch 286 - Training loss: 110.1749496459961\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.0642,   1.5229,   1.0083,   7.2756,  -0.8226,   2.2996,  -2.3706,\n","          5.3934, -13.8789,   8.5836,   3.3450,   3.3397,  -2.2326,   6.2961,\n","         -2.4811,  10.8705], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9986, -1.0000,\n","        -1.0000, -0.9980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.06489562988281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.0642,   1.5229,   1.0083,   7.2756,  -0.8226,   2.2996,  -2.3706,\n","          5.3934, -13.8789,   8.5836,   3.3450,   3.3397,  -2.2326,   6.2961,\n","         -2.4811,  10.8705], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9986, -1.0000,\n","        -1.0000, -0.9980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.90449523925781\n","Epoch 13, Batch 287 - Training loss: 115.90449523925781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.1999,   0.2755,  -3.8725,   4.9520,   3.4430,  -1.5947,  -1.0932,\n","         -1.1568, -13.5564,   1.0059,   2.9719,  -0.0503,  -4.2067,   3.1188,\n","         -4.1694,   5.8853], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9967, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.41817474365234\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.1999,   0.2755,  -3.8725,   4.9520,   3.4430,  -1.5947,  -1.0932,\n","         -1.1568, -13.5564,   1.0059,   2.9719,  -0.0503,  -4.2067,   3.1188,\n","         -4.1694,   5.8853], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9967, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.80630493164062\n","Epoch 13, Batch 288 - Training loss: 115.80630493164062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.4983,   1.6987,   2.8258,   5.6290,   0.8106,  -0.2041,   1.4952,\n","          6.4301, -10.0852,   6.7918,  -0.0357,  10.6646,  -0.1486,   4.7624,\n","          1.5157,  10.6575], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.42228698730469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.4983,   1.6987,   2.8258,   5.6290,   0.8106,  -0.2041,   1.4952,\n","          6.4301, -10.0852,   6.7918,  -0.0357,  10.6646,  -0.1486,   4.7624,\n","          1.5157,  10.6575], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.32673645019531\n","Epoch 13, Batch 289 - Training loss: 114.32673645019531\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.2047,   5.2385,   4.2643,   6.7077,   2.9880,  -2.6970,  -4.6176,\n","          4.5026, -11.3930,   4.4464,   5.7345,   5.7825,  -2.3934,  -1.0434,\n","         -1.9639,   6.9203], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9955, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.83184814453125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.2047,   5.2385,   4.2643,   6.7077,   2.9880,  -2.6970,  -4.6176,\n","          4.5026, -11.3930,   4.4464,   5.7345,   5.7825,  -2.3934,  -1.0434,\n","         -1.9639,   6.9203], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9955, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.25674438476562\n","Epoch 13, Batch 290 - Training loss: 116.25674438476562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.6385, -0.2153,  1.0689, -0.2413,  3.8593, -2.0044, -1.4518, -1.3489,\n","        -7.7322,  8.3712,  4.4035,  0.8589,  1.7025, -0.2213, -2.9448,  7.3779],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9997, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.4309310913086\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.6385, -0.2153,  1.0689, -0.2413,  3.8593, -2.0044, -1.4518, -1.3489,\n","        -7.7322,  8.3712,  4.4035,  0.8589,  1.7025, -0.2213, -2.9448,  7.3779],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9997, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.35543823242188\n","Epoch 13, Batch 291 - Training loss: 113.35543823242188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.3687,   0.0311,   2.6790,   3.3970,   1.0273,   3.1417,  -1.5163,\n","         -1.3692, -12.4096,   3.1797,   5.0199,   6.1552,  -1.7844,   2.1556,\n","         -8.0745,   4.5281], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.6803970336914\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.3687,   0.0311,   2.6790,   3.3970,   1.0273,   3.1417,  -1.5163,\n","         -1.3692, -12.4096,   3.1797,   5.0199,   6.1552,  -1.7844,   2.1556,\n","         -8.0745,   4.5281], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.2140884399414\n","Epoch 13, Batch 292 - Training loss: 115.2140884399414\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1583,   1.0236,   4.6883,  -0.7738,   5.6956,  -0.1996,   0.8114,\n","          1.9929, -12.4220,   1.0346,   5.3319,  -1.8651,   1.1232,   2.6421,\n","          0.0279,   2.2560], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.74191284179688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.1583,   1.0236,   4.6883,  -0.7738,   5.6956,  -0.1996,   0.8114,\n","          1.9929, -12.4220,   1.0346,   5.3319,  -1.8651,   1.1232,   2.6421,\n","          0.0279,   2.2560], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.90541076660156\n","Epoch 13, Batch 293 - Training loss: 112.90541076660156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.8992,  1.9028,  4.5821, -1.1389,  3.5576,  3.3667, -2.7808,  5.1753,\n","        -9.2600,  7.1522,  8.6186,  3.1764, -2.9855,  3.3105, -2.3890,  7.9872],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9991, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9968, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.03402709960938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-2.8992,  1.9028,  4.5821, -1.1389,  3.5576,  3.3667, -2.7808,  5.1753,\n","        -9.2600,  7.1522,  8.6186,  3.1764, -2.9855,  3.3105, -2.3890,  7.9872],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -0.9991, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9968, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.65812683105469\n","Epoch 13, Batch 294 - Training loss: 112.65812683105469\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.6864,  -0.8728,  -2.9550,   1.0372,   2.6423,   1.0189,  -3.5968,\n","          4.5659, -10.5077,   3.8579,   7.1641,   0.7489,  -2.2938,  -0.9131,\n","          2.5184,   6.9820], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.28226470947266\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.6864,  -0.8728,  -2.9550,   1.0372,   2.6423,   1.0189,  -3.5968,\n","          4.5659, -10.5077,   3.8579,   7.1641,   0.7489,  -2.2938,  -0.9131,\n","          2.5184,   6.9820], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.99362182617188\n","Epoch 13, Batch 295 - Training loss: 113.99362182617188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.2167e+00, -7.6809e-03,  8.2890e-02,  6.1423e+00,  4.2935e+00,\n","        -4.7427e+00,  1.2124e+00,  4.4126e+00, -6.9020e+00,  1.8004e+00,\n","         7.9731e+00,  2.8115e+00,  7.3495e-01, -1.4293e+00, -4.1641e+00,\n","         5.8952e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.19434356689453\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.2167e+00, -7.6809e-03,  8.2890e-02,  6.1423e+00,  4.2935e+00,\n","        -4.7427e+00,  1.2124e+00,  4.4126e+00, -6.9020e+00,  1.8004e+00,\n","         7.9731e+00,  2.8115e+00,  7.3495e-01, -1.4293e+00, -4.1641e+00,\n","         5.8952e+00], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.5455093383789\n","Epoch 13, Batch 296 - Training loss: 115.5455093383789\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-13.5875,   3.7128,   1.1880,   1.1462,   6.3185,  -1.6059,   4.8003,\n","         -2.5007,  -8.0843,   2.8691,   2.2118,   1.2427,  -3.3682,  -1.8315,\n","         -1.9627,   9.9241], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9995, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.191650390625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-13.5875,   3.7128,   1.1880,   1.1462,   6.3185,  -1.6059,   4.8003,\n","         -2.5007,  -8.0843,   2.8691,   2.2118,   1.2427,  -3.3682,  -1.8315,\n","         -1.9627,   9.9241], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9995, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9995],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.06777954101562\n","Epoch 13, Batch 297 - Training loss: 118.06777954101562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4767,   1.0522,  -0.6589,   0.0593,   8.8294,   4.7383,  -2.6479,\n","          3.8287, -14.1450,   8.5571,   2.9096,   0.6436,   0.7461,   4.9384,\n","         -3.4893,   8.0823], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.70487976074219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.4767,   1.0522,  -0.6589,   0.0593,   8.8294,   4.7383,  -2.6479,\n","          3.8287, -14.1450,   8.5571,   2.9096,   0.6436,   0.7461,   4.9384,\n","         -3.4893,   8.0823], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.51811218261719\n","Epoch 13, Batch 298 - Training loss: 114.51811218261719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.3237,   1.4174,   0.5029,   0.1828,   4.6425,  -0.3860,  -1.8693,\n","          2.3960, -17.7215,   2.7600,   6.9306,   0.6588,  -3.8071,   1.4253,\n","          0.4771,   8.6753], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9993],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.19696044921875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.3237,   1.4174,   0.5029,   0.1828,   4.6425,  -0.3860,  -1.8693,\n","          2.3960, -17.7215,   2.7600,   6.9306,   0.6588,  -3.8071,   1.4253,\n","          0.4771,   8.6753], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9996, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9993],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.98210906982422\n","Epoch 13, Batch 299 - Training loss: 117.98210906982422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.8529,  1.4969,  2.9397,  2.0540,  7.7771, -1.1720,  0.9262,  3.1608,\n","        -4.8271,  5.1110,  4.3730,  3.0902, -1.4197,  2.3008, -0.0953, 10.5257],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9997, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -0.9992],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.63904571533203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.8529,  1.4969,  2.9397,  2.0540,  7.7771, -1.1720,  0.9262,  3.1608,\n","        -4.8271,  5.1110,  4.3730,  3.0902, -1.4197,  2.3008, -0.0953, 10.5257],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -0.9997, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -0.9992],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.63336181640625\n","Epoch 13, Batch 300 - Training loss: 110.63336181640625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.5885,   3.5122,   2.6970,   6.8218,   5.6771,  -3.7014,   1.1502,\n","          3.5125, -14.3614,   3.5382,   2.5171,  -2.2276,  -3.7929,   3.6551,\n","         -2.3973,   9.5681], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9982],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.88793182373047\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.5885,   3.5122,   2.6970,   6.8218,   5.6771,  -3.7014,   1.1502,\n","          3.5125, -14.3614,   3.5382,   2.5171,  -2.2276,  -3.7929,   3.6551,\n","         -2.3973,   9.5681], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9988, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9982],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.3905029296875\n","Epoch 13, Batch 301 - Training loss: 117.3905029296875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.3498,  5.0227, -2.3998,  1.2609,  4.9769, -3.7468, -0.5011,  1.3459,\n","        -8.5859,  1.8548,  7.0407,  4.3456, -4.1587,  2.1098, -1.5074,  6.6505],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9981, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.56869506835938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.3498,  5.0227, -2.3998,  1.2609,  4.9769, -3.7468, -0.5011,  1.3459,\n","        -8.5859,  1.8548,  7.0407,  4.3456, -4.1587,  2.1098, -1.5074,  6.6505],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9981, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.99479675292969\n","Epoch 13, Batch 302 - Training loss: 115.99479675292969\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.8244,   0.3154,   1.4946,   0.0188,   3.0039,  -3.2771,  -3.3138,\n","          0.8551, -13.6372,   3.5783,   1.8717,   3.9365,  -3.5581,  -0.3317,\n","          0.6184,   5.1693], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.43046569824219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.8244,   0.3154,   1.4946,   0.0188,   3.0039,  -3.2771,  -3.3138,\n","          0.8551, -13.6372,   3.5783,   1.8717,   3.9365,  -3.5581,  -0.3317,\n","          0.6184,   5.1693], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9980, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.37298583984375\n","Epoch 13, Batch 303 - Training loss: 113.37298583984375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.0735,  3.9356,  6.0945,  3.1649,  6.9315, -3.4898, -2.3388,  4.1985,\n","        -5.2287,  4.9846,  6.9740,  6.9419, -2.9641,  2.3660, -5.2295,  3.4900],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9982, -1.0000, -1.0000,\n","        -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.3780746459961\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-8.0735,  3.9356,  6.0945,  3.1649,  6.9315, -3.4898, -2.3388,  4.1985,\n","        -5.2287,  4.9846,  6.9740,  6.9419, -2.9641,  2.3660, -5.2295,  3.4900],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9982, -1.0000, -1.0000,\n","        -1.0000, -0.9994, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.72665405273438\n","Epoch 13, Batch 304 - Training loss: 119.72665405273438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.8804,   3.9448,   1.8315,   3.9286,   0.5338,   1.0846,  -1.5814,\n","          1.0404, -13.5170,   3.8099,   0.8972,   1.2500,  -2.7649,   2.8168,\n","         -6.8802,   8.0577], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.69282531738281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.8804,   3.9448,   1.8315,   3.9286,   0.5338,   1.0846,  -1.5814,\n","          1.0404, -13.5170,   3.8099,   0.8972,   1.2500,  -2.7649,   2.8168,\n","         -6.8802,   8.0577], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.15461730957031\n","Epoch 13, Batch 305 - Training loss: 118.15461730957031\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.8378,  1.7058,  3.6825,  5.4189,  1.3469, -2.4113, -0.2043,  1.7264,\n","        -9.8505,  5.9933,  2.9867, -0.3964, -0.9002, -0.5436, -1.0893,  9.3372],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.27471923828125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-3.8378,  1.7058,  3.6825,  5.4189,  1.3469, -2.4113, -0.2043,  1.7264,\n","        -9.8505,  5.9933,  2.9867, -0.3964, -0.9002, -0.5436, -1.0893,  9.3372],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.63406372070312\n","Epoch 13, Batch 306 - Training loss: 111.63406372070312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0713, -2.3033,  2.5918,  1.4520,  6.2453,  0.4206, -3.6775,  0.8128,\n","        -6.1262,  2.4001,  5.9692, -1.5142,  0.1573, -5.8972, -1.8901,  7.7134],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.69522094726562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0713, -2.3033,  2.5918,  1.4520,  6.2453,  0.4206, -3.6775,  0.8128,\n","        -6.1262,  2.4001,  5.9692, -1.5142,  0.1573, -5.8972, -1.8901,  7.7134],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.85694885253906\n","Epoch 13, Batch 307 - Training loss: 111.85694885253906\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.0603,  2.5776,  4.7586,  5.5648,  2.4595, -2.1991, -3.2906,  5.1464,\n","        -9.0196,  3.5097,  3.0386,  2.4843,  0.5605,  0.1177,  2.4341,  6.2712],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9987, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.33181762695312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-4.0603,  2.5776,  4.7586,  5.5648,  2.4595, -2.1991, -3.2906,  5.1464,\n","        -9.0196,  3.5097,  3.0386,  2.4843,  0.5605,  0.1177,  2.4341,  6.2712],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -0.9987, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.6708755493164\n","Epoch 13, Batch 308 - Training loss: 117.6708755493164\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.1406,   3.8130,   3.2844,   5.3004,   6.1797,   0.3547,  -1.8185,\n","          5.7220, -12.7551,   5.1756,   7.3037,   6.4773,  -2.5621,   6.1441,\n","         -2.1320,   7.0388], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.30005645751953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.1406,   3.8130,   3.2844,   5.3004,   6.1797,   0.3547,  -1.8185,\n","          5.7220, -12.7551,   5.1756,   7.3037,   6.4773,  -2.5621,   6.1441,\n","         -2.1320,   7.0388], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.79470825195312\n","Epoch 13, Batch 309 - Training loss: 116.79470825195312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.9797,  -0.1333,   4.2578,   2.5390,   3.9141,  -3.1624,   0.2675,\n","          2.2358, -14.8772,   3.6083,   1.7346,   2.5645,  -0.3710,   6.0024,\n","         -1.0181,   3.0967], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9974,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.35731506347656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.9797,  -0.1333,   4.2578,   2.5390,   3.9141,  -3.1624,   0.2675,\n","          2.2358, -14.8772,   3.6083,   1.7346,   2.5645,  -0.3710,   6.0024,\n","         -1.0181,   3.0967], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9974,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.25243377685547\n","Epoch 13, Batch 310 - Training loss: 116.25243377685547\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.0278,  4.7544,  3.7214,  3.9261,  1.4683, -4.2158, -1.1195,  2.8412,\n","        -8.7881,  3.9456,  6.4861,  2.8177,  2.6499,  4.4547, -1.2956,  8.4226],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9961, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.84129333496094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-9.0278,  4.7544,  3.7214,  3.9261,  1.4683, -4.2158, -1.1195,  2.8412,\n","        -8.7881,  3.9456,  6.4861,  2.8177,  2.6499,  4.4547, -1.2956,  8.4226],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9998, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -0.9961, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.00550079345703\n","Epoch 13, Batch 311 - Training loss: 117.00550079345703\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.0402,  -0.1077,   0.9544,   5.6508,   3.8179,   0.0519,  -3.8915,\n","          1.7065, -10.4513,  10.1400,   4.8859,   3.5714,  -0.5002,   5.1403,\n","         -3.2457,   7.9453], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.72016906738281\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -8.0402,  -0.1077,   0.9544,   5.6508,   3.8179,   0.0519,  -3.8915,\n","          1.7065, -10.4513,  10.1400,   4.8859,   3.5714,  -0.5002,   5.1403,\n","         -3.2457,   7.9453], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.86469268798828\n","Epoch 13, Batch 312 - Training loss: 114.86469268798828\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6216,   2.0310,   3.9920,   2.9735,   1.4896,  -1.5207,   1.8842,\n","          1.0911, -10.9211,   6.5506,   2.8117,   1.0762,  -6.1969,   2.7917,\n","         -5.7155,   8.1354], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 116.95771789550781\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -5.6216,   2.0310,   3.9920,   2.9735,   1.4896,  -1.5207,   1.8842,\n","          1.0911, -10.9211,   6.5506,   2.8117,   1.0762,  -6.1969,   2.7917,\n","         -5.7155,   8.1354], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 117.38247680664062\n","Epoch 13, Batch 313 - Training loss: 117.38247680664062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.1294,   1.6617,   1.4223,   4.2393,   4.1971,  -0.6185,  -2.5172,\n","          0.2533, -11.4248,   1.5262,   6.5852,   6.5888,  -3.6065,   4.1503,\n","         -0.5714,   6.5005], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 120.11053466796875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.1294,   1.6617,   1.4223,   4.2393,   4.1971,  -0.6185,  -2.5172,\n","          0.2533, -11.4248,   1.5262,   6.5852,   6.5888,  -3.6065,   4.1503,\n","         -0.5714,   6.5005], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 119.43559265136719\n","Epoch 13, Batch 314 - Training loss: 119.43559265136719\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.0514,   2.8724,   2.0842,   2.8184,  -0.0250,   0.5788,  -1.7731,\n","          0.4389, -11.9774,   2.2164,   4.5696,   2.7100,   1.3898,  -0.0314,\n","         -2.2628,   6.8306], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.62517547607422\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -4.0514,   2.8724,   2.0842,   2.8184,  -0.0250,   0.5788,  -1.7731,\n","          0.4389, -11.9774,   2.2164,   4.5696,   2.7100,   1.3898,  -0.0314,\n","         -2.2628,   6.8306], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 115.61087799072266\n","Epoch 13, Batch 315 - Training loss: 115.61087799072266\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.5687,  -1.7992,   3.6949,   3.7584,   5.2689,   2.8252,  -2.1853,\n","          5.3834, -11.1312,   7.7605,   7.2074,   1.7582,   6.6035,   1.5675,\n","         -5.1445,   5.5614], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9981, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.41142272949219\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -6.5687,  -1.7992,   3.6949,   3.7584,   5.2689,   2.8252,  -2.1853,\n","          5.3834, -11.1312,   7.7605,   7.2074,   1.7582,   6.6035,   1.5675,\n","         -5.1445,   5.5614], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9981, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.1257095336914\n","Epoch 13, Batch 316 - Training loss: 111.1257095336914\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.9828,   0.4453,  -2.2168,   6.7181,   2.1399,  -0.1823,  -1.6607,\n","          0.6874, -10.3460,   3.2498,   0.8970,   3.5510,   2.1270,   3.0654,\n","         -5.3536,   7.7758], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.31243896484375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -7.9828,   0.4453,  -2.2168,   6.7181,   2.1399,  -0.1823,  -1.6607,\n","          0.6874, -10.3460,   3.2498,   0.8970,   3.5510,   2.1270,   3.0654,\n","         -5.3536,   7.7758], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 113.39369201660156\n","Epoch 13, Batch 317 - Training loss: 113.39369201660156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.0839, -0.6476,  6.6982,  2.0475,  4.5477, -2.2139,  1.7333,  0.8128,\n","        -8.5707,  5.4269,  5.2487, -0.9049,  1.4110,  0.8429, -3.2698,  5.5674],\n","       grad_fn=<SumBackward1>), log_var: tensor([-0.9974, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 110.1118392944336\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-6.0839, -0.6476,  6.6982,  2.0475,  4.5477, -2.2139,  1.7333,  0.8128,\n","        -8.5707,  5.4269,  5.2487, -0.9049,  1.4110,  0.8429, -3.2698,  5.5674],\n","       grad_fn=<SumBackward1>), log_var: tensor([-0.9974, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 109.60865020751953\n","Epoch 13, Batch 318 - Training loss: 109.60865020751953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.1959,   5.2355,   1.8706,   1.7048,   5.1958,   0.7030,  -0.2416,\n","          1.0839, -10.3658,   6.3822,   5.5693,   5.3433,   0.6996,   3.8143,\n","          1.1655,   7.2473], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9982, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.0217514038086\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.1959,   5.2355,   1.8706,   1.7048,   5.1958,   0.7030,  -0.2416,\n","          1.0839, -10.3658,   6.3822,   5.5693,   5.3433,   0.6996,   3.8143,\n","          1.1655,   7.2473], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -0.9982, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.32818603515625\n","Epoch 13, Batch 319 - Training loss: 114.32818603515625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.5106,   0.3895,  -1.4652,   3.6637,   8.2337,  -1.8495,  -5.6633,\n","          3.3985, -12.2855,   2.2149,   6.6020,   0.3076,  -2.8758,   4.0897,\n","         -4.6438,   1.1938], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9982, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.91091918945312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -3.5106,   0.3895,  -1.4652,   3.6637,   8.2337,  -1.8495,  -5.6633,\n","          3.3985, -12.2855,   2.2149,   6.6020,   0.3076,  -2.8758,   4.0897,\n","         -4.6438,   1.1938], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -0.9982, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 112.2921142578125\n","Epoch 13, Batch 320 - Training loss: 112.2921142578125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.3575,  6.7626,  1.5849,  2.3944,  0.9360,  0.4886, -1.8818,  4.4990,\n","        -8.2483,  7.1405,  5.9012,  5.5199, -0.3776,  7.4257,  3.8766,  9.1826],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9972, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.98451232910156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-7.3575,  6.7626,  1.5849,  2.3944,  0.9360,  0.4886, -1.8818,  4.4990,\n","        -8.2483,  7.1405,  5.9012,  5.5199, -0.3776,  7.4257,  3.8766,  9.1826],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -1.0000, -0.9972, -1.0000, -1.0000, -1.0000, -1.0000],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 118.70966339111328\n","Epoch 13, Batch 321 - Training loss: 118.70966339111328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.2114,   3.1832,   2.5340,  -0.0999,   3.3070,   3.2302,  -2.1307,\n","          1.7819,  -8.6139,   3.8405,   6.7209,   3.4275,  -6.6916,   1.8376,\n","         -2.7671,   4.4369], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.5266342163086\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.2114,   3.1832,   2.5340,  -0.0999,   3.3070,   3.2302,  -2.1307,\n","          1.7819,  -8.6139,   3.8405,   6.7209,   3.4275,  -6.6916,   1.8376,\n","         -2.7671,   4.4369], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 114.79857635498047\n","Epoch 13, Batch 322 - Training loss: 114.79857635498047\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.5397,  -2.2362,   0.1222,   3.6004,   3.8064,  -0.5616,  -0.8603,\n","          1.0841, -10.8331,   1.9106,   4.1634,   4.3990,  -1.8097,  -0.8539,\n","         -0.6586,   7.0056], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.60635375976562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-10.5397,  -2.2362,   0.1222,   3.6004,   3.8064,  -0.5616,  -0.8603,\n","          1.0841, -10.8331,   1.9106,   4.1634,   4.3990,  -1.8097,  -0.8539,\n","         -0.6586,   7.0056], grad_fn=<SumBackward1>), log_var: tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n","        -1., -1.], grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 111.26113891601562\n","Epoch 13, Batch 323 - Training loss: 111.26113891601562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-5.0079,  2.0786,  3.0899,  0.3635,  4.0925, -4.3181, -2.5682,  4.7805,\n","        -9.4379,  5.7521,  7.0468,  6.7251, -1.6836,  4.7895,  5.2734,  7.4513],\n","       grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n","        -1.0000, -1.0000, -0.9992, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-fd8be832b630>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ==========DO NOT REMOVE OR MODIFY==========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Training procedure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m nll_val = training(name=result_dir + name, max_patience=max_patience,\n\u001b[0m\u001b[1;32m      4\u001b[0m                    \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mtraining_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-39-175dbe831ae2>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader, shape)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-a205fc63a5f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, reduction)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mkl_prior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mkl_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_e\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var_e\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_var_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkl_prior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkl_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Shape mismatch: {kl_prior.shape} vs {kl_encoder.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkl_prior\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkl_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-a6adecf84d12>\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, x, mu_e, log_var_e, z)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmu_e\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_var_e\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'z or mu_e or log_var_e must be given, if x is not provided'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mlog_prob_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_normal_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_var_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;31m#print(f\"Log probability: {log_prob_value}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_prob_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-709a816ff13f>\u001b[0m in \u001b[0;36mlog_normal_diag\u001b[0;34m(x, mu, log_var, reduction, dim)\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0mlog_var_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m          \u001b[0mlog_var_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_var\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Ensure x, mu, and log_var have the correct shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# ==========DO NOT REMOVE OR MODIFY==========\n","# Training procedure\n","nll_val = training(name=result_dir + name, max_patience=max_patience,\n","                   num_epochs=num_epochs, model=model, optimizer=optimizer,\n","                   training_loader=train_loader, val_loader=val_loader,\n","                   shape=(28,28))"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"JAuMt9_wquOI","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1719646754905,"user_tz":-120,"elapsed":36539,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"}},"outputId":"ea64ea28-9d67-46d1-c951-ae0c5e65bcef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 66.9706,  24.5396,  55.5578, -38.4227, -29.1558, -56.7870, -88.4687,\n","        -10.8828,  34.3244,  18.9265,   5.4100,  10.4308,  54.4164,  60.0438,\n","         21.2620, -49.0687], grad_fn=<SumBackward1>), log_var: tensor([-0.9889, -0.8435, -0.7896, -0.9756, -0.9514, -0.9828, -0.9864, -0.9611,\n","        -0.9787, -0.8371, -0.9445, -0.9526, -0.9853, -0.9721, -0.7719, -0.9858],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.22140502929688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  -1.3678,  -46.6553,    7.1594,  -65.8905,  -39.6477,  -30.3610,\n","        -125.5808,   53.9297,   50.3615,   42.1961,   21.4565,   19.1154,\n","          67.3468,   31.2313,   31.9942,  -54.3842], grad_fn=<SumBackward1>), log_var: tensor([-0.9800, -0.8317, -0.8105, -0.9818, -0.9471, -0.9743, -0.9864, -0.9524,\n","        -0.9887, -0.8222, -0.9043, -0.9423, -0.9675, -0.9817, -0.7867, -0.9809],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 158.92630004882812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  32.6383,  -59.0977,  -24.2952,  -99.1673,  -36.8027,  -62.7617,\n","        -136.7827,   54.6591,   52.5409,   91.0041,   56.1435,   85.8060,\n","          68.5659,   -6.3061,   35.9342, -115.5032], grad_fn=<SumBackward1>), log_var: tensor([-0.9953, -0.8008, -0.7185, -0.9633, -0.9607, -0.9858, -0.9855, -0.9514,\n","        -0.9926, -0.8980, -0.9321, -0.9311, -0.9645, -0.9625, -0.7175, -0.9714],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 167.21896362304688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 32.6149, -59.3531,  14.9442, -33.7834, -51.8585,  -8.4695, -80.7710,\n","         37.0340,  34.9383,  40.6537,  -2.8271,   8.1726,  70.5870,   5.5380,\n","         32.8567, -59.3214], grad_fn=<SumBackward1>), log_var: tensor([-0.9906, -0.8044, -0.8878, -0.9683, -0.9390, -0.9822, -0.9782, -0.9568,\n","        -0.9798, -0.8048, -0.9182, -0.9459, -0.9724, -0.9874, -0.8114, -0.9799],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.13633728027344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 64.5653, -55.5354,  21.4629, -13.7258, -71.6631, -20.1821, -89.2896,\n","         45.5364,  55.3612,  27.4708,  18.7215,  28.3866, 104.4632,  12.2090,\n","         58.9760, -45.1093], grad_fn=<SumBackward1>), log_var: tensor([-0.9913, -0.7899, -0.8480, -0.9559, -0.9351, -0.9538, -0.9800, -0.9544,\n","        -0.9766, -0.7654, -0.9417, -0.9366, -0.9438, -0.9695, -0.8737, -0.9849],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 173.23699951171875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  33.1936,  -19.9208,   37.5150,  -74.2124,  -39.7841,  -58.3764,\n","        -112.5725,   39.6786,   19.8827,   63.9931,   29.8112,   55.7858,\n","          78.5593,   24.2752,  -14.7845,  -98.8212], grad_fn=<SumBackward1>), log_var: tensor([-0.9807, -0.8716, -0.8272, -0.9854, -0.9424, -0.9563, -0.9925, -0.9594,\n","        -0.9832, -0.8629, -0.9210, -0.9073, -0.9501, -0.9852, -0.8039, -0.9795],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.43545532226562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 55.5904, -75.8142, -44.9077, -65.8277, -74.6435, -49.2562, -64.6807,\n","         55.9791,  43.5499,  96.0858,  27.1818,  98.9862, 111.9759, -33.5629,\n","         68.6736, -78.5380], grad_fn=<SumBackward1>), log_var: tensor([-0.9885, -0.8529, -0.8067, -0.9813, -0.9436, -0.9757, -0.9883, -0.9409,\n","        -0.9732, -0.8197, -0.9488, -0.9512, -0.9917, -0.9649, -0.7428, -0.9504],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 167.5490264892578\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  37.4588,  -57.6525,    8.9394,  -65.4017,  -35.7481,  -47.2394,\n","        -132.2265,   46.8235,   39.2656,   67.1738,   22.9231,   26.3712,\n","          72.8791,   23.6814,   27.5236, -100.3974], grad_fn=<SumBackward1>), log_var: tensor([-0.9977, -0.8376, -0.8250, -0.9630, -0.9694, -0.9647, -0.9843, -0.9506,\n","        -0.9937, -0.8330, -0.9242, -0.9386, -0.9756, -0.9841, -0.7938, -0.9799],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 164.2647705078125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 24.6800, -45.6077,  36.9248, -64.1995, -32.9107, -16.2249, -92.1533,\n","         25.2064,  31.9428,  37.2886,  -1.3260,   3.3631,  63.9993,  27.9559,\n","         -0.4957, -70.0010], grad_fn=<SumBackward1>), log_var: tensor([-0.9933, -0.8263, -0.8402, -0.9761, -0.9220, -0.9825, -0.9696, -0.9612,\n","        -0.9794, -0.8170, -0.9087, -0.9395, -0.9679, -0.9709, -0.8066, -0.9851],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 163.9607696533203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  20.7313,  -31.7951,   -2.9639,  -47.8034,  -32.5488,  -40.2661,\n","        -128.3562,   32.5040,   42.8378,   28.7198,   21.3571,   49.1114,\n","          58.8093,   16.5282,   32.8996,  -59.9783], grad_fn=<SumBackward1>), log_var: tensor([-0.9917, -0.8160, -0.8093, -0.9689, -0.9183, -0.9828, -0.9782, -0.9681,\n","        -0.9801, -0.8162, -0.9452, -0.9559, -0.9846, -0.9743, -0.8122, -0.9620],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 165.7733917236328\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  39.5860,  -45.4999,    2.5519,  -56.8096,  -53.3343,  -53.1735,\n","        -143.6370,   45.4157,   63.7642,   28.4787,   30.2404,   38.9805,\n","          94.3649,    5.6383,   32.7021,  -92.6956], grad_fn=<SumBackward1>), log_var: tensor([-0.9919, -0.8455, -0.8318, -0.9786, -0.9705, -0.9709, -0.9894, -0.9419,\n","        -0.9956, -0.8071, -0.9542, -0.9251, -0.9611, -0.9670, -0.8282, -0.9872],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 164.41671752929688\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 64.7127, -45.2722,  16.3424, -65.2620, -55.4682, -51.4276, -46.7938,\n","         37.9391,  47.5388,  79.1092,  32.8926,  62.1479, 115.3478,  17.1689,\n","         51.4244, -95.5794], grad_fn=<SumBackward1>), log_var: tensor([-0.9862, -0.8506, -0.8217, -0.9689, -0.9514, -0.9888, -0.9867, -0.9697,\n","        -0.9825, -0.8731, -0.9212, -0.9243, -0.9715, -0.9715, -0.8236, -0.9713],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 170.2847442626953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([   7.5642,  -37.9496,   29.1891,  -81.8436,  -25.0325,  -20.8473,\n","        -108.5574,   53.1026,   42.3525,   48.3852,    7.8436,   44.0699,\n","          79.0321,   28.3829,   20.5690,  -47.1109], grad_fn=<SumBackward1>), log_var: tensor([-0.9945, -0.8275, -0.8527, -0.9876, -0.9429, -0.9697, -0.9865, -0.9726,\n","        -0.9884, -0.8222, -0.9283, -0.9410, -0.9647, -0.9786, -0.8358, -0.9679],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 162.1033935546875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  33.6740,  -38.6558,   10.4428, -120.8994,   -4.5715,  -57.1090,\n","        -134.8442,    6.4409,   22.8603,   70.1833,   53.9149,   45.3433,\n","          16.2945,   12.1940,   26.1142, -129.7974], grad_fn=<SumBackward1>), log_var: tensor([-0.9993, -0.8366, -0.7675, -0.9681, -0.9622, -0.9721, -0.9741, -0.9562,\n","        -0.9940, -0.8206, -0.9164, -0.9219, -0.9882, -0.9739, -0.7335, -0.9827],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 165.1930389404297\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  32.4010,  -58.4457,    0.1559,  -73.4795,  -37.6554,  -48.6519,\n","        -131.8479,   38.8969,   52.0946,   57.0354,   43.6300,   34.3028,\n","          79.1309,   11.0160,   44.7871, -112.9837], grad_fn=<SumBackward1>), log_var: tensor([-0.9864, -0.8084, -0.8229, -0.9646, -0.9420, -0.9780, -0.9897, -0.9670,\n","        -0.9793, -0.8523, -0.9354, -0.9443, -0.9707, -0.9803, -0.8542, -0.9805],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.0208282470703\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  27.1343,    2.0014,   11.2075,  -82.1182,    9.4388,  -37.8121,\n","        -134.9329,   32.2072,   78.5373,   39.1273,   26.4654,   57.6789,\n","          51.2208,   40.3955,   50.3821,  -64.4393], grad_fn=<SumBackward1>), log_var: tensor([-0.9790, -0.7955, -0.7832, -0.9809, -0.9608, -0.9598, -0.9753, -0.9371,\n","        -0.9839, -0.8319, -0.9595, -0.9217, -0.9526, -0.9848, -0.7730, -0.9625],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 163.3267822265625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 22.8442, -76.3240,   6.2821, -59.5540, -53.9489,  -6.4806, -65.0543,\n","         51.1067,  43.6226,  66.9700,   2.1389,  36.2233, 102.5583, -15.3102,\n","         49.3214, -72.3157], grad_fn=<SumBackward1>), log_var: tensor([-0.9814, -0.8208, -0.8852, -0.9820, -0.9275, -0.9879, -0.9729, -0.9636,\n","        -0.9892, -0.8356, -0.9224, -0.9542, -0.9624, -0.9719, -0.8152, -0.9623],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 171.28134155273438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  40.8952,  -57.9943,   -5.8190,  -44.9465,  -58.3340,  -48.3947,\n","        -105.2551,   22.6240,   21.8455,   17.6389,   10.5312,   15.8685,\n","          63.0267,  -12.5274,   26.7109,  -90.5924], grad_fn=<SumBackward1>), log_var: tensor([-0.9877, -0.8458, -0.9038, -0.9736, -0.9301, -0.9648, -0.9736, -0.9680,\n","        -0.9756, -0.7696, -0.9489, -0.9200, -0.9741, -0.9830, -0.8202, -0.9700],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 167.9888153076172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  56.7493,  -41.4269,   -9.0722,  -47.0901,  -42.1391,  -62.1987,\n","        -123.5987,   21.3183,   22.2496,   46.5798,   32.7885,   69.0484,\n","          80.0145,  -23.6470,   32.0349, -100.3859], grad_fn=<SumBackward1>), log_var: tensor([-0.9813, -0.8399, -0.7786, -0.9704, -0.9746, -0.9784, -0.9850, -0.9705,\n","        -0.9659, -0.8188, -0.9519, -0.9230, -0.9576, -0.9659, -0.7813, -0.9853],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 167.45787048339844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 41.3814, -59.3226,  26.6014, -40.9311, -51.8401, -29.6125, -92.0433,\n","         44.6129,  18.5205,  49.4946,   9.8259,  29.9421,  95.4697,  36.5705,\n","         19.9718, -53.3525], grad_fn=<SumBackward1>), log_var: tensor([-0.9769, -0.8264, -0.8649, -0.9533, -0.9434, -0.9669, -0.9895, -0.9730,\n","        -0.9830, -0.8012, -0.9197, -0.9385, -0.9653, -0.9840, -0.8050, -0.9748],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 165.00228881835938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([   8.5774,  -91.0222,   -5.7403, -114.9888,  -38.0060,  -19.7431,\n","         -80.9717,   37.7060,   28.1415,   45.8582,   17.0992,   21.2396,\n","          54.5795,    7.3032,   18.4572, -132.1479], grad_fn=<SumBackward1>), log_var: tensor([-0.9884, -0.8577, -0.8481, -0.9634, -0.9465, -0.9837, -0.9878, -0.9682,\n","        -0.9894, -0.7878, -0.9413, -0.9508, -0.9424, -0.9788, -0.7738, -0.9799],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 165.8384552001953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 50.8926, -64.6648, -19.9993, -58.9704, -13.8053, -23.8697, -70.6461,\n","         48.9596,  65.1312,  51.0927,  48.2900,  62.8392,  69.3480,  12.4514,\n","        107.5634, -52.2038], grad_fn=<SumBackward1>), log_var: tensor([-0.9943, -0.7840, -0.8439, -0.9921, -0.9587, -0.9852, -0.9889, -0.9392,\n","        -0.9937, -0.8059, -0.9413, -0.9641, -0.9720, -0.9947, -0.8491, -0.9625],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 167.4268035888672\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 39.1030, -41.2536,  47.5348, -44.1493, -30.9070, -10.1819, -95.9815,\n","         11.1950,  44.4384,  33.6556,   6.0743,  10.8567,  70.7026,  24.8522,\n","         12.9694, -61.4620], grad_fn=<SumBackward1>), log_var: tensor([-0.9908, -0.7970, -0.8417, -0.9796, -0.9477, -0.9962, -0.9838, -0.9717,\n","        -0.9629, -0.8073, -0.9234, -0.9595, -0.9632, -0.9861, -0.8242, -0.9707],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.20008850097656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([   0.5874,  -52.7163,  -23.9161,  -73.2022,  -12.2351,  -33.8747,\n","        -102.9097,   36.1049,   46.8970,   39.6006,   15.5837,   59.2233,\n","          51.6237,    1.6692,   42.6513,  -64.3879], grad_fn=<SumBackward1>), log_var: tensor([-0.9845, -0.7774, -0.8170, -0.9771, -0.9541, -0.9840, -0.9732, -0.9643,\n","        -0.9882, -0.8240, -0.9587, -0.9455, -0.9667, -0.9811, -0.7856, -0.9661],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 164.53274536132812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 48.3864, -53.1131,   7.7850, -65.1449, -50.9615, -31.1523, -99.7580,\n","         50.1583,  61.5181,  65.0638,   8.1010,  30.8778,  96.7868,  41.0954,\n","         72.3283, -56.6093], grad_fn=<SumBackward1>), log_var: tensor([-0.9959, -0.8070, -0.8200, -0.9794, -0.9682, -0.9720, -0.9788, -0.9343,\n","        -0.9920, -0.8520, -0.9314, -0.9426, -0.9421, -0.9784, -0.8349, -0.9700],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 164.2337188720703\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 22.0983, -82.3622, -47.2883, -35.3121, -51.9240, -35.3622, -95.4781,\n","         37.0677,  30.7721,  28.9458,  23.3790,  69.5593,  65.0887, -46.3840,\n","         40.4587, -84.0177], grad_fn=<SumBackward1>), log_var: tensor([-0.9904, -0.7958, -0.8529, -0.9859, -0.9160, -0.9721, -0.9904, -0.9484,\n","        -0.9874, -0.7800, -0.9185, -0.9302, -0.9788, -0.9750, -0.7626, -0.9730],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 165.34832763671875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 1.4616e+01, -9.5241e-03,  1.3099e+00, -6.2689e+01, -4.3914e+00,\n","        -2.1172e+01, -6.6350e+01,  4.1885e+01,  1.7503e+01,  5.1129e+01,\n","         1.5285e+01,  8.7048e+01,  5.0380e+01,  5.2795e+00,  3.2547e+01,\n","        -3.4590e+01], grad_fn=<SumBackward1>), log_var: tensor([-0.9864, -0.8548, -0.8396, -0.9717, -0.9573, -0.9858, -0.9730, -0.9899,\n","        -0.9876, -0.8446, -0.9417, -0.9237, -0.9889, -0.9817, -0.7736, -0.9866],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 163.5791015625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 44.3232, -72.7697,  10.6972, -21.5149, -70.3771, -13.6334, -60.0720,\n","         22.7688,  62.7912,  35.5673,  14.5386,  26.3266, 118.6510,   4.8482,\n","         51.3793, -38.2929], grad_fn=<SumBackward1>), log_var: tensor([-0.9877, -0.7693, -0.8612, -0.9776, -0.9193, -0.9776, -0.9781, -0.9454,\n","        -0.9757, -0.8053, -0.9122, -0.9463, -0.9727, -0.9651, -0.8257, -0.9501],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 170.5703125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  38.0560,  -19.0985,    0.7963,  -46.2949,  -32.3075,  -62.9119,\n","        -107.8443,    9.1399,    3.1822,   58.2937,   15.1271,   48.9257,\n","          56.2687,   -2.4760,   38.1383,  -73.5847], grad_fn=<SumBackward1>), log_var: tensor([-0.9822, -0.8630, -0.8156, -0.9764, -0.9408, -0.9821, -0.9779, -0.9750,\n","        -0.9805, -0.8608, -0.9614, -0.9323, -0.9746, -0.9723, -0.7920, -0.9718],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 164.0012664794922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 38.4264, -59.8495,  -5.2680, -32.2256, -39.2539, -23.4594, -50.0774,\n","         12.7126,   5.5961,  53.3314,   9.1854,  42.2105,  63.9496, -33.7592,\n","         29.5104, -82.8830], grad_fn=<SumBackward1>), log_var: tensor([-0.9862, -0.8216, -0.8462, -0.9682, -0.9617, -0.9751, -0.9836, -0.9654,\n","        -0.9793, -0.7831, -0.9332, -0.9237, -0.9726, -0.9677, -0.7803, -0.9742],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 177.15621948242188\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 53.1950, -69.4902,   9.8845, -12.9537, -47.5913, -13.7900, -49.4046,\n","         18.4140,  32.4825,  62.5971,  25.1176,  22.3467,  76.9663,  13.6365,\n","         69.6304, -72.2750], grad_fn=<SumBackward1>), log_var: tensor([-0.9792, -0.7880, -0.8335, -0.9799, -0.9608, -0.9825, -0.9819, -0.9378,\n","        -0.9812, -0.8366, -0.9187, -0.9575, -0.9746, -0.9663, -0.8707, -0.9800],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 176.1197052001953\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  40.2117,   -8.8647,   42.9813,  -97.3610,    8.4128,  -51.4860,\n","        -108.5522,   14.2425,   -3.7331,   69.9377,   43.3705,   58.9842,\n","          36.5760,   41.4141,  -10.7506, -104.8792], grad_fn=<SumBackward1>), log_var: tensor([-0.9921, -0.8227, -0.7413, -0.9772, -0.9739, -0.9915, -0.9743, -0.9558,\n","        -0.9789, -0.8461, -0.9550, -0.9356, -0.9780, -0.9831, -0.7502, -0.9702],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 162.23658752441406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  16.5868,  -33.9428,   -6.7848,  -64.2744,  -23.2788,  -29.9498,\n","        -120.6177,   41.0895,   11.6261,   29.5546,   11.7822,   62.7707,\n","          47.2152,   -6.1390,   -8.1301,  -64.6730], grad_fn=<SumBackward1>), log_var: tensor([-0.9813, -0.7976, -0.8295, -0.9802, -0.9490, -0.9801, -0.9824, -0.9534,\n","        -0.9741, -0.8140, -0.9595, -0.9559, -0.9696, -0.9709, -0.7447, -0.9845],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 167.90760803222656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  20.9919,  -42.9519,   -3.2299,  -90.0583,   -7.6630,  -40.4038,\n","        -107.7272,   17.8737,   53.8987,   64.8771,   21.5077,   35.3750,\n","          51.9694,   15.3604,   39.9394,  -89.1734], grad_fn=<SumBackward1>), log_var: tensor([-0.9906, -0.8135, -0.8542, -0.9500, -0.9464, -0.9797, -0.9894, -0.9262,\n","        -0.9877, -0.8485, -0.9492, -0.9333, -0.9829, -0.9725, -0.8082, -0.9814],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 163.39453125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 40.8367, -81.2106,  25.9472, -32.7747, -62.7826,   1.5074, -61.3772,\n","         44.5737,  68.2721,  49.9648,   9.8972,   6.2970, 117.0716,  25.1165,\n","         51.6098, -46.4407], grad_fn=<SumBackward1>), log_var: tensor([-0.9962, -0.7439, -0.8618, -0.9791, -0.9502, -0.9810, -0.9631, -0.9302,\n","        -0.9925, -0.8100, -0.9130, -0.9417, -0.9670, -0.9844, -0.8547, -0.9658],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 170.7629852294922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 12.2500, -46.8865,   8.0840, -47.8563, -59.1842, -37.3623, -82.7568,\n","         51.9383,  27.3194,  45.0651,   0.5292,  57.2943,  70.2310,  -3.1137,\n","         -5.5581, -50.9739], grad_fn=<SumBackward1>), log_var: tensor([-0.9903, -0.8745, -0.8353, -0.9854, -0.9321, -0.9630, -0.9681, -0.9598,\n","        -0.9773, -0.8098, -0.9346, -0.9521, -0.9781, -0.9701, -0.8154, -0.9741],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.7290496826172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 55.9488, -40.0511,   2.8426, -39.2349, -50.7556, -46.6812, -96.2456,\n","         14.8392,  53.5056,  36.7638,  41.7308,  42.8533,  85.8418,  16.5366,\n","         33.8610, -88.6851], grad_fn=<SumBackward1>), log_var: tensor([-0.9958, -0.8415, -0.8499, -0.9800, -0.9550, -0.9667, -0.9786, -0.9219,\n","        -0.9805, -0.8619, -0.9464, -0.9454, -0.9670, -0.9707, -0.8010, -0.9839],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.2014617919922\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  14.1158,  -38.7534,   72.3674,  -68.3922,  -37.3794,  -15.3797,\n","        -112.9206,   29.9341,   25.3931,   48.8143,   14.2206,   12.1741,\n","          56.1054,   42.4066,  -32.8958,  -81.6419], grad_fn=<SumBackward1>), log_var: tensor([-0.9923, -0.8044, -0.8121, -0.9860, -0.9061, -0.9897, -0.9761, -0.9590,\n","        -0.9868, -0.8128, -0.9017, -0.9342, -0.9611, -0.9716, -0.8265, -0.9697],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.68466186523438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  31.5030,  -52.8678,    3.1179,  -69.7891,  -40.6449,  -36.8357,\n","        -146.1186,   32.8757,   62.7028,   46.6663,   25.2149,   30.6138,\n","          66.6481,    1.0645,   19.5674,  -70.3749], grad_fn=<SumBackward1>), log_var: tensor([-0.9877, -0.7228, -0.8356, -0.9856, -0.9698, -0.9901, -0.9771, -0.9474,\n","        -0.9870, -0.7977, -0.9222, -0.9390, -0.9703, -0.9690, -0.7946, -0.9917],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 163.65667724609375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -96.1852,    0.6107,  -49.7752,   40.4821,   64.4900,  100.1908,\n","          26.8124,  -33.4355, -145.8096,  -58.0285,  -88.8197,   28.4056,\n","         -65.1189, -135.7656,   16.4068,   91.1043], grad_fn=<SumBackward1>), log_var: tensor([-0.9868, -0.7568, -0.9534, -0.9916, -0.9375, -0.9990, -0.9791, -0.9583,\n","        -0.9921, -0.5266, -0.9234, -0.9623, -0.9816, -0.9797, -0.9011, -0.9907],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 161.95004272460938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-17.4845, -37.3949,  -8.6619, -12.1431,  32.8613,  31.5158, -45.4771,\n","        -29.2729, -54.8035, -11.0308, -41.2947, -19.5731, -32.2532, -15.6328,\n","         46.5793,   1.3942], grad_fn=<SumBackward1>), log_var: tensor([-0.9935, -0.7847, -0.8861, -0.9692, -0.9341, -0.9801, -0.9361, -0.9287,\n","        -0.9952, -0.7171, -0.9026, -0.9137, -0.9557, -0.9804, -0.8391, -0.9801],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 171.1803436279297\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  18.9934,  -68.8012,   36.7488,   10.7161,  -12.7643,   78.9544,\n","         124.5434,   -9.0012, -102.8910,   66.0651,  -37.7508,  -11.5460,\n","          28.7253,  -36.4517,   67.3441,   28.5164], grad_fn=<SumBackward1>), log_var: tensor([-0.9975, -0.8075, -0.9196, -0.9947, -0.9627, -0.9860, -0.9878, -0.9715,\n","        -0.9887, -0.6901, -0.9360, -0.9677, -0.9609, -0.9876, -0.9205, -0.9844],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 161.7022705078125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([   5.2324,  -63.2573,   -2.8491,   49.3043,  -21.0539,   79.4251,\n","          56.8313,    3.1770, -127.9448,  -16.6568,  -50.7422,   -0.6819,\n","           5.6039,  -78.4657,    6.6953,   12.6037], grad_fn=<SumBackward1>), log_var: tensor([-0.9890, -0.7792, -0.9336, -0.9724, -0.9548, -0.9877, -0.9493, -0.9728,\n","        -0.9838, -0.6263, -0.9193, -0.9500, -0.9779, -0.9655, -0.8910, -0.9893],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 170.44207763671875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  49.1567, -138.7778,   74.5544,  -61.1924,  -83.6036,   58.1583,\n","           5.6472,   93.0725,    1.6127,  174.5740,   32.3055,   74.0367,\n","         168.7027,   34.0669,   23.8631,  -51.2064], grad_fn=<SumBackward1>), log_var: tensor([-0.9913, -0.8220, -0.8233, -0.9965, -0.9841, -0.9752, -0.9900, -0.9611,\n","        -0.9928, -0.8785, -0.9490, -0.9599, -0.9769, -0.9604, -0.7915, -0.9751],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 164.41848754882812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 39.4549, -69.1673,  32.3807, -39.1035, -46.8866,  -3.6447, -45.3171,\n","         42.6985,  11.9213,  75.4514,  26.7245,  41.9361,  85.9855,  23.8916,\n","         22.0708, -46.1172], grad_fn=<SumBackward1>), log_var: tensor([-0.9937, -0.8419, -0.8811, -0.9947, -0.9584, -0.9556, -0.9864, -0.9466,\n","        -0.9907, -0.8668, -0.9130, -0.9617, -0.9807, -0.9753, -0.8148, -0.9776],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 170.82089233398438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  3.8840, -76.8794, -23.9851,   8.1856, -54.1440,  38.7286,  29.0222,\n","         53.7186, -46.7548,  96.2514,   1.8552,  72.9029,  87.8410, -54.8462,\n","         89.5837,  -5.9739], grad_fn=<SumBackward1>), log_var: tensor([-0.9910, -0.8640, -0.8884, -0.9686, -0.9738, -0.9963, -0.9801, -0.9733,\n","        -0.9761, -0.8180, -0.9347, -0.9175, -0.9799, -0.9652, -0.8090, -0.9717],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 173.0938262939453\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 146.9291,  -71.2639,   62.0711,  -67.7541, -132.1697,  -54.2625,\n","         -33.9427,  110.1430,  113.6264,  109.4057,   57.5491,  124.9619,\n","         238.4584,   64.4444,    4.5562,  -91.4676], grad_fn=<SumBackward1>), log_var: tensor([-0.9897, -0.8296, -0.8578, -0.9938, -0.9595, -0.9529, -0.9859, -0.9640,\n","        -0.9769, -0.8993, -0.9045, -0.9646, -0.9653, -0.9871, -0.8314, -0.9266],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 176.54566955566406\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 125.7013, -112.0003,   76.4723,    2.9466, -140.0638,   39.8676,\n","         115.9121,  108.8544,  -80.2684,  120.2502,   32.3999,  145.6033,\n","         217.2068,  -63.3753,  -44.0230,  -57.3705], grad_fn=<SumBackward1>), log_var: tensor([-0.9774, -0.9404, -0.8861, -0.9982, -0.9676, -0.9631, -0.9768, -0.9866,\n","        -0.9828, -0.8798, -0.8749, -0.9459, -0.9672, -0.9932, -0.9054, -0.9540],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 190.20916748046875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  -2.0398,  -75.3125,  111.6370,   40.2030,  -46.7547,  123.7886,\n","         163.1371,    1.5567, -171.9242,   71.8186,  -53.9734,  -20.8596,\n","          72.0300,  -18.4728,  -24.7198,   57.4990], grad_fn=<SumBackward1>), log_var: tensor([-0.9889, -0.9214, -0.9425, -0.9918, -0.9540, -0.9937, -0.9786, -0.9630,\n","        -0.9920, -0.7711, -0.8742, -0.9570, -0.9850, -0.9780, -0.8321, -0.9734],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 167.20989990234375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 71.1659, -73.7450,  15.6512,  79.4553, -87.1941,  53.1671,  96.3697,\n","         41.4552, -53.6650, 109.5524,   7.6223,  86.9922, 143.6517, -41.0919,\n","        102.6497,  18.7447], grad_fn=<SumBackward1>), log_var: tensor([-0.9722, -0.8604, -0.9225, -0.9625, -0.9620, -0.9766, -0.9868, -0.9651,\n","        -0.9783, -0.8205, -0.9000, -0.9379, -0.9758, -0.9647, -0.8883, -0.9823],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 172.43597412109375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -82.6495,  -40.4300,  -53.4937,   58.2545,   40.0604,  133.7914,\n","         123.4414,  -35.5467, -159.2016,   15.4531,  -78.3972,    9.8998,\n","         -26.6149, -102.3177,   98.7233,  107.3829], grad_fn=<SumBackward1>), log_var: tensor([-0.9795, -0.7871, -0.9360, -0.9559, -0.9652, -0.9785, -0.9636, -0.9632,\n","        -0.9875, -0.7073, -0.9200, -0.9742, -0.9833, -0.9589, -0.9063, -0.9763],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 169.46327209472656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -50.5737,   87.8183,  -92.6870,  -50.2104,   70.8356,  -57.1007,\n","        -138.6472,  -40.2809,    3.8538,  -51.9972,  -39.2180,   -4.4763,\n","         -93.0211,  -29.4806,   82.5364,   -1.7009], grad_fn=<SumBackward1>), log_var: tensor([-0.9864, -0.7706, -0.8231, -0.9564, -0.9446, -0.9838, -0.9620, -0.9631,\n","        -0.9904, -0.7602, -0.9458, -0.9293, -0.9484, -0.9817, -0.7946, -0.9975],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 161.0443115234375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -69.6836,   51.0821,  -92.0894,   89.5886,   56.2509,   96.2432,\n","         143.4298,  -91.0569, -151.7950,  -85.9855, -128.6779,   38.6796,\n","         -92.4569, -194.2975,   61.9232,  132.6258], grad_fn=<SumBackward1>), log_var: tensor([-0.9915, -0.6551, -0.9495, -0.9662, -0.8803, -0.9840, -0.9884, -0.9536,\n","        -0.9748, -0.5614, -0.9368, -0.9666, -0.9727, -0.9951, -0.8948, -0.9880],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 180.37510681152344\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  68.7960,  -83.6945,   37.6615,  -98.9476,  -73.1231,  -37.1281,\n","         -82.1113,   82.8764,   26.8684,  119.7377,   28.3835,   80.2693,\n","         143.0325,   32.3254,   20.0254, -109.9223], grad_fn=<SumBackward1>), log_var: tensor([-0.9794, -0.8433, -0.8659, -0.9812, -0.9416, -0.9507, -0.9876, -0.9427,\n","        -0.9883, -0.9075, -0.9406, -0.9453, -0.9847, -0.9917, -0.8289, -0.9560],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 165.648193359375\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-126.9662,  -55.6706,   -8.7655,  -46.2525,   24.7441,  131.7158,\n","          46.0297,   79.2443, -117.0997,   18.9141, -119.2777,    6.3317,\n","           7.2862,  -32.7139,   -9.7382,  109.2857], grad_fn=<SumBackward1>), log_var: tensor([-0.9994, -0.8254, -0.9506, -0.9923, -0.9617, -0.9973, -0.9743, -0.9821,\n","        -0.9849, -0.7362, -0.9207, -0.9678, -0.9600, -0.9807, -0.8350, -0.9871],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 152.66677856445312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-139.5269,  -23.9542,    1.9382,   -9.1477,   38.0441,  137.2829,\n","          37.6115,   37.5232, -182.3562,  -86.9271, -175.1665,  -49.7582,\n","         -96.1667,  -67.4820,  -75.6776,  109.4433], grad_fn=<SumBackward1>), log_var: tensor([-0.9815, -0.7779, -0.9565, -0.9886, -0.9371, -0.9738, -0.9437, -0.9570,\n","        -0.9859, -0.5814, -0.9021, -0.9668, -0.9839, -0.9770, -0.8801, -0.9943],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 156.86239624023438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -69.7205,   18.0403,  -51.0236,  -11.7715,   64.9292,   51.9117,\n","          31.8893,  -48.9961, -102.8967,  -11.9139,  -90.7557,  -12.4657,\n","         -83.8232,  -79.6427,   38.2204,   48.9665], grad_fn=<SumBackward1>), log_var: tensor([-0.9867, -0.7201, -0.9094, -0.9576, -0.9317, -0.9912, -0.9499, -0.9671,\n","        -0.9745, -0.7259, -0.9043, -0.9670, -0.9909, -0.9532, -0.8408, -0.9936],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 165.7573699951172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-144.4374,  -79.3424,   10.7439,    8.9147,   -2.0508,  173.7083,\n","          78.6464,  105.5871, -159.8344,  -17.7855, -146.8079,   -4.3471,\n","          -0.7670,  -76.3019,  -49.5480,  149.8401], grad_fn=<SumBackward1>), log_var: tensor([-0.9961, -0.7549, -0.9556, -0.9877, -0.9637, -0.9933, -0.9906, -0.9895,\n","        -0.9978, -0.6530, -0.8610, -0.9614, -0.9866, -0.9777, -0.8878, -0.9893],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 152.42662048339844\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-188.3403,    7.8701, -140.1594,  -36.9490,  105.0346,   96.8016,\n","          48.5074,  -19.1498,  -99.0191,  -48.0294, -156.3530,  -17.1280,\n","        -106.9285, -122.8980,   77.4021,  117.0009], grad_fn=<SumBackward1>), log_var: tensor([-0.9914, -0.7523, -0.9653, -0.9591, -0.9258, -0.9968, -0.9946, -0.9375,\n","        -0.9922, -0.7074, -0.9445, -0.9721, -0.9795, -0.9771, -0.8557, -0.9714],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 168.42367553710938\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-11.3308, -53.4079,  12.3496, -22.3747, -17.4171,  44.7913, -33.0083,\n","         -1.1562,   0.8904,  44.0497, -38.5717, -23.3094,  39.5719,  -9.9030,\n","         66.0247,  -0.0782], grad_fn=<SumBackward1>), log_var: tensor([-0.9988, -0.7651, -0.9127, -0.9933, -0.9283, -0.9865, -0.9883, -0.9359,\n","        -0.9850, -0.7062, -0.8859, -0.9466, -0.9632, -0.9830, -0.8121, -0.9776],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 161.40090942382812\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  22.9683, -121.2935,   42.7131,   81.9623, -111.7010,  105.4073,\n","         142.1057,   71.8549, -131.8953,   60.6578,  -51.0036,   42.8923,\n","         122.5747,  -92.9949,   11.7569,   48.3020], grad_fn=<SumBackward1>), log_var: tensor([-0.9907, -0.8889, -0.9366, -0.9752, -0.9403, -0.9777, -0.9628, -0.9765,\n","        -0.9878, -0.7177, -0.9090, -0.9642, -0.9839, -0.9651, -0.8960, -0.9643],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 178.62564086914062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -41.3062,  -37.3004,   58.1657,  183.3770,  -79.9975,  183.5953,\n","         305.7691,  -11.3104, -302.4609,  -50.5046, -149.5349,   68.8414,\n","          77.4821, -218.2161,  -67.2502,  176.1255], grad_fn=<SumBackward1>), log_var: tensor([-0.9754, -0.8978, -0.9866, -0.9903, -0.9183, -0.9879, -0.9707, -0.9574,\n","        -0.9702, -0.5153, -0.9110, -0.9901, -0.9981, -0.9909, -0.9704, -0.9987],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 189.22401428222656\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -31.3976,  -86.3802,   38.5680,   55.4508,  -52.0477,  124.9498,\n","         179.7832,   67.5778, -188.7260,   24.7237, -103.4509,   57.9930,\n","          85.3844, -135.1255,  -37.1201,   93.0245], grad_fn=<SumBackward1>), log_var: tensor([-0.9905, -0.8320, -0.9523, -0.9783, -0.9296, -0.9807, -0.9616, -0.9625,\n","        -0.9905, -0.6725, -0.8933, -0.9778, -0.9925, -0.9793, -0.9229, -0.9597],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 178.4558868408203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -67.0031,  -42.1234,   -4.5949,    4.2375,    3.9974,  119.8188,\n","          98.4743,   51.7321, -169.1858,  -15.2881,  -85.5704,   53.3178,\n","          -1.5694, -115.3836,  -33.3849,   65.2738], grad_fn=<SumBackward1>), log_var: tensor([-0.9817, -0.7738, -0.9038, -0.9909, -0.9342, -0.9837, -0.9872, -0.9887,\n","        -0.9860, -0.6864, -0.8760, -0.9770, -0.9835, -0.9861, -0.9112, -0.9594],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 169.25732421875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -21.7479,   43.4107,    5.1888,   69.5359,   51.2161,   77.8201,\n","         131.6560,  -94.6280, -152.4729,  -72.0808,  -98.5899,   -8.4712,\n","         -97.3410, -107.4131,   46.1499,   76.2811], grad_fn=<SumBackward1>), log_var: tensor([-0.9928, -0.7262, -0.9142, -0.9808, -0.9110, -0.9972, -0.9750, -0.9684,\n","        -0.9781, -0.5833, -0.9012, -0.9406, -0.9739, -0.9846, -0.9318, -0.9679],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 189.05770874023438\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  15.9357,   54.9841,   19.5196,   35.6790,   40.2603,   32.5284,\n","          77.2726,  -64.8072, -124.2043,    4.9058,  -27.3969,   41.8756,\n","         -11.3424,  -60.6485,   38.7079,   38.3863], grad_fn=<SumBackward1>), log_var: tensor([-0.9771, -0.7848, -0.9416, -0.9562, -0.9418, -0.9947, -0.9838, -0.9686,\n","        -0.9739, -0.7693, -0.9227, -0.9252, -0.9544, -0.9870, -0.8699, -0.9791],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 180.1489715576172\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  92.4906, -118.0702,   77.8643,   25.4432, -156.9338,   21.3078,\n","          64.5887,  101.8999,  -72.3251,  145.6676,   21.7410,  147.5119,\n","         213.6346,  -31.6323,  -51.0422,  -60.1917], grad_fn=<SumBackward1>), log_var: tensor([-0.9746, -0.9448, -0.8594, -0.9959, -0.9598, -0.9667, -0.9644, -0.9644,\n","        -0.9836, -0.9248, -0.8959, -0.9626, -0.9715, -0.9669, -0.8513, -0.9493],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 183.03204345703125\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 56.7092, -98.5773,  79.5290,  18.8015, -46.2937,  49.5300,  31.8226,\n","         -4.2647, -47.1294,  97.8138,  11.0352, -36.2924,  96.0698,  44.2812,\n","         74.9696, -49.8952], grad_fn=<SumBackward1>), log_var: tensor([-0.9941, -0.8208, -0.8888, -0.9695, -0.9594, -0.9859, -0.9492, -0.9691,\n","        -0.9801, -0.8401, -0.9281, -0.9254, -0.9728, -0.9611, -0.8351, -0.9893],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 166.00389099121094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -36.0587,  -57.6115,   42.8258,   44.9068,  -26.5869,  128.6238,\n","          79.3985,   39.7123, -157.0841,   22.6593,  -82.7711,   -4.4010,\n","          57.7215,  -46.5248,   -9.5990,   92.0906], grad_fn=<SumBackward1>), log_var: tensor([-0.9887, -0.8371, -0.9825, -0.9871, -0.9491, -0.9895, -0.9755, -0.9598,\n","        -0.9829, -0.7176, -0.9188, -0.9624, -0.9880, -0.9698, -0.9140, -0.9693],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 155.45449829101562\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -94.5775,   -2.2516,    6.8213,   43.4304,   48.7339,  126.8289,\n","         154.2065,  -46.3401, -210.7763,    0.3761, -146.8859,  -36.6511,\n","         -60.0100,  -79.7117,   49.6757,  147.7117], grad_fn=<SumBackward1>), log_var: tensor([-0.9886, -0.8263, -0.9722, -0.9778, -0.9360, -0.9898, -0.9693, -0.9765,\n","        -0.9725, -0.6172, -0.9605, -0.9767, -0.9764, -0.9704, -0.8978, -0.9591],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 163.2469482421875\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  -7.8258,  -16.1964,  -31.8719,   95.9450,   -5.8245,  108.3035,\n","         126.5625,  -33.5314, -113.9206,   -5.4832,  -69.4182,   42.8492,\n","          21.5333, -159.0816,   60.5723,   71.0954], grad_fn=<SumBackward1>), log_var: tensor([-0.9793, -0.7376, -0.9405, -0.9922, -0.9306, -0.9842, -0.9698, -0.9731,\n","        -0.9794, -0.7007, -0.8748, -0.9455, -0.9684, -0.9706, -0.9235, -0.9855],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 189.93763732910156\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([  31.7246,  -94.4448,   21.2121,   46.7994, -105.2756,   67.8572,\n","          85.5835,   43.0703,  -93.8607,   56.8827,  -40.8358,   78.2308,\n","         130.1220,  -96.6898,  -34.3083,   10.7102], grad_fn=<SumBackward1>), log_var: tensor([-0.9827, -0.8150, -0.9279, -0.9855, -0.9402, -0.9930, -0.9949, -0.9847,\n","        -0.9845, -0.7999, -0.9174, -0.9290, -0.9827, -0.9618, -0.8749, -0.8996],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 184.95066833496094\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-13.2939,  -9.9100,  14.1259, -52.1175,  54.3617,  33.8220,   5.7396,\n","        -53.3501, -96.8853,  14.0391, -44.8662,  -9.8313, -54.2919, -27.3174,\n","         28.3815,  -4.3738], grad_fn=<SumBackward1>), log_var: tensor([-0.9923, -0.7752, -0.8273, -0.9721, -0.9437, -0.9889, -0.9735, -0.9852,\n","        -0.9904, -0.7305, -0.9213, -0.9430, -0.9601, -0.9809, -0.8277, -0.9935],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 168.55621337890625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ 92.8057, -21.1627,  44.9124,  -7.4341, -64.1322, -33.3644, -23.1852,\n","         38.6010,  -1.7206,  98.0250,  42.9252,  81.2307, 117.0969,  15.2993,\n","         42.7926, -56.7256], grad_fn=<SumBackward1>), log_var: tensor([-0.9886, -0.8963, -0.8152, -0.9701, -0.9091, -0.9640, -0.9842, -0.9479,\n","        -0.9796, -0.8793, -0.9084, -0.9618, -0.9751, -0.9783, -0.7872, -0.9760],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 169.11245727539062\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([ -49.4013,  -26.2086,   52.1459,   44.1581,  -31.0449,   52.4981,\n","          17.2215,   21.3516, -159.1044,  -29.0302, -113.1252,  -15.6320,\n","          -5.1245,  -79.8106,  -73.9175,   48.0558], grad_fn=<SumBackward1>), log_var: tensor([-0.9766, -0.8734, -0.9589, -0.9689, -0.9485, -0.9839, -0.9557, -0.9779,\n","        -0.9866, -0.6135, -0.8954, -0.9161, -0.9832, -0.9746, -0.8736, -0.9814],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 172.1297149658203\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-144.2389,    4.1153, -157.8991,  -11.8040,   97.6332,   33.7369,\n","          12.0728, -110.7597, -137.6758,  -63.0030, -126.0019,   -9.3697,\n","        -135.8316, -172.5185,   76.0040,   53.8155], grad_fn=<SumBackward1>), log_var: tensor([-0.9843, -0.6544, -0.9518, -0.9570, -0.9114, -0.9925, -0.9782, -0.9598,\n","        -0.9947, -0.6189, -0.9568, -0.9655, -0.9866, -0.9810, -0.8168, -0.9909],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 172.26882934570312\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-202.2148,    1.7167, -185.0342,  -50.2739,  124.5249,   73.1808,\n","          -4.1816,  -72.0198, -119.4112,  -75.5123, -117.9621,   13.3198,\n","        -155.9117, -169.0218,   66.6000,   55.4300], grad_fn=<SumBackward1>), log_var: tensor([-0.9949, -0.6521, -0.9284, -0.9778, -0.9396, -0.9896, -0.9808, -0.9754,\n","        -0.9692, -0.6101, -0.9497, -0.9710, -0.9723, -0.9558, -0.8357, -0.9922],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 163.96978759765625\n","Encoder - shape encode mu: torch.Size([128, 16]), log_var: torch.Size([128, 16])\n","Encodeer - shape reparam mu: torch.Size([128, 16]), std: torch.Size([128, 16]), eps: torch.Size([128, 16])\n","Encodeer - shape sample mu: torch.Size([128, 16]), log_var: torch.Size([128, 16]), z: torch.Size([128, 16])\n","Encoder sample - mu: tensor([-118.3206,   33.8519,  -91.4251,   -3.8369,  107.1861,   44.5941,\n","         -18.9600,  -95.6224, -122.1113,  -85.4947,  -91.7505,  -13.6914,\n","        -168.2806, -108.7280,   46.3633,   47.1039], grad_fn=<SumBackward1>), log_var: tensor([-0.9795, -0.6786, -0.8831, -0.9761, -0.9332, -0.9966, -0.9683, -0.9729,\n","        -0.9823, -0.6343, -0.9342, -0.9494, -0.9897, -0.9812, -0.8540, -0.9854],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([128])\n","current elbo 164.0972900390625\n","Encoder - shape encode mu: torch.Size([16, 16]), log_var: torch.Size([16, 16])\n","Encodeer - shape reparam mu: torch.Size([16, 16]), std: torch.Size([16, 16]), eps: torch.Size([16, 16])\n","Encodeer - shape sample mu: torch.Size([16, 16]), log_var: torch.Size([16, 16]), z: torch.Size([16, 16])\n","Encoder sample - mu: tensor([ -8.2472, -11.3398,   4.7025,   1.0406,  -5.9265,  12.8010,   7.5105,\n","         15.6352, -24.2295,   4.9766, -12.2381,   7.5102,   5.7189,  -9.7811,\n","        -15.8625,   6.8620], grad_fn=<SumBackward1>), log_var: tensor([-1.0000, -0.9487, -0.9607, -1.0000, -0.8959, -0.9304, -0.9965, -0.9933,\n","        -0.9747, -0.8124, -0.8024, -0.9362, -1.0000, -0.9953, -0.8254, -0.9843],\n","       grad_fn=<MeanBackward1>)\n","Log probability decoded x shape: torch.Size([16])\n","current elbo 164.1627655029297\n","FINAL LOSS: nll=168.5440858154297\n","Log probability decoded x shape: torch.Size([64])\n"]},{"output_type":"error","ename":"ValueError","evalue":"cannot reshape array of size 1 into shape (28,28)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-06328ce5ff40>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msamples_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msamples_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_FINAL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplot_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnll_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-0d7b0610ee5a>\u001b[0m in \u001b[0;36msamples_generated\u001b[0;34m(name, data_loader, shape, extra_name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mplottable_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplottable_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    283\u001b[0m            [5, 6]])\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (28,28)"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 16 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# ==========DO NOT REMOVE OR MODIFY==========\n","# Final evaluation\n","test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n","f = open(result_dir + name + '_test_loss.txt', \"w\")\n","f.write(str(test_loss))\n","f.close()\n","\n","samples_real(result_dir + name, test_loader)\n","samples_generated(result_dir + name, test_loader, extra_name='_FINAL')\n","\n","plot_curve(result_dir + name, nll_val)"]},{"cell_type":"code","source":["def samples_generated(name, data_loader, shape=(28,28), extra_name=''):\n","    x, _ = next(iter(data_loader))\n","    x = x.to('cpu').detach().numpy()\n","\n","    # generations-------\n","    model_best = torch.load(name + '.model')\n","    model_best.eval()\n","\n","    num_x = 4\n","    num_y = 4\n","    x = model_best.sample(num_x * num_y)\n","    x = x.to('cpu').detach().numpy()\n","    print(x.shape)\n","    z=prior.sample(batch_size=9)\n","    y = decoder.sample(z)\n","    print(y.shape)\n","    print(model_best)\n","    # fig, ax = plt.subplots(num_x, num_y)\n","    # for i, ax in enumerate(ax.flatten()):\n","    #     plottable_image = np.reshape(x[i], shape)\n","    #     ax.imshow(plottable_image, cmap='gray')\n","    #     ax.axis('off')\n","\n","    #plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n","    #plt.close()\n","samples_generated(result_dir+name, test_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kj_b1U7rHtOt","executionInfo":{"status":"ok","timestamp":1719650265317,"user_tz":-120,"elapsed":305,"user":{"displayName":"Marco Simnacher","userId":"16297580182300741177"}},"outputId":"890fc686-38b5-475e-886f-aced0e4789f0"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Log probability decoded x shape: torch.Size([64])\n","(64,)\n","torch.Size([9, 784])\n","VAE(\n","  (encoder): Encoder(\n","    (encoder): Sequential(\n","      (0): Linear(in_features=784, out_features=128, bias=True)\n","      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Linear(in_features=128, out_features=32, bias=True)\n","    )\n","  )\n","  (decoder): Decoder(\n","    (decoder_net): Sequential(\n","      (0): Linear(in_features=16, out_features=128, bias=True)\n","      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","      (3): Linear(in_features=128, out_features=784, bias=True)\n","    )\n","  )\n","  (prior): Prior()\n",")\n"]}]},{"cell_type":"markdown","metadata":{"id":"qaBwGtSJF8ag"},"source":["### Results and discussion\n","\n","After a successful training of your model, we would like to ask you to present your data and analyze it. Please answer the following questions."]},{"cell_type":"markdown","metadata":{"id":"v4WZkoiHFyZm"},"source":["#### Question 9\n","\n","Please select the real data, and the final generated data and include them in this report. Please comment on the following:\n","- Do you think the model was trained properly by looking at the generations? Please motivate your answer well.\n","- What are the potential problems with evaluating a generative model by looking at generated data? How can we evaluate generative models (NOTE: ELBO or NLL do not count as answers)?"]},{"cell_type":"markdown","metadata":{"id":"Z8yQ2T9GIuvc"},"source":["ANSWER: [Please fill in]"]},{"cell_type":"markdown","metadata":{"id":"lmyH318fIwc9"},"source":["#### Question 10\n","\n","Please include the plot of the negative ELBO. Please comment on the following:\n","- Is the training of your VAE stable or unstable? Why?\n","- What is the influence of the optimizer on your model? Do the hyperparameter values of the optimizer important and how do they influence the training? Motivate well your answer (e.g., run the script with more than one learning rate and present two plots here)."]},{"cell_type":"markdown","metadata":{"id":"-10GAVZtKTj2"},"source":["ANSWER: [Please fill in]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1MJqcBJeYXxdGUimDdN3O_szoZV_pcteh","timestamp":1718703121907},{"file_id":"1C6CaZsSdXdc5fONOVrJy5iYKzr2DIg9j","timestamp":1607008727578}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}